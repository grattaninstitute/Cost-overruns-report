\documentclass{grattanAlpha}
\title{Cost overruns}
\author{Marion Terrill}

% \GrattanReportNumber{XX}


\catcode`\$=12
\begin{document}

<<source_all, echo=FALSE, message=FALSE, cache=FALSE>>=
# Grattan Program: Transport
# Project: Project level evaluation of transport infrastructure in Australia
# Module: Transport investment pipeline dynamics 


# Extensions:
#1. Double check that this filter works as it should. It looks like the sort of thing that would be easy to get wrong:
#project_dataset_costs_real <-
# project_dataset %>%
#filter(!is.na(Const_mid_point)) %>%
#setkey(Grattan_record, Qtrs_in_dataset) 
#2. > writeData(Cost_overrun_figures, 15, co_all_portfolio_level_table_1_AM)
#Error in writeData(Cost_overrun_figures, 15, co_all_portfolio_level_table_1_AM) : 
#  object 'co_all_portfolio_level_table_1_AM' not found


# Summary --------------------------------------------------------

# This script analyses data on the transport project pipeline from the Deloitte-Access Economics Investment Monitor Database. Data is imported from the quarterly snapshots of the project provided by the Investment Monitor (in Excel) and the data is cleaned and standardised for analysis. 

# This time series database of the project pipeline is complemented by data from a second IM dataset of all projects that exied the project pipeline, either because they were constructed, or because they were deleted from the pipeline. 

# Analysis will focus initially on how cost estimates change as projects progress through the IM project pipeline classifications. Later work will link this up with additional variables looking at whether projects were first proposed during State or CW election campaigns.

# A second purpose of this script is to produce a useable summary of data in the IM on the evolution of projects through the pipeline. This will support other modules of the project, especially in informing the manual collection of data on cost and time overruns from business cases, such as in controlling for changes in scope, or the staged implementation of projects.

# Documentation for the Investment Monitor

# Deloitte-Access provide a sample of the Investment Monitor report at: https://www.deloitteaccesseconomics.com.au/publications+and+reports/subscription+publications

# This includes a summary of some of the classifications adopted by Deloitte in the dataset. If required, we can obtain further detail from them on any particular definitions that we're interested in.

# Deloitte-Access Contacts

# Sheraan Underwood
# Graduate | Macroeconomic Policy and Forecasting
# Deloitte Touche Tohmatsu
# 8 Brindabelle Circuit, Canberra, 2609, Australia
# Tel/Direct: +61 2 6263 7000 
# shunderwood@deloitte.com.au | www.deloitte.com.au

# Stephen Smith

# Partner | Deloitte Access Economics
# Deloitte Touche Tohmatsu
# Level 2, 8 Brindabella Circuit
# Brindabella Business Park ACT 2609
# Tel: +61 (2) 6263 5079 | Mobile: +61 438 609 986 
# stephensmith1@deloitte.com.au | www.deloitte.com/au/economics
library(testthat)
library(Rcpp)
library(rJava)
library(xlsx)
library(readxl)
library(openxlsx)
library(plyr)
library(dplyr)
library(data.table)
library(dtplyr)
library(magrittr)
library(tidyr)
library(zoo)
library(ggplot2)
library(timeDate)
library(DescTools)
library(devtools)
library(CostOverrunsData)
library(data.table)
library(grattan)
if (texNum(1.25, dollar = TRUE) != "\\$1.25"){
  stop("Update the grattan package")  # recent bugfix
}
library(stats)
library(scales)
library(stats)
library(Hmisc)
library(VGAM)
library(ineq)
library(igraph)
library(actuar)
library(mixtools)
library(broom)
library(sandwich)
library(car)
library(mfx)
library(corrplot)
library(logistf)
library(curl)
library(DBI)
library(digest)


aspercent<-function(x){
  percent<-(x-1)*100
  return(percent)
}


project_dataset_plus<-
project_dataset %>% 
  mutate(Grattan_record = ifelse(is.na(`Record No`), 
                                 `Project No.`,
                                 `Record No`)) 
#subset(select = -c(`Project No.`, `Record No`))


# Expected project cost (and remove the old variables)

project_dataset_plus %<>% 
  mutate(Expected_cost = ifelse(!is.na(`Cost ($m)`), 
                                `Cost ($m)`, 
                                ifelse(!is.na(`Total cost`), `Total cost`, `Total cost $m`)), 
         Expected_cost = ifelse(Expected_cost==0, NA, Expected_cost))

# We also need to create a consistent set of State names for the state variable

project_dataset_plus %<>%
  mutate(State_new = ifelse(State == "TAS", "Tasmania",
                            ifelse(State == "Tasmania", "Tasmania", 
                                   ifelse(State == "SA", "South Australia",
                                          ifelse(State == "South Australia", "South Australia",
                                                 ifelse(State == "WA", "Western Australia",
                                                        ifelse(State == "Western Australia", "Western Australia",
                                                               ifelse(State == "Western Australia  ", "Western Australia",
                                                                      ifelse(State == "NSW", "New South Wales", 
                                                                             ifelse(State == "New South Wales", "New South Wales",
                                                                                    ifelse(State == "QLD", "Queensland",
                                                                                           ifelse(State == "Queensland", "Queensland",
                                                                                                  ifelse(State == "VIC","Victoria", 
                                                                                                         ifelse(State == "Victoria", "Victoria", 
                                                                                                                ifelse(State == "NT", "Northern Territory",
                                                                                                                       ifelse(State == "Northern Territory", "Northern Territory", 
                                                                                                                              ifelse(State == "ACT", "Australian Capital Territory", 
                                                                                                                                     ifelse(State == "Australian Capital Territory", "Australian Capital Territory", "Unallocated"))))))))))))))))))
 
# Fill expected cost variable, and filter out projects with initial or all expected costs == 0: -----

# First, we need to write a function that calculates the distance to the closest earlier non-NA cost estimate:

na_reset <- function(x) {
  test <- is.na(x)
  y <- cumsum(test)
  c(y - cummax(y * !test))
}

test_that("na_reset expected", {
  expect_equal(na_reset(c(1, 2, NA, NA, NA, 4, 5, NA, NA, 3, NA, 5)), 
               c(0L, 0L, 1L, 2L, 3L, 0L, 0L, 1L, 2L, 0L, 1L, 0L))
})


# Then we need to write a function that calulates the distance to the closest later non-NA cost estimate:

na_reset_rev <- function(x) {
  x <- rev(x)
  test <- is.na(x)
  y <- cumsum(test)
  rev(c(y - cummax(y * !test)))
}

# Now we need to generate the: 
#D2PC (distance to previous non na cost), 
#D2FC (distance to following non na cost), 
#Previous cost (previous non na cost)
#Following cost (following non na cost)
# and gap (D2PC + D2FC) variables:

## But first: Turning the sheet name into a record date. We want this to be the last day of the Quarter, as that is the point that the IM pipeline snapshot reflects. This will be important when we match the timing of project annoucements to election dates. 

project_dataset_plus %<>% 
  mutate(Record_date = paste("1 ", sheet), 
         Record_date = as.Date(as.yearqtr(Record_date, format = "%d %b %Y"), frac = 1)) %>%
  group_by(Grattan_record) %>%
  mutate(Qtrs_in_dataset = row_number(Record_date)) %>%
  ungroup

### REMEMBER TO TREAT NA's and 0's THE SAME!!


project_dataset_plus %<>%
  group_by(Grattan_record) %>%
  mutate(D2PC=na_reset(Expected_cost),
         D2FC=na_reset_rev(Expected_cost),
         gap = D2PC + D2FC, 
         Quarter_of_previous_cost = Qtrs_in_dataset - D2PC,
         Previous_cost = ifelse(is.na(Expected_cost), na.locf(Expected_cost, na.rm = FALSE), Expected_cost),
         Following_cost = ifelse(!is.na(Expected_cost), Expected_cost, ifelse(is.na(na.locf(Expected_cost, na.rm = FALSE, fromLast = TRUE)), Previous_cost, na.locf(Expected_cost, na.rm = FALSE, fromLast = TRUE))),
         Expected_cost_fill = ifelse(gap == 0, Expected_cost, Previous_cost^((gap - D2PC)/gap)*Following_cost^((gap - D2FC)/gap))) %>%
  mutate(Expected_cost = Expected_cost_fill) %>%
  ungroup() %>%
  filter(Quarter_of_previous_cost >0) %>%    # Drop observations prior to a cost being allocated to the project 
  arrange(Grattan_record)

# Writing new variables for when project enters and exits database -----------------------------------

## Turning the sheet name into a record date. We want this to be the last day of the Quarter, as that is the point that the IM pipeline snapshot reflects. This will be important when we match the timing of project annoucements to election dates. 

project_dataset_plus %<>% 
  mutate(Record_date = paste("1 ", sheet), 
         Record_date = as.Date(as.yearqtr(Record_date, format = "%d %b %Y"), frac = 1))


# Writing a variable for when project first enters database
# Writing an index number of the sequential quarter from when project first enters database, until it exits
# Writing a variable for when project exits database

project_dataset_plus %<>% 
  group_by(Grattan_record) %>% 
  mutate(Initial_date = min(Record_date), 
         Qtrs_in_dataset = row_number(Record_date), 
         Final_date = max(Record_date), 
         Total_qtrs_in_dataset = max(Qtrs_in_dataset),
         First_qtr_in_dataset = min(Qtrs_in_dataset))



# Fixing status descriptors - 'under construction' appears both as a lower and upper case but we only want one unique identifier

project_dataset_plus %<>%
  mutate(Status = ifelse(Status == "Under Construction", "Under construction", Status))

# I DON'T UNDERSTAND THIS PIECE OF CODE (at least it's hashed..) DELETE?
# There was a variable for when a record changed in the IM dataset (such as a status change), however it does not capture all status changes. 
# * New Projects  ^ Status Change  ~ Other Amended Details, or some combination of them

# project_dataset_plus %<>% 
#   mutate(Status_change = ifelse(is.na(Symbol), 
#                                 `Change `, 
#                                 Symbol),
#          New_project = grepl(pattern = "*", x = Status_change, fixed = TRUE), 
#          Pipeline_change = grepl(pattern = "^", x = Status_change, fixed = TRUE),
#          Other_amended_details = grepl(pattern = "~", x = Status_change, fixed = TRUE)) %>%
#   select(-Symbol, -`Change `)

# We therefore write a new variable for when the status of a project changes

project_dataset_plus %<>% 
  group_by(Grattan_record) %>%
  mutate(Status_change = ifelse(is.na(Status != lag(Status, order_by = Qtrs_in_dataset)), 
                                TRUE,
                                Status != lag(Status, order_by = Qtrs_in_dataset)))

# Now we write a new data frame that showsthe first quarter in which a project was listed under a particular status

first_qtr_by_status <- 
  project_dataset_plus %>%
  group_by(Grattan_record, Status) %>%
  summarise(first_quarter = min(Qtrs_in_dataset)) %>%
  spread(Status, first_quarter)

# And we do the same for the first date / period in which a project was listed under a particular status

first_date_by_status <- 
  project_dataset_plus %>%
  group_by(Grattan_record, Status) %>%
  summarise(first_date = min(Record_date)) %>%
  spread(Status, first_date) %>%
  setnames(old = names(.)[names(.) != "Grattan_record"], new = paste0("Date_first_as_", names(.)[names(.) != "Grattan_record"])) %>%
  setkey(Grattan_record)

# Setting Initial cost and Final cost based on when project entered the dataset
project_dataset_plus %<>%
  group_by(Grattan_record) %>%
  mutate(Initial_cost = first(Expected_cost_fill, order_by = Qtrs_in_dataset), 
         Final_cost = last(Expected_cost_fill, order_by = Qtrs_in_dataset))

# Reading in the historical dataset --------------------------------------------------------

# Deloitte-Access have also provided a listing of all projects in the Transport and Storage sector that have exited the database, either due to being completed, or being deleted (i.e. did not proceed)

# This is the replacement dataset provided by Deloitte access by email on 15 April 2016
#historical_dataset <- read_excel("../../Data sources/IM/Historical Transport and Storage - Original - 15 April.xls", sheet = "Project listing", skip = 2, col_names = TRUE, na = "na")

# Checking NA's - there are some records that have NA's for project costs - these are useless to us
#str(project_dataset_plus)
#str(historical_dataset)

#historical_dataset %>% 
#  group_by(is.na(`Total cost $m`)) %>%
#  summarise(total = length(`Total cost $m`))

# We subset just for those variables from the historical dataset that arent duplicates, and create a unique Grattan project record number to merge with our current dataset

# We also filter out those records that do not have a final expected project cost

historical_dataset %<>%
  filter(!is.na(`Total cost $m`)) %>%
  rename(Grattan_record = `Project No.`, 
         Final_cost_historical = `Total cost $m`, 
         Final_status_historical = Status, 
         Ownership_historical = Ownership, 
         Sub_industry_historical = `Sub-industry`, 
         State_historical = State) %>%
  dplyr::select(Grattan_record, Final_cost_historical, 
                Final_status_historical, Ownership_historical, Sub_industry_historical, State_historical) %>%
  as.data.table %>%
  setkey(Grattan_record) %>%
  unique



# Now we join the historical dataset to our project data by Grattan record project number key set earlier

setkey(project_dataset_plus, Grattan_record)
project_dataset_plus <- merge(project_dataset_plus, historical_dataset, all.x = TRUE)

# Writing the cost variables ---------------------------------

# Write a variable for the initial and final costs listed for projects in a particular period

costs_by_status <- 
  project_dataset_plus %>%
  group_by(Grattan_record, Status) %>%
  summarise(cost_when_first = first(Expected_cost_fill, order_by = Record_date), 
            cost_when_final = last(Expected_cost_fill, order_by = Record_date)) %>%
  ungroup %>%
  arrange(Grattan_record, Status)

all_statuses_each_record <- 
  data.table::CJ(
    Grattan_record = unique(project_dataset_plus$Grattan_record),
    Status = unique(project_dataset_plus$Status), 
    dummy = 0
  )

costs_by_status <- 
  costs_by_status %>%
  merge(all_statuses_each_record, by = c("Grattan_record", "Status"), all.y = TRUE) %>%
  dplyr::select(-dummy) %>%
  mutate(Status_ordered = factor(Status, levels = c("Possible", "Under consideration", "Committed", "Under construction", "Deleted"), ordered = TRUE)) %>%
  arrange(Grattan_record, Status_ordered) %>%
  group_by(Grattan_record) %>%
  mutate(cost_when_first = na.locf(cost_when_first, na.rm = FALSE), 
         cost_when_final = na.locf(cost_when_final, na.rm = FALSE)) %>%
  dplyr::select(-Status_ordered)

# Separate data frame for intial cost in each status

first_cost_by_status <- 
  costs_by_status %>%
  dplyr::select(-contains("final")) %>%
  spread(Status, cost_when_first) %>%
  setnames(old = names(.)[names(.) != "Grattan_record"], new = paste0("First_cost_when_", names(.)[names(.) != "Grattan_record"])) %>% .[] %>%
  setkey(Grattan_record)

# Separate data frame for final cost in each status

final_cost_by_status <- 
  costs_by_status %>%
  dplyr::select(-contains("first")) %>%
  spread(Status, cost_when_final) %>%
  setnames(old = names(.)[names(.) != "Grattan_record"], new = paste0("Final_cost_when_", names(.)[names(.) != "Grattan_record"])) %>% .[] %>%
  setkey(Grattan_record)

# Now we merge this data frame into our main project_dataset_plus

# Set key for merging the datasets
setkey(project_dataset_plus, Grattan_record)

project_dataset_plus <-
  merge(project_dataset_plus, first_date_by_status, all.x = TRUE) 

project_dataset_plus <-
  merge(project_dataset_plus, first_cost_by_status, all.x = TRUE) 

project_dataset_plus <-
  merge(project_dataset_plus, final_cost_by_status, all.x = TRUE) 

# Writing status and other time-related variables -----


# Quickly rename the variables

project_dataset_plus %<>%
  mutate(First_cost_when_under_consideration = `First_cost_when_Under consideration`, 
         First_cost_when_under_construction = `First_cost_when_Under construction`, 
         Final_cost_when_under_consideration = `Final_cost_when_Under consideration`, 
         Final_cost_when_under_construction = `Final_cost_when_Under construction`) %>%
  dplyr::select(-c(`First_cost_when_Under consideration`,
                   `First_cost_when_Under construction`,
                   `Final_cost_when_Under consideration`,
                   `Final_cost_when_Under construction`))   



# We're going to combine the "Possible" and "Under consideration" statuses (ie. periods) because there are not many projects in the IM that are ever listed as Possible, and it's not clear what the distinction is between projects classified as 'Possible' and 'Under consideration' in Deloitte's classification system (at least for projects to deliver public infrastructure in the roads and rail sectors)

# So first, we need to write a new expected cost variable that amalgamates the costs of projects the commence in the 'Possible' and 'Under Consideration' stages

project_dataset_plus %<>%
  mutate(First_cost_when_Possible_or_under_consideration = ifelse(!is.na(First_cost_when_Possible), 
                                                                  First_cost_when_Possible, 
                                                                  First_cost_when_under_consideration), 
         Final_cost_when_Possible_or_under_consideration = Final_cost_when_under_consideration) 

# We also clean up some of the other variables that have inconsistent names over the IM dataset

## Start Date / Date Start


project_dataset_plus %<>% 
  mutate(Start_date = ifelse(is.na(`Start date`), 
                             `Date start`,
                             `Start date`)) %>%
  mutate(Start_date = ifelse(grepl(pattern = "^[3][0-9]{4}$", x = Start_date),
                             as.character(as.Date("1899-12-30") + as.numeric(Start_date)),
                             Start_date)) %>%
  subset(select = -c(`Start date`,`Date start`))

## End Date / Completion Date

project_dataset_plus %<>% 
  mutate(End_date = ifelse(is.na(`Completion date`), 
                           `End date`,
                           `Completion date`)) %>%
  mutate(End_date = ifelse(grepl(pattern = "[3][0-9]{4}", x = End_date),
                           as.character(as.Date("1899-12-30") + as.numeric(Start_date)),
                           End_date)) %>%
  subset(select = -c(`Completion date`,`End date`))



## Employment Construction / [spaces] Employment Construction

project_dataset_plus %<>% 
  mutate(Construction_employment = ifelse(is.na(`Employment Construction`), 
                                          `               Employment Construction`,
                                          `Employment Construction`)) %>%
  subset(select = -c(`Employment Construction`,`               Employment Construction`))

# Writing a variable for what status a project had when it first entered the database 




project_dataset_plus %<>% 
  group_by(Grattan_record) %>%
  mutate(Numeric_status = ifelse(Status == "Possible", 1, 
                                 ifelse(Status == "Under consideration", 2, 
                                        ifelse(Status == "Committed", 3, 
                                               ifelse(Status == "Under construction", 4, 
                                                      ifelse(Status == "Deleted", 5, 6))))), 
         Min_numeric_status = min(Numeric_status), 
         Initial_status_prep = ifelse(Min_numeric_status < 2, "Possible", 
                                      ifelse(Min_numeric_status < 3, "Under consideration", 
                                             ifelse(Min_numeric_status < 4, "Committed", 
                                                    ifelse(Min_numeric_status < 5, "Under construction", 
                                                           ifelse(Min_numeric_status < 6, "Deleted", "NA")))))) %>%
  mutate(Initial_status_prep2 = as.factor(Initial_status_prep)) %>%
  mutate(Initial_status = ordered(Initial_status_prep2, c("Possible", "Under consideration", "Committed", "Under construction", "Deleted")))


# Writing a variable for what status a project had when it left the database
project_dataset_plus %<>%
  group_by(Grattan_record) %>%
  mutate(Max_numeric_status = max(Numeric_status), 
         Final_status_prep = ifelse(Max_numeric_status < 2, "Possible", 
                                    ifelse(Max_numeric_status < 3, "Under consideration", 
                                           ifelse(Max_numeric_status < 4, "Committed", 
                                                  ifelse(Max_numeric_status < 5, "Under construction", 
                                                         ifelse(Max_numeric_status < 6, "Deleted", "NA")))))) %>%
  mutate(Final_status_prep2 = as.factor(Final_status_prep)) %>%
  mutate(Final_status = ordered(Final_status_prep2, c("Possible", "Under consideration", "Committed", "Under construction", "Deleted")))

# Writing variables for the number of quarters that projects spend at each stage

# First we create a new data frame to assign the number of quarters that projects spend in each status

status_length_assign <-
  project_dataset_plus %>% 
  group_by(Grattan_record, Status) %>%
  summarise(Total_qtrs_in_status = n()) %>%
  ungroup %>%
  mutate(Status = paste0("n_quarters_",gsub("\\s+", "_", Status))) %>%
  spread(Status, Total_qtrs_in_status, fill = 0) %>%
  setkey(Grattan_record)

# Now we merge this data frame into our main project_dataset_plus

project_dataset_plus <-
  merge(project_dataset_plus, status_length_assign, all.x = TRUE) 

# Checking pipeline definitions

levels(as.factor(project_dataset_plus$Status)) # OK there is one doubling up. Let's fix it

project_dataset_plus %<>% 
  mutate(Status = ifelse(Status == 'Under Construction', 'Under construction', Status))

# Checking matching of final status from the time series dataset with the Final Status from the Historical Dataset

project_dataset_plus %>%
  setkey(Grattan_record) %>%     
  unique %>%
  filter(`Major industry` == "Transport & Storage") %>%
  group_by(Final_status, Final_status_historical) %>%
  summarise(no_records = n())

# We see there are some projects that made it to the 'under construction' stage in the quarterly IM which were deemed to be 'Deleted' in the final historical dataset

# Writing variables for project period 

project_dataset_plus %<>%
  mutate(Final_date_year = year(Final_date), 
         Final_date_period_5yrs = ifelse(Final_date_year < 2005, "2000-2004", 
                                         ifelse(Final_date_year < 2010, "2005-2009", "2010-2015")), 
         Final_date_year = year(Final_date), 
         Initial_date_year = year(Initial_date), 
         Initial_date_period_5yrs = ifelse(Initial_date_year < 2005, "2000-2004", 
                                           ifelse(Initial_date_year < 2010, "2005-2009", "2010-2015")))

# Normalising our cost variables into real terms -----------------------------------

# One aspect we wish to investigate is whether cost overruns vary by project size. Therefore we need to normalise our project cost variables over time for changes in prices, in order to consistently compare project sizes in real terms over time

# Importantly, our prospective cost estimates are forward looking, and in nominal terms. For example, a cost estimate published in June 2006 will refer to nominal prices for the project across the various years in which it is expected to be built. Such as between 2010 and 2012. Therefore we dont need to treat the cost variables differently as a project transitions through stages. Rather, the same transformations will be applied to all cost variables.

# However, how do we need a way of inflating cost variables for projects that are constructed in different time periods. One option is to work out the midpoint quarter of a project's life and then inflate all project cost variables to that point. That should at least normalise the size of projects that occur at different time periods. 

# The question then becomes what is the relevant time period to take? For example, should we take the mid point from when the project first enters the dataset until it leaves? Or should the midpoint be from when a project commences construction until when it completes constuction? This second approach is much more difficult since not all projects reach construction. 

# For now, we will use the first approach, taking the mid point from when a project first enters the dataset until it exits. We also need the mid_point to align with the nearest quarter in order to use the quarterly inflation figures from the ABS

project_dataset_plus %<>%
  group_by(Grattan_record) %>%
  mutate(Project_mid_point = as.Date(Initial_date + as.numeric(Final_date - Initial_date) / 2), 
         Project_mid_point_qtr = as.Date(as.yearqtr(Project_mid_point), frac = 1))

# And the second approach, taking the midpoint only for projects that are actually constructed

project_dataset_plus %<>%
  group_by(Grattan_record) %>%
  mutate(Const_mid_point = if_else(!is.na(as.Date(`Date_first_as_Under construction` + as.numeric(Final_date - `Date_first_as_Under construction`) / 2)),
                                   as.Date(`Date_first_as_Under construction` + as.numeric(Final_date - `Date_first_as_Under construction`) / 2),
                                   Project_mid_point), 
         Const_mid_point_qtr_date = as.Date(as.yearqtr(Const_mid_point), frac = 1), 
         Const_mid_point_qtr = as.character(gsub(" ", "-",as.character(as.yearqtr(Const_mid_point, format="%Y-%m-%d"))))) 
table(is.na(project_dataset_plus$Const_mid_point_qtr))

# Inflating cost variables

# Here we only inflate for the second approach - only for those projects that actually make it to the construction phase
# We inflate all cost variables in the dataset forward to 2015-Q4 dollars
# At the moment we're only using a CPI deflator as that is what is easily available via the ABS SDMX website. However we will move to a deflator based on construction costs.

# NEW: Construction_inflator.R script:

# This is now redundant because it's written to the CostOveerrunsData package.
#construction_indices <- 
#  read_excel("./Construction-price-index.xlsx", sheet = "Data")

construction_indices %<>% 
  mutate(Time = as.yearqtr(Time)) %>%
  as.data.table 


# This will equal 1.661184 if the inflator's working correctly:
#general_inflator(from = as.yearqtr("1998 Q1"), to = as.yearqtr("2013 Q1"), inflator_table = construction_indices)

construction_inflator <- function(x = 1, from, to){
  general_inflator(x = x, from = from, to = to, inflator_table = construction_indices)
}

inflate_using_mid_point_qtr_construction <- function(x){
  construction_inflator(x, from = as.yearqtr(project_dataset_plus$Const_mid_point_qtr, format = "%Y-Q%q"), to = as.yearqtr("2015 Q4"))
}

project_dataset_plus %<>%
mutate(Expected_cost_real = inflate_using_mid_point_qtr_construction(Expected_cost),
         Initial_cost_real = inflate_using_mid_point_qtr_construction(Initial_cost),
         Final_cost_real = inflate_using_mid_point_qtr_construction(Final_cost),
         Final_cost_historical_real = inflate_using_mid_point_qtr_construction(Final_cost_historical),
         First_cost_when_Possible_real = inflate_using_mid_point_qtr_construction(First_cost_when_Possible),
         First_cost_when_under_consideration_real = inflate_using_mid_point_qtr_construction(First_cost_when_under_consideration),
         First_cost_when_Possible_or_under_consideration_real = inflate_using_mid_point_qtr_construction(First_cost_when_Possible_or_under_consideration),
         First_cost_when_Committed_real = inflate_using_mid_point_qtr_construction(First_cost_when_Committed),
         First_cost_when_under_construction_real = inflate_using_mid_point_qtr_construction(First_cost_when_under_construction),
         Final_cost_when_Possible_real = inflate_using_mid_point_qtr_construction(Final_cost_when_Possible),
         Final_cost_when_Possible_or_under_consideration_real = inflate_using_mid_point_qtr_construction(Final_cost_when_Possible_or_under_consideration),
         Final_cost_when_under_consideration_real = inflate_using_mid_point_qtr_construction(Final_cost_when_under_consideration),
         Final_cost_when_Committed_real = inflate_using_mid_point_qtr_construction(Final_cost_when_Committed),
         Final_cost_when_under_construction_real = inflate_using_mid_point_qtr_construction(Final_cost_when_under_construction))
         
# This is the code that Brendan/Hugh initially wrote. 
# It's tempermental: sometimes it doesn't inflate the series', but it also doesn't provide an explanation. 
# I also am not very familar with grep, so I find it hard to fix. That's why I've written it out longhand. 
# We do this in a different dataframe: (can this be deleted, now that it's not used to filter out the projects with no construction mid point date?)

#project_dataset_plus_costs_real <-
#  as.data.table(project_dataset_plus) %>%
#  setkey(Grattan_record, Qtrs_in_dataset) 

# Now we inflate forward all cost variable into Q4-2015 dollars

#for (j in grep("cost", names(project_dataset_plus_costs_real))){
#  set(project_dataset_plus_costs_real, j = j, value = construction_inflator(x = as.numeric(project_dataset_plus_costs_real[[j]]), 
#                                                                       from = as.yearqtr(project_dataset_plus_costs_real$Const_mid_point_qtr, format = "%Y-Q%q"), 
#                                                                       to = as.yearqtr("2015 Q4")))
#}

# Now we merge the inflated dataset back into our main dataset, prescribing the '_real' postscript to all inflated variables 

# We select only those inflated cost variables that we need to port across to the main dataset
#project_dataset_plus_costs_real %<>%
#  dplyr::select(contains("cost"), Grattan_record, Qtrs_in_dataset)

#setkey(as.data.table(project_dataset_plus), Grattan_record, Qtrs_in_dataset)

#project_dataset_plus <-
#  merge(project_dataset_plus, project_dataset_plus_costs_real, all.x = TRUE, suffixes = c("","_real")) 

stopifnot(all(!is.na(project_dataset_plus$Initial_cost_real)))
test_that("Inflator returns different values", {
  expect_false(project_dataset_plus %$% all(near(Initial_cost, Initial_cost_real)))
})

# Writing cost ratio variables (used to build indices) -----

project_dataset_plus %<>%
  mutate(Under_consideration_cost_over_initial = ifelse(is.na(First_cost_when_under_consideration)==FALSE, First_cost_when_under_consideration / Initial_cost, 1),
         Committed_cost_over_initial = ifelse(is.na(First_cost_when_Committed)==FALSE, First_cost_when_Committed / Initial_cost, 1),
         Under_construction_cost_over_initial = ifelse(is.na(First_cost_when_under_construction)==FALSE, First_cost_when_under_construction / Initial_cost, 1),
         
         Final_cost_over_initial = Final_cost / Initial_cost, 
         Final_cost_over_Possible = ifelse(is.na(First_cost_when_Possible)==FALSE, Final_cost / First_cost_when_Possible,
                                           ifelse(is.na(First_cost_when_under_consideration)==FALSE, Final_cost / First_cost_when_under_consideration, 
                                                                  ifelse(is.na(First_cost_when_Committed)==FALSE, Final_cost / First_cost_when_Committed,  Final_cost / First_cost_when_under_construction))),
         Final_cost_over_Possible_or_under_consideration = ifelse(is.na(First_cost_when_Possible_or_under_consideration)==FALSE, Final_cost / First_cost_when_Possible_or_under_consideration, 
                                                                  ifelse(is.na(First_cost_when_Committed)==FALSE, Final_cost / First_cost_when_Committed,  Final_cost / First_cost_when_under_construction)),
         Final_cost_over_under_consideration = ifelse(is.na(First_cost_when_under_consideration)==FALSE, Final_cost / First_cost_when_under_consideration, 
                                                                  ifelse(is.na(First_cost_when_Committed)==FALSE, Final_cost / First_cost_when_Committed,  Final_cost / First_cost_when_under_construction)),
         Final_cost_over_committed = ifelse(is.na(First_cost_when_Committed)==FALSE,Final_cost / First_cost_when_Committed, Final_cost / First_cost_when_under_construction),
         Final_cost_over_under_construction = Final_cost / First_cost_when_under_construction, 
         
         
         Under_consideration_cost_over_Possible = ifelse(is.na(First_cost_when_under_consideration)==TRUE, 1, 
                                                         ifelse(is.na(First_cost_when_Possible)==FALSE, First_cost_when_under_consideration / First_cost_when_Possible, 1)),
         
         Committed_cost_over_Possible = ifelse(is.na(First_cost_when_Committed)==TRUE, 1, 
                                                                      ifelse(is.na(First_cost_when_Possible)==FALSE, First_cost_when_Committed / First_cost_when_Possible, 
                                                                             ifelse(is.na(First_cost_when_Committed)==FALSE, First_cost_when_Committed/First_cost_when_under_construction, 1))),
         Committed_cost_over_Possible_or_under_consideration = ifelse(is.na(First_cost_when_Committed)==TRUE, 1, 
                                                                      ifelse(is.na(First_cost_when_Possible_or_under_consideration)==FALSE, First_cost_when_Committed / First_cost_when_Possible_or_under_consideration, 1)),
         Committed_cost_over_under_consideration = ifelse(is.na(First_cost_when_Committed)==TRUE, 1, 
                                                                       ifelse(is.na(First_cost_when_under_consideration)==FALSE, First_cost_when_Committed / First_cost_when_under_consideration, 1)),

         Under_construction_cost_over_Possible = ifelse(is.na(First_cost_when_under_construction)==TRUE, 1, 
                                                                               ifelse(is.na(First_cost_when_Possible)==FALSE, First_cost_when_under_construction / First_cost_when_Possible, 
                                                                                      ifelse(is.na(First_cost_when_under_consideration)==FALSE, First_cost_when_under_construction / First_cost_when_under_consideration,
                                                                                      ifelse(is.na(First_cost_when_Committed)==FALSE, First_cost_when_under_construction / First_cost_when_Committed, 1)))),
         Under_construction_cost_over_Possible_or_under_consideration = ifelse(is.na(First_cost_when_under_construction)==TRUE, 1, 
                                                                   ifelse(is.na(First_cost_when_Possible_or_under_consideration)==FALSE, First_cost_when_under_construction / First_cost_when_Possible_or_under_consideration, 
                                                                          ifelse(is.na(First_cost_when_Committed)==FALSE, First_cost_when_under_construction / First_cost_when_Committed, 1))),
         Under_construction_cost_over_under_consideration = ifelse(is.na(First_cost_when_under_construction)==TRUE, 1, 
                                                                   ifelse(is.na(First_cost_when_under_consideration)==FALSE, First_cost_when_under_construction / First_cost_when_under_consideration, 
                                                                      ifelse(is.na(First_cost_when_Committed)==FALSE, First_cost_when_under_construction / First_cost_when_Committed, 1))),
         Under_construction_cost_over_committed = ifelse(is.na(First_cost_when_under_construction)==TRUE, 1, 
                                                         ifelse(is.na(First_cost_when_Committed)==FALSE, First_cost_when_under_construction / First_cost_when_Committed, 1)))
 

# Writing variables for project size -----------------------------------

# We're writing all our project size variables based on the inflation-adjusted real expected cost variable
# We'll also write project size variables based on the unadjusted expected cost variables

# Classifications based on initial cost - inflation adjusted

project_dataset_plus %<>%
  mutate(Expected_cost_real_band_initial = ifelse(Initial_cost_real < 50, "Less than $50 million", 
                                                  ifelse(Initial_cost_real < 100, "$50-$100 million", 
                                                         ifelse(Initial_cost_real < 200, "$100-$200 million", 
                                                                ifelse(Initial_cost_real < 500, "$200-$500 million", 
                                                                       ifelse(Initial_cost_real < 1000, "$500 million - $1 billion", "More than $1 billion" 
                                                                       ))))), 
         Expected_cost_real_band_initial = as.factor(Expected_cost_real_band_initial), 
         Expected_cost_real_band_initial = ordered(x = Expected_cost_real_band_initial, 
                                                   c("Less than $50 million",
                                                     "$50-$100 million",
                                                     "$100-$200 million",
                                                     "$200-$500 million", 
                                                     "$500 million - $1 billion", 
                                                     "More than $1 billion")))

# Classifications based on initial cost - not inflation adjusted
project_dataset_plus %<>%
  mutate(Expected_cost_band_initial = ifelse(Initial_cost < 50, "Less than $50 million", 
                                             ifelse(Initial_cost < 100, "$50-$100 million", 
                                                    ifelse(Initial_cost < 200, "$100-$200 million", 
                                                           ifelse(Initial_cost < 500, "$200-$500 million", 
                                                                  ifelse(Initial_cost < 1000, "$500 million - $1 billion", "More than $1 billion" 
                                                                  ))))), 
         Expected_cost_band_initial = as.factor(Expected_cost_band_initial), 
         Expected_cost_band_initial = ordered(x = Expected_cost_real_band_initial, 
                                              c("Less than $50 million",
                                                "$50-$100 million",
                                                "$100-$200 million",
                                                "$200-$500 million", 
                                                "$500 million - $1 billion", 
                                                "More than $1 billion")))

# Classifications based on final cost - inflation adjusted 

project_dataset_plus %<>%
  mutate(Expected_cost_real_band_final = ifelse(Final_cost_real < 50, "Less than $50 million", 
                                                ifelse(Final_cost_real < 100, "$50-$100 million", 
                                                       ifelse(Final_cost_real < 200, "$100-$200 million", 
                                                              ifelse(Final_cost_real < 500, "$200-$500 million", 
                                                                     ifelse(Final_cost_real < 1000, "$500 million - $1 billion", "More than $1 billion" 
                                                                     ))))),
         
         Expected_cost_real_band_final = as.factor(Expected_cost_real_band_final), 
         Expected_cost_real_band_final = ordered(x = Expected_cost_real_band_final, 
                                                 c("Less than $50 million",
                                                   "$50-$100 million",
                                                   "$100-$200 million",
                                                   "$200-$500 million", 
                                                   "$500 million - $1 billion", 
                                                   "More than $1 billion")))

# Classifications based on final cost - not inflation adjusted 

project_dataset_plus %<>%
  mutate(Expected_cost_band_final = ifelse(Final_cost < 50, "Less than $50 million", 
                                           ifelse(Final_cost < 100, "$50-$100 million", 
                                                  ifelse(Final_cost < 200, "$100-$200 million", 
                                                         ifelse(Final_cost < 500, "$200-$500 million", 
                                                                ifelse(Final_cost < 1000, "$500 million - $1 billion", "More than $1 billion" 
                                                                ))))),
         
         Expected_cost_band_final = as.factor(Expected_cost_band_final), 
         Expected_cost_band_final = ordered(x = Expected_cost_band_final, 
                                            c("Less than $50 million",
                                              "$50-$100 million",
                                              "$100-$200 million",
                                              "$200-$500 million", 
                                              "$500 million - $1 billion", 
                                              "More than $1 billion")))

# Checking
project_dataset_plus %>%
  setkey(Grattan_record) %>%     
  unique %>%
  filter(`Major industry` == "Transport & Storage") %>% 
  group_by(Expected_cost_real_band_initial) %>%
  summarise(total = n())

# Writing any other miscellanous variables to project_dataset_plus: ----

# Writing a variable for the GFC and when projects commenced construction

# We assume the GFC starts with the collapse of Lehmann Brothers, but write the variable to the end of the quarter since we only have discrete quarterly dates in the IM
# https://en.wikipedia.org/wiki/Lehman_Brothers

GFC <- as.Date("2008-12-31") 

project_dataset_plus %<>%
  mutate(Constructed_post_GFC = ifelse(`Date_first_as_Under construction` > GFC, 1, 0))

# We also write variables for the time period (in days) between when a project enters the dataset until it (a) is committed to; and (b) commences construction

project_dataset_plus %<>%
  mutate(Total_days_under_construction = ifelse(!is.na(`Date_first_as_Under construction`), as.numeric(Final_date - `Date_first_as_Under construction`), NA))

Prep_for_average_days_under_construction<-
  project_dataset_plus %>%
  filter(!is.na(Total_days_under_construction)) %>%
  setkey(Grattan_record) %>%     
  unique
  
Average_days_under_construction <- mean(Prep_for_average_days_under_construction$Total_days_under_construction)

project_dataset_plus %<>%
  mutate(Total_days_pre_construction = ifelse(is.na(Total_days_under_construction) == TRUE, as.numeric(Final_date - Initial_date)-Average_days_under_construction, as.numeric(`Date_first_as_Under construction` - Initial_date)),
         Total_days_pre_commitment = as.numeric(`Date_first_as_Committed` - Initial_date), 
         Total_days_pre_consideration = as.numeric(`Date_first_as_Under consideration` - Initial_date)) 

# Finally, we need a categorical variable that describes in one when projects enter and exist the dataset. We also need a variable that checks whether projects that are under construction are actually listed as completed in the IM historical dataset. 
# NOTE: I also clean the final_cost_historical series here. If a project exits the dataset as NA before being under construction, it's classified as "deleted"; otherwise, "completed".

project_dataset_plus %<>%
  mutate(Pipeline_status = paste0(Initial_status, " - ", Final_status), 
         Matching_status_prep = paste0(Initial_status, " - ", Final_status_historical), 
         Final_status_historical = if_else(Matching_status_prep =="Under construction - NA", "Completed", Final_status_historical),
         Final_status_historical = if_else(Matching_status_prep =="Possible - NA", "Deleted", Final_status_historical),
         Final_status_historical = if_else(Matching_status_prep =="Under consideration - NA", "Deleted", Final_status_historical),
         Final_status_historical = if_else(Matching_status_prep =="Committed - NA", "Deleted", Final_status_historical),
         Matching_status = as.factor(paste0(Initial_status, " - ", Final_status_historical)),
         Matching_status = ordered(Matching_status, c("Possible - NA", "Under consideration - NA", "Committed - NA", "Under construction - NA", "Possible - Deleted",
                                                            "Under consideration - Deleted", "Committed - Deleted", "Under construction - Deleted", "Possible - Completed", 
                                                            "Under consideration - Completed", "Committed - Completed", "Under construction - Completed")),
         Matching_status_numeric = if_else(Matching_status == "Possible - Completed", 1, 
                                           if_else(Matching_status == "Under consideration - Completed", 2,
                                                   if_else(Matching_status == "Committed - Completed", 3, 4))),
         Final_matching_status = paste0(Final_status, " - ", Final_status_historical),
         Matching_status_refined = if_else(as.character(Matching_status) =="Possible - Completed", "Possible or under consideration - Completed", as.character(Matching_status)), 
         Matching_status_refined = as.factor(if_else(Matching_status_refined == "Under consideration - Completed", "Possible or under consideration - Completed", Matching_status_refined)),
         Matching_status_refined = ordered(Matching_status_refined, c("Possible - NA", "Under consideration - NA", "Committed - NA", "Under construction - NA", "Possible - Deleted",
                                                            "Under consideration - Deleted", "Committed - Deleted", "Under construction - Deleted", "Possible or under consideration - Completed", "Committed - Completed", "Under construction - Completed")))



####################### Sub setting the dataset to the first usable dataset (biggest filter: transport projects only): ********* "project_dataset_t" ******** -----------------------------------

# Not all of these are public infrastructure projects, so we need to filter out (a) non-transport projects, (b) private projects and (c) projects that are missing key data (eg: costs) 

# A) Subsetting to public projects only
# The Ownership variable in the Deloitte Access dataset is incomplete - it has not been recorded for all projects. 
# However, Lucille has gone through every road and rail project in the historical dataset and has manually classified each project as being either public or private. 
# In this section we:
# A1. Export the Deloitte dataset's record of whether a project is public/private
# A2. Pull back in the list of projects that Lucille has manually classified as either public or private projects. 
# A3. Merge Lucille's public/private variable for all transport projects back into the main dataframe.
# A4. Filter out any private projects

# A1. Export the Deloitte dataset's record of whether a project is public/private

#project_list <- read_excel("../Spreadsheets/IM historical transport and storage working copy.xls", sheet = "Project listing", skip = 2, col_names = TRUE, na = "na")

#project_list %<>% 
#  mutate(Grattan_record = `Project No.`, 
#         Private_project_Grattan = `Private? (coded for road/rail projects only)`, 
#         Public_project_Grattan = ifelse(is.na(Private_project_Grattan), TRUE, FALSE)) %>%
#  dplyr::select(Grattan_record, Private_project_Grattan, Public_project_Grattan) %>%
#  as.data.table %>%
#  setkey(Grattan_record) %>%
#  unique

#project_dataset_merging <- 
#  project_dataset_plus %>%
#  filter(`Sub-industry` == "Road" | `Sub-industry` == "Rail" ) %>%
#  dplyr::select(Grattan_record, Company, Project, Ownership, Initial_date, Initial_status, Final_date, Final_status, Final_status_historical, `Sub-industry`, Expected_cost, Expected_cost_real) %>%
#  as.data.table %>%
#  setkey(Grattan_record) %>%
#  unique

#project_list_merged <- 
#  merge(project_dataset_plus_merging, project_list, all.x = TRUE) %>%
#  filter(!is.na(Grattan_record)) 

#project_list_merged %>% 
#  write.xlsx(file = "../Spreadsheets/Deloitte pipeline analysis outputs/Projects by mode and ownership - Project List.xlsx",
#             sep = ",", col.names = TRUE, sheetName = "Project_list")


# A2. Pull back in the list of projects that Lucille has manually classified as either public or private projects. 

#completed_project_list <- read_excel("../../Data sources/IM/Projects by mode and ownership - Project List_LD.xlsx", 
#                                     sheet = "Project_list", col_names = TRUE, na = "na")

# A3. Merge Lucille's public/private variable for all transport projects back into the main dataframe.
completed_project_list %<>%
  dplyr::select(Grattan_record, Public_project_Grattan, Private_project_Grattan) %>%
  as.data.table %>%
  setkey(Grattan_record)

project_dataset_plus <- 
  merge(project_dataset_plus, completed_project_list, all.x = TRUE)  

# A4. Filter out any private projects
project_dataset_t_A <- 
  project_dataset_plus %>% 
  filter(Public_project_Grattan == 1)

# B) Subsetting to Transport Projects only


project_dataset_t_B <- 
  project_dataset_t_A %>% 
  filter(`Major industry` == "Transport & Storage") %>%
  filter(`Sub-industry` == "Road"| `Sub-industry` == "Rail" )


# C) Filter out any projects that are missing key data

project_dataset_t_C <- 
  project_dataset_t_B %>% 
  setkey(Grattan_record) %>%     
  unique 


# D) Filter out projects with final values below $20m:
project_dataset_t_D <- 
  project_dataset_t_C %>% 
  filter(Initial_cost >= 20)

# E) Filter out any erroneous data:
project_dataset_t <- 
  project_dataset_t_D %>% 
  filter(Final_cost_over_initial <=5.2) %>% # Any overrun greater than 5.2 is suspect of a data error. This is because the Peel deviation is the project with the largest overrun that we have been able to verify with certainty. A bunch of the extreme outliers were all redcorded on the same day, which looks suspicious too. 
  filter(Final_cost_over_initial >=0.5) # This is a generous definition of outliers as the biggest underrun we observe is the 34% underrun on the Springfield to Richlands line. 
  
### In case we need to replicate earlier results, this was the previous outlier filter I had applied: 
# filter(Grattan_record != 6829) Grattan id: 6829 has an overall cost overrun of 7950%. 

# Creating election variables part 1: All elections ### ----
# Note: There is one WA Senate election observation that will not be captured in either the state or federal election variables.

# First we need to import the list of CW and State elections that Lucille has prepared.

#elections <- read_excel("../../Data sources/IM/Dates of all state and federal elections.xlsx", sheet = 1, col_names = TRUE)


# We re-write the date variable to date form, and convert it to the end of the quarter to align with the IM dataset
elections %<>%
  mutate(Election_date  = as.Date(Date, format = "%d %b %Y"),
         Election_qtr = as.Date(as.yearqtr(Election_date, format = "%d %b %Y"), frac = 1), 
         Date_first_as_Committed = Election_qtr) %>%
  as.data.table

# Now we define the relevant election variables we're interested in

# Now we write a variable for whether the first quarter in which a project is classified as committed is within 90, 180 or 365 days of a recent CW or state election

# Here we use a rolling join

# Set keys for the rolling join
setkey(elections, Date_first_as_Committed)
setkey(project_dataset_t, Date_first_as_Committed)

# We do the CW elections first
federal_elections <- elections[Jurisdiction == "Federal"]

federal_elections_90_days <-
  federal_elections[project_dataset_t, roll=-90] %>%
  mutate(CW_election_within_90_days = !is.na(Jurisdiction)) %>%
  dplyr::select(Grattan_record, CW_election_within_90_days) %>%
  setkey(Grattan_record) %>%
  unique

federal_elections_180_days <-
  federal_elections[project_dataset_t, roll=-180] %>%
  mutate(CW_election_within_180_days = !is.na(Jurisdiction)) %>%
  dplyr::select(Grattan_record, CW_election_within_180_days) %>%
  setkey(Grattan_record) %>%
  unique

federal_elections_365_days <-
  federal_elections[project_dataset_t, roll=-365] %>%
  mutate(CW_election_within_365_days = !is.na(Jurisdiction), 
         CW_election_date = Election_date, 
         CW_election_qtr = Election_qtr) %>%
  dplyr::select(Grattan_record, CW_election_within_365_days, CW_election_date, CW_election_qtr) %>%
  setkey(Grattan_record) %>%
  unique

# Now we join the CW election variables to the main project dataset

project_dataset_t %>%
  setkey(Grattan_record)

project_dataset_t <- 
  merge(project_dataset_t, federal_elections_90_days, all.x = TRUE) 

project_dataset_t <- 
  merge(project_dataset_t, federal_elections_180_days, all.x = TRUE) 

project_dataset_t <- 
  merge(project_dataset_t, federal_elections_365_days, all.x = TRUE) 

project_dataset_t %>%
    setkey(Grattan_record) %>%     unique %>%
  group_by(CW_election_within_90_days, CW_election_within_180_days, CW_election_within_365_days) %>%
  summarise(n = n())

# Now we do the same for state elections

state_elections <- elections[Jurisdiction != "Federal"]

state_elections %<>%
  mutate(State = Jurisdiction) %>%
  setkey(State, Date_first_as_Committed)

setkey(project_dataset_t, State, Date_first_as_Committed)

state_elections_90_days <-
  state_elections[project_dataset_t, roll=-90] %>%
  mutate(State_election_within_90_days = !is.na(Jurisdiction)) %>%
  dplyr::select(Grattan_record, State_election_within_90_days) %>%
  setkey(Grattan_record) %>%
  unique

state_elections_180_days <-
  state_elections[project_dataset_t, roll=-180] %>%
  mutate(State_election_within_180_days = !is.na(Jurisdiction)) %>%
  dplyr::select(Grattan_record, State_election_within_180_days) %>%
  setkey(Grattan_record) %>%
  unique

state_elections_365_days <-
  state_elections[project_dataset_t, roll=-365] %>%
  mutate(State_election_within_365_days = !is.na(Jurisdiction), 
         State_election_qtr = Election_qtr, 
         State_election_date = Election_date) %>%
  dplyr::select(Grattan_record, State_election_within_365_days, State_election_date, State_election_qtr) %>%
  setkey(Grattan_record) %>%
  unique

# Now we join the State election variables to the main project dataset

project_dataset_t %>%
  setkey(Grattan_record)

project_dataset_t <- 
  merge(project_dataset_t, state_elections_90_days, all.x = TRUE) 

project_dataset_t <- 
  merge(project_dataset_t, state_elections_180_days, all.x = TRUE) 

project_dataset_t <- 
  merge(project_dataset_t, state_elections_365_days, all.x = TRUE) 

project_dataset_t %>%
    setkey(Grattan_record) %>%     unique %>%
  group_by(State_election_within_90_days, State_election_within_180_days, State_election_within_365_days) %>%
  summarise(n = n())

# Creating election variables part 2: Elections won by incumbents ### ----

# First we need to import the list of CW and State elections that Lucille has prepared.

#incumbent_won_elections <- read_excel("../../Data sources/IM/Dates of incumbent won state and federal elections.xlsx", sheet = 1, col_names = TRUE)


# We re-write the date variable to date form, and convert it to the end of the quarter to align with the IM dataset
incumbent_won_elections %<>%
  mutate(incumbent_won_Election_date  = as.Date(Date, format = "%d %b %Y"),
         incumbent_won_Election_qtr = as.Date(as.yearqtr(incumbent_won_Election_date, format = "%d %b %Y"), frac = 1), 
         Date_first_as_Committed = incumbent_won_Election_qtr) %>%
  as.data.table

# Now we define the relevant election variables we're interested in

# Now we write a variable for whether the first quarter in which a project is classified as committed is within 90, 180 or 365 days of a recent CW or state election

# Here we use a rolling join

# Set keys for the rolling join
setkey(incumbent_won_elections, Date_first_as_Committed)
setkey(project_dataset_t, Date_first_as_Committed)

# We do the CW elections first
incumbent_won_federal_elections <- incumbent_won_elections[Jurisdiction == "Federal"]

incumbent_won_federal_elections_90_days <-
  incumbent_won_federal_elections[project_dataset_t, roll=-90] %>%
  mutate(incumbent_won_CW_election_within_90_days = !is.na(Jurisdiction)) %>%
  dplyr::select(Grattan_record, incumbent_won_CW_election_within_90_days) %>%
  setkey(Grattan_record) %>%
  unique

incumbent_won_federal_elections_180_days <-
  incumbent_won_federal_elections[project_dataset_t, roll=-180] %>%
  mutate(incumbent_won_CW_election_within_180_days = !is.na(Jurisdiction)) %>%
  dplyr::select(Grattan_record, incumbent_won_CW_election_within_180_days) %>%
  setkey(Grattan_record) %>%
  unique

incumbent_won_federal_elections_365_days <-
  incumbent_won_federal_elections[project_dataset_t, roll=-365] %>%
  mutate(incumbent_won_CW_election_within_365_days = !is.na(Jurisdiction), 
         incumbent_won_CW_election_date = incumbent_won_Election_date, 
         incumbent_won_CW_election_qtr = incumbent_won_Election_qtr) %>%
  dplyr::select(Grattan_record, incumbent_won_CW_election_within_365_days, incumbent_won_CW_election_date, incumbent_won_CW_election_qtr) %>%
  setkey(Grattan_record) %>%
  unique

# Now we join the CW election variables to the main project dataset

project_dataset_t %>%
  setkey(Grattan_record)

project_dataset_t <- 
  merge(project_dataset_t, incumbent_won_federal_elections_90_days, all.x = TRUE) 

project_dataset_t <- 
  merge(project_dataset_t, incumbent_won_federal_elections_180_days, all.x = TRUE) 

project_dataset_t <- 
  merge(project_dataset_t, incumbent_won_federal_elections_365_days, all.x = TRUE) 

project_dataset_t %>%
  group_by(incumbent_won_CW_election_within_90_days, incumbent_won_CW_election_within_180_days, incumbent_won_CW_election_within_365_days) %>%
  summarise(n = n())

# Now we do the same for state elections

incumbent_won_state_elections <- incumbent_won_elections[Jurisdiction != "Federal"]

incumbent_won_state_elections %<>%
  mutate(State = Jurisdiction) %>%
  setkey(State, Date_first_as_Committed)

setkey(project_dataset_t, State, Date_first_as_Committed)

incumbent_won_state_elections_90_days <-
  incumbent_won_state_elections[project_dataset_t, roll=-90] %>%
  mutate(incumbent_won_State_election_within_90_days = !is.na(Jurisdiction)) %>%
  dplyr::select(Grattan_record, incumbent_won_State_election_within_90_days) %>%
  setkey(Grattan_record) %>%
  unique

incumbent_won_state_elections_180_days <-
  incumbent_won_state_elections[project_dataset_t, roll=-180] %>%
  mutate(incumbent_won_State_election_within_180_days = !is.na(Jurisdiction)) %>%
  dplyr::select(Grattan_record, incumbent_won_State_election_within_180_days) %>%
  setkey(Grattan_record) %>%
  unique

incumbent_won_state_elections_365_days <-
  incumbent_won_state_elections[project_dataset_t, roll=-365] %>%
  mutate(incumbent_won_State_election_within_365_days = !is.na(Jurisdiction), 
         incumbent_won_State_election_qtr = incumbent_won_Election_qtr, 
         incumbent_won_State_election_date = incumbent_won_Election_date) %>%
  dplyr::select(Grattan_record, incumbent_won_State_election_within_365_days, incumbent_won_State_election_date, incumbent_won_State_election_qtr) %>%
  setkey(Grattan_record) %>%
  unique

# Now we join the State election variables to the main project dataset

project_dataset_t %>%
  setkey(Grattan_record)

project_dataset_t <- 
  merge(project_dataset_t, incumbent_won_state_elections_90_days, all.x = TRUE) 

project_dataset_t <- 
  merge(project_dataset_t, incumbent_won_state_elections_180_days, all.x = TRUE) 

project_dataset_t <- 
  merge(project_dataset_t, incumbent_won_state_elections_365_days, all.x = TRUE) 

project_dataset_t %>%
    setkey(Grattan_record) %>%     unique %>%
  group_by(incumbent_won_State_election_within_90_days, incumbent_won_State_election_within_180_days, incumbent_won_State_election_within_365_days) %>%
  summarise(n = n())

# Creating election variables part 3: Elections not won by the incumbent (ie: "won by the nonincumbent") ### ----

# First we need to import the list of CW and State elections that Lucille has prepared.

#nonincumbent_won_elections <- read_excel("../../Data sources/IM/Dates of nonincumbent won state and federal elections.xlsx", sheet = 1, col_names = TRUE)

unique(nonincumbent_won_elections$Jurisdiction)
unique(project_dataset_t$State)

# We re-write the date variable to date form, and convert it to the end of the quarter to align with the IM dataset
nonincumbent_won_elections %<>%
  mutate(nonincumbent_won_Election_date  = as.Date(Date, format = "%d %b %Y"),
         nonincumbent_won_Election_qtr = as.Date(as.yearqtr(nonincumbent_won_Election_date, format = "%d %b %Y"), frac = 1), 
         Date_first_as_Committed = nonincumbent_won_Election_qtr) %>%
  as.data.table

# Now we define the relevant election variables we're interested in

# Now we write a variable for whether the first quarter in which a project is classified as committed is within 90, 180 or 365 days of a recent CW or state election

# Here we use a rolling join

# Set keys for the rolling join
setkey(nonincumbent_won_elections, Date_first_as_Committed)
setkey(project_dataset_t, Date_first_as_Committed)

# We do the CW elections first
nonincumbent_won_federal_elections <- nonincumbent_won_elections[Jurisdiction == "Federal"]

nonincumbent_won_federal_elections_90_days <-
  nonincumbent_won_federal_elections[project_dataset_t, roll=-90] %>%
  mutate(nonincumbent_won_CW_election_within_90_days = !is.na(Jurisdiction)) %>%
  dplyr::select(Grattan_record, nonincumbent_won_CW_election_within_90_days) %>%
  setkey(Grattan_record) %>%
  unique

nonincumbent_won_federal_elections_180_days <-
  nonincumbent_won_federal_elections[project_dataset_t, roll=-180] %>%
  mutate(nonincumbent_won_CW_election_within_180_days = !is.na(Jurisdiction)) %>%
  dplyr::select(Grattan_record, nonincumbent_won_CW_election_within_180_days) %>%
  setkey(Grattan_record) %>%
  unique

nonincumbent_won_federal_elections_365_days <-
  nonincumbent_won_federal_elections[project_dataset_t, roll=-365] %>%
  mutate(nonincumbent_won_CW_election_within_365_days = !is.na(Jurisdiction), 
         nonincumbent_won_CW_election_date = nonincumbent_won_Election_date, 
         nonincumbent_won_CW_election_qtr = nonincumbent_won_Election_qtr) %>%
  dplyr::select(Grattan_record, nonincumbent_won_CW_election_within_365_days, nonincumbent_won_CW_election_date, nonincumbent_won_CW_election_qtr) %>%
  setkey(Grattan_record) %>%
  unique

# Now we join the CW election variables to the main project dataset

project_dataset_t %>%
  setkey(Grattan_record)

project_dataset_t <- 
  merge(project_dataset_t, nonincumbent_won_federal_elections_90_days, all.x = TRUE) 

project_dataset_t <- 
  merge(project_dataset_t, nonincumbent_won_federal_elections_180_days, all.x = TRUE) 

project_dataset_t <- 
  merge(project_dataset_t, nonincumbent_won_federal_elections_365_days, all.x = TRUE) 

project_dataset_t %>%
    setkey(Grattan_record) %>%     unique %>%
  group_by(nonincumbent_won_CW_election_within_90_days, nonincumbent_won_CW_election_within_180_days, nonincumbent_won_CW_election_within_365_days) %>%
  summarise(n = n())


# Now we do the same for state elections

nonincumbent_won_state_elections <- nonincumbent_won_elections[Jurisdiction != "Federal"]

nonincumbent_won_state_elections %<>%
  mutate(State = Jurisdiction) %>%
  setkey(State, Date_first_as_Committed)

setkey(project_dataset_t, State, Date_first_as_Committed)

nonincumbent_won_state_elections_90_days <-
  nonincumbent_won_state_elections[project_dataset_t, roll=-90] %>%
  mutate(nonincumbent_won_State_election_within_90_days = !is.na(Jurisdiction)) %>%
  dplyr::select(Grattan_record, nonincumbent_won_State_election_within_90_days) %>%
  setkey(Grattan_record) %>%
  unique

nonincumbent_won_state_elections_180_days <-
  nonincumbent_won_state_elections[project_dataset_t, roll=-180] %>%
  mutate(nonincumbent_won_State_election_within_180_days = !is.na(Jurisdiction)) %>%
  dplyr::select(Grattan_record, nonincumbent_won_State_election_within_180_days) %>%
  setkey(Grattan_record) %>%
  unique

nonincumbent_won_state_elections_365_days <-
  nonincumbent_won_state_elections[project_dataset_t, roll=-365] %>%
  mutate(nonincumbent_won_State_election_within_365_days = !is.na(Jurisdiction), 
         nonincumbent_won_State_election_qtr = nonincumbent_won_Election_qtr, 
         nonincumbent_won_State_election_date = nonincumbent_won_Election_date) %>%
  dplyr::select(Grattan_record, nonincumbent_won_State_election_within_365_days, nonincumbent_won_State_election_date, nonincumbent_won_State_election_qtr) %>%
  setkey(Grattan_record) %>%
  unique

# Now we join the State election variables to the main project dataset

project_dataset_t %>%
  setkey(Grattan_record)

project_dataset_t <- 
  merge(project_dataset_t, nonincumbent_won_state_elections_90_days, all.x = TRUE) 

project_dataset_t <- 
  merge(project_dataset_t, nonincumbent_won_state_elections_180_days, all.x = TRUE) 

project_dataset_t <- 
  merge(project_dataset_t, nonincumbent_won_state_elections_365_days, all.x = TRUE) 

project_dataset_t %>%
    setkey(Grattan_record) %>%     unique %>%
  group_by(nonincumbent_won_State_election_within_90_days, nonincumbent_won_State_election_within_180_days, nonincumbent_won_State_election_within_365_days) %>%
  summarise(n = n())

project_dataset_t %>%
    setkey(Grattan_record) %>%     unique %>%
  group_by(nonincumbent_won_State_election_within_90_days, nonincumbent_won_State_election_within_180_days, nonincumbent_won_State_election_within_365_days) %>%
  summarise(n = n())


# So we have 1 projects within 90 days of a state election, 9 projects within 180 days, and 16 projects within 365 days

#* Checking the quality of the project_dataset_t data (corr between final cost and final cost historical): ----


# Testing correlation between final cost and final cost historical - chat with Deloitte
project_dataset_t_cor <-
  project_dataset_t %>%
  filter(`Sub-industry` == "Road" | `Sub-industry` == "Rail") %>%
  filter(Public_project_Grattan == 1) %>%
  filter(Initial_cost != 0) %>%
  filter(Final_matching_status != "Possible - Completed" & Final_matching_status != "Committed - Completed" & Final_matching_status != "Under consideration - Completed") %>%
  filter(Final_status_historical == "Completed")

test_correlation <- cor(project_dataset_t_cor$Final_cost_historical, project_dataset_t_cor$Final_cost)
final_cost_differences<-project_dataset_t_cor$Final_cost_historical - project_dataset_t_cor$Final_cost
table(final_cost_differences)

#* Analysis >>>>>>>>>>>>  Descriptive Statistics, project_dataset_t:  --------------------------

# Summary statistics for Deloitte dataset
# Note: pdt in the table names stands for "Project_dataset_t"


# Table 0 - Number of projects that enter and exit the dataset at each stage:
Initial_statuses <-
  project_dataset_t %>%
  filter(Final_status_historical != "NA") %>%
  arrange(Initial_status) %>%
  group_by(Initial_status) %>%
  summarise(no_projects = n()) %>%
  spread(Initial_status, no_projects)  

#Final_statuses <-
#  project_dataset_plus%>%
#  setkey(Grattan_record) %>%     
#  unique %>%
#  filter(`Major industry` == "Transport & Storage") %>%
#  group_by(Final_matching_status) %>%
#  summarise(no_projects = n()) %>%
#spread(Final_matching_status, no_projects)

Final_statuses_of_deleted <-
  project_dataset_t %>%
  filter(Final_status_historical == "Deleted") %>%
  arrange(Final_status) %>%
  group_by(Final_status) %>%
  summarise(no_projects = n()) %>%
  spread(Final_status, no_projects)  

SS_pdt_table_0 <-data.frame(variable = c("Entry", "Deletion stage"), rbind(Initial_statuses, Final_statuses_of_deleted))

# Table 1 - Completed projects - split by initial status and mode
SS_pdt_table_1 <-
  project_dataset_t %>%
  arrange(Matching_status) %>%
  filter(Final_status_historical == "Completed") %>%
  group_by(`Sub-industry`, Matching_status) %>%
  summarise(no_projects = n()) %>%
  spread(Matching_status, no_projects)  %>%
  setkey(`Sub-industry`)


# Note on Table 2: Dataset includes some projects that transition directly from possible and other earlt stages directly to 'Completed' in the final historical dataset. We are going to chase this with SS from Deloitte and possibly manually re-classify. 

# Table 2 - Deleted projects - split by initial status and mode
SS_pdt_table_2 <-
  project_dataset_t %>%
  arrange(Matching_status) %>%
  filter(Final_status_historical == "Deleted") %>%
  group_by(`Sub-industry`, Matching_status) %>%
  summarise(no_projects = n()) %>%
  spread(Matching_status, no_projects) %>%
  setkey(`Sub-industry`)

# Table 3 - Completed projects - split by mode and state

SS_pdt_table_3 <-  
  project_dataset_t %>%
  filter(Final_status_historical== "Completed") %>%
  group_by(`Sub-industry`, State_new) %>%
  summarise(no_projects = n()) %>%
  spread(State_new, no_projects) %>%
  setkey(`Sub-industry`)

# Table 4 - Completed projects - split by mode and state

SS_pdt_table_4 <-  
  project_dataset_t %>%
  filter(Final_status_historical== "Deleted") %>%
  group_by(`Sub-industry`, State_new) %>%
  summarise(no_projects = n()) %>%
  spread(State_new, no_projects) %>%
  setkey(`Sub-industry`)


# Export these summary statistics to excel

# Lucille's zipping Rtool wouldn't work properly. This is the code used to redirect R to the tool, in case the problem reoccurs: Sys.setenv(R_ZIPCMD= "C:/R/Rtools/bin/zip") 

#Summary_statistics_project_dataset_t <- createWorkbook()
#addWorksheet(Summary_statistics_project_dataset_t, "Entry.exit X status")
#addWorksheet(Summary_statistics_project_dataset_t, "Mode X initial status, comp")
#addWorksheet(Summary_statistics_project_dataset_t, "Mode X initial status, del")
#addWorksheet(Summary_statistics_project_dataset_t, "Mode X state, comp")
#addWorksheet(Summary_statistics_project_dataset_t, "Mode3 X state, del")
#writeData(Summary_statistics_project_dataset_t, 1, SS_pdt_table_0)
#writeData(Summary_statistics_project_dataset_t, 2, SS_pdt_table_1)
#writeData(Summary_statistics_project_dataset_t, 3, SS_pdt_table_2)
#writeData(Summary_statistics_project_dataset_t, 4, SS_pdt_table_3)
#writeData(Summary_statistics_project_dataset_t, 5, SS_pdt_table_4)
#saveWorkbook(Summary_statistics_project_dataset_t, file = "../Spreadsheets/Deloitte pipeline analysis outputs/Summary statistics project_dataset_t.xlsx", overwrite = TRUE)

#* Analysis >>>>>>>>>>>>  Survival curves -----------------------------------

# Group 1.1 survival curves

g1.1_suvival_curve_data<-
  project_dataset_t %>%
  arrange(Final_status_historical, Final_status) %>%
  filter(Initial_status == "Possible") %>%
  group_by(Final_status_historical == "Deleted", Final_status) %>%
  summarise(no_projects_G11 = n()) 

# Group 1.2 survival curves

g1.2_suvival_curve_data<-
  project_dataset_t %>%
  arrange(Final_status_historical, Final_status) %>%
  filter(Initial_status == "Under consideration") %>%
  group_by(Final_status_historical == "Deleted", Final_status) %>%
  summarise(no_projects_G12 = n()) 

# Group 2 survival curves

g2_suvival_curve_data<-
  project_dataset_t %>%
  arrange(Final_status_historical, Final_status) %>%
  filter(Initial_status == "Committed") %>%
  group_by(Final_status_historical == "Deleted", Final_status) %>%
  summarise(no_projects_G2 = n()) 

# Group 3 survival curves

g3_suvival_curve_data<-
  project_dataset_t %>%
  arrange(Final_status_historical, Final_status) %>%
  filter(Initial_status == "Under construction") %>%
  group_by(Final_status_historical == "Deleted", Final_status) %>%
  summarise(no_projects_G3 = n()) 

# Surival figures needed for report outputs:
n_projects_deleted_t1<-
  project_dataset_t %>% 
  filter(Initial_status=="Possible" | Initial_status=="Under consideration") %>% 
  filter(Final_status_historical =="Deleted") %>% 
  filter(Final_status == "Possible" | Final_status == "Under consideration") %>% 
  nrow  

n_projects_deleted_t2<-
project_dataset_t %>% 
  filter(Initial_status=="Possible" | Initial_status=="Under consideration" | Initial_status=="Committed") %>% 
  filter(Final_status_historical =="Deleted") %>% 
  filter(Final_status == "Committed") %>% 
  nrow  

n_projects_deleted_t3<-
project_dataset_t %>% 
  filter(Final_status_historical =="Deleted") %>% 
  filter(Final_status == "Under construction") %>% 
  nrow  

n_projects_t1<-project_dataset_t %>% filter(Initial_status=="Possible" | Initial_status=="Under consideration") %>% nrow
n_projects_t2<-project_dataset_t %>% filter(Initial_status=="Possible" | Initial_status=="Under consideration" | Initial_status=="Committed") %>% nrow - n_projects_deleted_t1
n_projects_t3<-project_dataset_t %>% filter(Initial_status=="Possible" | Initial_status=="Under consideration" | Initial_status=="Committed" | Initial_status=="Under construction") %>% nrow - n_projects_deleted_t1 - n_projects_deleted_t2

pc_cancelled_t1<-n_projects_deleted_t1/n_projects_t1
pc_cancelled_t2<-n_projects_deleted_t2/n_projects_t2
pc_cancelled_t3<-n_projects_deleted_t3/n_projects_t3

cancellation_rate_by_stage<-data.frame(Project_stage = c("Possible and under consideration", "Committed", "Under construction"), 
           Cancellation_rate = c(pc_cancelled_t1, pc_cancelled_t2, pc_cancelled_t3))

pc_cancelled_g1<- 1- nrow(co_g1)/(project_dataset_t %>% filter(Initial_status == "Possible" | Initial_status == "Under consideration") %>% nrow)
pc_cancelled_g2<- 1- nrow(co_g2)/(project_dataset_t %>% filter(Initial_status == "Committed") %>% nrow)
pc_cancelled_g3<- 1- nrow(co_g3)/(project_dataset_t %>% filter(Initial_status == "Under construction") %>% nrow)

cancellation_rate_by_cohort <-data.frame(First_project_stage = c("Possible and under consideration", "Committed", "Under construction"), 
           Cancellation_rate = c(pc_cancelled_g1, pc_cancelled_g2, pc_cancelled_g3))
  
  
# Export the survival curve data to excel... after the next section...

# I think this code can be deleted. 
#Final_matching_status_summary <- createWorkbook()
#addWorksheet(Final_matching_status_summary, "Summary")
#writeData(Final_matching_status_summary, 1, table(project_dataset_t_C$Final_matching_status))
#saveWorkbook(Final_matching_status_summary, file = "../Spreadsheets/Deloitte pipeline analysis outputs/Final_matching_status_summary.xlsx", overwrite = TRUE)

# Superfluous:
#pc_projects_completed<-(co_all%>% summarise(n()))/(project_dataset_t%>% summarise(n()))
#pc_projects_completed_w_initial_status_possible <- (co_all %>% filter(Matching_status_numeric == 1) %>% summarise(n()))/(project_dataset_t %>% filter(Initial_status == "Possible") %>% summarise(n()))
#pc_projects_completed_w_initial_status_under_consideration <- (co_all %>% filter(Matching_status_numeric == 2) %>% summarise(n()))/(project_dataset_t %>% filter(Initial_status == "Under consideration") %>% summarise(n()))
#pc_projects_completed_w_initial_status_committed <- (co_all %>% filter(Matching_status_numeric == 3) %>% summarise(n()))/(project_dataset_t %>% filter(Initial_status == "Committed") %>% summarise(n()))
#pc_projects_completed_w_initial_status_under_construction <- (co_all %>% filter(Matching_status_numeric == 4) %>% summarise(n()))/(project_dataset_t %>% filter(Initial_status == "Under construction") %>% summarise(n()))

#* Analysis >>>>>>>>>>>>  Cost overruns and project survival: -----

# How should I do this?

    # Step 1: generate survival variables for each stage

project_dataset_t_subgroup1<-
  project_dataset_t %>%
  filter(Initial_status == "Possible") %>%
  mutate(Survived_01 = ifelse(Final_matching_status == "Possible - Deleted", 0, 1), 
         Survival_analysis_co_01 = ifelse(Survived_01 == 1, Under_consideration_cost_over_initial, Final_cost_over_initial))
  
project_dataset_t_subgroup2<-
  project_dataset_t %>%
  filter(Initial_status == "Possible" | Initial_status == "Under consideration" ) %>%
  filter(Final_matching_status != "Possible - Deleted") %>%
  mutate(Survived_12 = ifelse(Final_matching_status == "Under consideration - Deleted", 0, 1), 
         Survival_analysis_co_02 = ifelse(Survived_12 == 1, Committed_cost_over_initial, Final_cost_over_initial))

project_dataset_t_subgroup3<-
  project_dataset_t %>%
  filter(Initial_status == "Possible" | Initial_status == "Under consideration" | Initial_status == "Committed") %>%
  filter(Final_matching_status != "Possible - Deleted" & Final_matching_status != "Under consideration - Deleted") %>%
  mutate(Survived_23 = ifelse(Final_matching_status == "Committed - Deleted", 0, 1), 
         Survival_analysis_co_03 = ifelse(Survived_23 == 1, Under_construction_cost_over_initial, Final_cost_over_initial))

project_dataset_t_subgroup4<-
  project_dataset_t %>%
  filter(Final_matching_status != "Possible - Deleted" & Final_matching_status != "Under consideration - Deleted" | Final_matching_status != "Committed - Deleted") %>%
  mutate(Survived_34 = ifelse(Final_matching_status == "Under construction - Deleted", 0, 1),
         Survival_analysis_co_04 = Final_cost_over_initial) 
  
    # Step 2: estimate the correlations between cost overruns and survival:
  #reg_SA_01 = glm(Survived_01~ Survival_analysis_co_01, family = binomial(link = "logit"), data = project_dataset_t_subgroup1)
  #ME_reg_SA_01 <-logitmfx(reg_SA_01, data = project_dataset_t_subgroup1)
  #ME_reg_SA_01
  reg_SA_02 = glm(Survived_12~ Survival_analysis_co_02, family = binomial(link = "logit"), data = project_dataset_t_subgroup2)
  ME_reg_SA_02 <-logitmfx(reg_SA_02, data = project_dataset_t_subgroup2)
  ME_reg_SA_02
  reg_SA_03 = glm(Survived_23~ Survival_analysis_co_03, family = binomial(link = "logit"), data = project_dataset_t_subgroup3)
  ME_reg_SA_03 <-logitmfx(reg_SA_03, data = project_dataset_t_subgroup3)
  ME_reg_SA_03
  #reg_SA_04 = glm(Survived_34~ Survival_analysis_co_04, family = binomial(link = "logit"), data = project_dataset_t_subgroup4)
  #ME_reg_SA_04 <-logitmfx(reg_SA_04, data = project_dataset_t_subgroup4)
 # ME_reg_SA_04
  
  # There's a trick here: reg_SA_01 and reg_SA_04 predict perfectly. 
  #It won't give me an output, because, in this sitation, the coefficient estimates will be inflated.
  # To get around this, I use the methodology proposed in: Firth (1993), "Bias reduction of maximum likelihood estimates", Biometrika, 80,1.; which removes the first-order bias from maximum likelihood estimates.
  reg_SA_01<-logistf(Survived_01~ Survival_analysis_co_01, data = project_dataset_t_subgroup1, pl = TRUE, alpha = 0.05, firth = TRUE) # NOTE: THIS IS NOT A MARGINAL EFFECT!! JUST A COEFFICIENT.
  reg_SA_01_coeff_results<-
    data.frame("dF/dx" = reg_SA_01$coefficients[2], "Std. Err." = sqrt(reg_SA_01$var[2,2]), "z"=reg_SA_01$coefficients[2]/sqrt(reg_SA_01$var[2,2]), "P>|z|" = reg_SA_01$prob[2], check.names = FALSE) # NOTE: THIS IS NOT A MARGINAL EFFECT!! JUST A COEFFICIENT. So "dy/dx" is misleading.
  reg_SA_04<-logistf(Survived_34~ Survival_analysis_co_04, data = project_dataset_t_subgroup4, pl = TRUE, alpha = 0.05, firth = TRUE) # NOTE: THIS IS NOT A MARGINAL EFFECT!! JUST A COEFFICIENT.
  reg_SA_04_coeff_results<-
    data.frame("dF/dx" = reg_SA_04$coefficients[2], "Std. Err." = sqrt(reg_SA_04$var[2,2]), "z"=reg_SA_04$coefficients[2]/sqrt(reg_SA_04$var[2,2]), "P>|z|" = reg_SA_04$prob[2], check.names = FALSE) # NOTE: THIS IS NOT A MARGINAL EFFECT!! JUST A COEFFICIENT. So "dy/dx" is misleading.
  
# This table lists the marginal effects of the cumulative cost overruns observed up to each stage, on the probability of surviving each stage 
  surv_co_analysis <- data.frame(Reg_results = c("reg_SA_01", "reg_SA_02", "reg_SA_03", "reg_SA_04"),
                                   rbind("reg_SA_01" = reg_SA_01_coeff_results, "reg_SA_02" = ME_reg_SA_02$mfxest, "reg_SA_03" = ME_reg_SA_03$mfxest, "reg_SA_04" = reg_SA_04_coeff_results))
  
  #Survival_curve_data <- createWorkbook()
  #addWorksheet(Survival_curve_data, "Group 1.1")
  #addWorksheet(Survival_curve_data, "Group 1.2")
  #addWorksheet(Survival_curve_data, "Group 2")
  #addWorksheet(Survival_curve_data, "Group3")
  #addWorksheet(Survival_curve_data, "COs and survival")
  #writeData(Survival_curve_data, 1, g1.1_suvival_curve_data)
  #writeData(Survival_curve_data, 2, g1.2_suvival_curve_data)
  #writeData(Survival_curve_data, 3, g2_suvival_curve_data)
  #writeData(Survival_curve_data, 4, g3_suvival_curve_data)
  #writeData(Survival_curve_data, 5, surv_co_analysis)
  #saveWorkbook(Survival_curve_data, file = "../Spreadsheets/Deloitte pipeline analysis outputs/Survival_curve_data.xlsx", overwrite = TRUE) 
  

  

  

  
  
  
  
  
# ~~~~~ NOTE: AM and GM are short for arithmetic and geometric mean ~~~~~ #   
  
  
  
  
  
  
  
  
  
  
  
  

######################## Sub setting the dataset to the datasets used for the cost overruns analysis: ********* "co_all" and variations ********-----

co_all <- 
  project_dataset_t %>%
  filter(Final_status_historical == 'Completed')

co_g1 <-
  co_all %>%
  filter(Matching_status == "Possible - Completed" | Matching_status == "Under consideration - Completed" )


co_g2 <-
  co_all %>%
  filter(Matching_status == "Committed - Completed")

co_g3 <-
  co_all %>%
  filter(Matching_status == "Under construction - Completed")

co_g1g2 <-
  co_all %>%
  filter(Matching_status_numeric<=3)


co_all %<>%
mutate(Matching_status_numeric = if_else(Matching_status == "Possible - Completed", 1, 
                                  if_else(Matching_status == "Under consideration - Completed", 2,
                                          if_else(Matching_status == "Committed - Completed", 3, 4))))

# Writing filled cost series' (assuming NO OVERRUN if not observed), for use in indices: ----
# Note: "_a_z" is shorthand for Assuming Zero overrun if no earlier cost is recorded.  

co_all %<>%
  mutate(First_cost_when_under_construction_a_z = First_cost_when_under_construction,
         First_cost_when_Committed_a_z = if_else(Matching_status_numeric <= 3, First_cost_when_Committed, First_cost_when_under_construction ),
         First_cost_when_Possible_or_under_consideration_a_z = Initial_cost, 
         First_cost_when_Possible_or_under_consideration_a_z_real = Initial_cost_real)

# Alternatively, one could define First_cost_when_Possible_or_under_consideration_a_z using a similar process. 
# This is flawed because a couple of projects (4) become less mature at some point. So "Initial" is earlier than first cost when possible. 
      #First_cost_when_Possible_or_under_consideration_a_z = if_else(Matching_status_numeric<=2, First_cost_when_Possible_or_under_consideration, First_cost_when_Committed_a_z), 
      #First_cost_when_Possible_or_under_consideration_a_z_real = if_else(Matching_status_numeric<=2, First_cost_when_Possible_or_under_consideration_real,
      #                                                                   if_else(Matching_status_numeric==3, First_cost_when_Committed_real, First_cost_when_under_construction_real)))


# Comparing the a_z variables to the "initial"
#cost_def_difference<- co_all$First_cost_when_Possible_or_under_consideration_a_z - co_all$Initial_cost
#table(cost_def_difference)
#problem_observations<-
#  co_all %>%
#  filter(cost_def_difference != 0) %>%
#  summarise(Grattan_record, Project, Final_cost_over_initial, Initial_cost, First_cost_when_Possible_or_under_consideration, First_cost_when_Committed, First_cost_when_under_construction, Final_cost, First_qtr_in_dataset, Date_first_as_Possible, `Date_first_as_Under consideration`, Date_first_as_Committed, `Date_first_as_Under construction` )
#View(problem_observations) # This reveals that Initial_cost's definition is wrong in four cases..  

# Writing filled cost series' (assuming average overrun if not observed), for use in indices: -----

# Construct the cost series that assume the average overrun when not observed. 
# (This involves calculating the average project_level overruns observed amoung the observations for which we have full data): 
cog1<-
  co_all%>% 
  filter(Matching_status_numeric <= 2) %>%
  mutate(total_projects = n()) %>%
  mutate(co12 = sum((First_cost_when_Committed - First_cost_when_Possible_or_under_consideration)/First_cost_when_Possible_or_under_consideration*(1/total_projects)))%>%
  dplyr::select(co12) %>%
  unique 

cog1g2<-
  co_all %>%
  filter(Matching_status_numeric <= 3) %>%
  mutate(total_projects = n()) %>%
  mutate(First_cost_when_Possible_or_under_consideration_a_a = if_else(Matching_status_numeric<=2, First_cost_when_Possible_or_under_consideration, First_cost_when_Committed/(1+cog1$co12)),
         First_cost_when_Possible_or_under_consideration_a_a_real = if_else(Matching_status_numeric<=2, First_cost_when_Possible_or_under_consideration_real, First_cost_when_Committed_real/(1+cog1$co12))) %>%
  mutate(co12 = sum((First_cost_when_Committed - First_cost_when_Possible_or_under_consideration_a_a)/First_cost_when_Possible_or_under_consideration_a_a*(1/total_projects)),
         co23 = sum((First_cost_when_under_construction - First_cost_when_Committed)/First_cost_when_Possible_or_under_consideration_a_a)*(1/total_projects), 
         co13 = sum((First_cost_when_under_construction - First_cost_when_Possible_or_under_consideration_a_a)/First_cost_when_Possible_or_under_consideration_a_a*(1/total_projects))) %>%
  dplyr::select(co12, co23, co13) %>%
  unique

co_all %<>%
  mutate(total_projects = n()) %>%
  mutate(First_cost_when_under_construction_a_a = First_cost_when_under_construction,
         First_cost_when_Committed_a_a = if_else(Matching_status_numeric <=3, First_cost_when_Committed, First_cost_when_under_construction/(1+cog1g2$co23)), 
         First_cost_when_Possible_or_under_consideration_a_a = if_else(Matching_status_numeric ==4, First_cost_when_under_construction/(1+cog1g2$co13), 
                                                                       if_else(Matching_status_numeric == 3, First_cost_when_Committed_a_a/(1+cog1g2$co12), First_cost_when_Possible_or_under_consideration)),
         First_cost_when_Possible_or_under_consideration_a_a_real = if_else(Matching_status_numeric ==4, First_cost_when_under_construction_real/(1+cog1g2$co13), 
                                                                            if_else(Matching_status_numeric == 3, First_cost_when_Committed_real/(1+cog1g2$co12), First_cost_when_Possible_or_under_consideration_real)))

# Writing miscellanous variables to the co_all dataset: -----

# Subsetting the data into that pertaining to road and rail projects:
co_all_road <-
  co_all %>%
  filter(`Sub-industry` == "Road")
co_all_rail <-
  co_all %>%
  filter(`Sub-industry` == "Rail")

# Total number of projects:
co_all %<>%
  mutate (total_no_projects = n()) 

co_g1 %<>%
  mutate (total_no_projects = n()) 

co_g2 %<>%
  mutate (total_no_projects = n()) 

co_g3 %<>%
  mutate (total_no_projects = n()) 

# Number of projects in each group (defined by "matching status")
co_all %<>%
  group_by(Matching_status) %>%
  mutate (no_projects_by_matching_status = n()) 

# Total value of cost overruns 
co_all %<>%
  mutate(value_co =  Final_cost_real - Initial_cost_real) %>%
  mutate(total_value_co = sum(value_co))

co_all_road %<>%
  mutate(value_co =  Final_cost_real - Initial_cost_real) %>%
  mutate(total_value_co = sum(value_co))

co_all_rail %<>%
  mutate(value_co =  Final_cost_real - Initial_cost_real) %>%
  mutate(total_value_co = sum(value_co)) 

#Misc:
co_all %<>%
  mutate(Possible_to_completed = ifelse(Matching_status == "Possible - Completed", 1, 0), 
         Under_consideration_to_completed = ifelse(Matching_status == "Under consideration - Completed", 1, 0), 
         Committed_to_completed = ifelse(Matching_status == "Committed - Completed", 1, 0), 
         Under_construction_to_completed = ifelse(Matching_status == "Under construction - Completed", 1, 0))

co_all %<>%
  mutate(State_new_factor = factor(State_new), 
         Matching_status_factor = factor(Matching_status),
         Matching_status_numeric = ifelse(Possible_to_completed==1, 1, 
                                          ifelse(Under_consideration_to_completed==1, 2, 
                                                 ifelse(Committed_to_completed==1, 3, 4))),
         Sub_industry_factor = factor(`Sub-industry`))

co_all %<>%
  mutate(on_budget = ifelse(Final_cost_over_initial == 1, 1, 0),
         total_cost = sum(Final_cost_real),
         experienced_overrun = ifelse(Final_cost_over_initial > 1, 1, 0),
         experienced_overrun_t1 = ifelse(Committed_cost_over_Possible_or_under_consideration > 1, 1, 0),
         experienced_overrun_t2 = ifelse(Under_construction_cost_over_committed > 1, 1, 0),
         experienced_overrun_t3 = ifelse(Final_cost_over_under_construction > 1, 1, 0),
         log_Total_days_pre_construction= dplyr::if_else(Total_days_pre_construction > 0, log(abs(Total_days_pre_construction)), 0, missing = 0), 
         #log_Total_days_pre_construction= ifelse(is.na(Total_days_pre_construction), 0, ifelse(Total_days_pre_construction ==0, 0, log(Total_days_pre_construction))), 
         big_states = ifelse(State_new == "New South Wales", "New South Wales", 
                             ifelse(State_new == "Queensland", "Queensland", 
                                    ifelse(State_new == "Victoria", "Victoria",
                                           ifelse(State_new == "Western Australia", "Western Australia", "Smaller states") ))),
         Road = ifelse(`Sub-industry`=="Road", 1, 0))


#testing<-
#co_all %>%
# mutate(total_cost = sum(Final_cost_real)) %>%
# filter(Final_cost_over_under_construction>1) %>%
# mutate(total_cost_t3 = sum(Final_cost_real)) %>%
# filter(Matching_status_numeric<4 & Under_construction_cost_over_committed>1)%>%
# mutate(total_cost_t2 = sum(Final_cost_real)) %>%
# filter(Matching_status_numeric<3 & Committed_cost_over_Possible_or_under_consideration >1) %>%
# mutate(total_cost_t1 = sum(Final_cost_real))

# Cost overruns: How big do we expect them to be? (top down calcs) -----

# Initial to final, portfolio level (assuming zero overrun):
(sum(co_all$Final_cost_real)-sum(co_all$First_cost_when_Possible_or_under_consideration_a_z_real))/sum(co_all$First_cost_when_Possible_or_under_consideration_a_z_real)

# Initial to final, project level (assuming zero overrun):
mean((co_all$Final_cost - co_all$First_cost_when_Possible_or_under_consideration_a_z)/co_all$First_cost_when_Possible_or_under_consideration_a_z)
#.. which is a trivial difference. 

# Initial to final, portfolio level (assuming average overrun):
(sum(co_all$Final_cost_real)-sum(co_all$First_cost_when_Possible_or_under_consideration_a_a_real))/sum(co_all$First_cost_when_Possible_or_under_consideration_a_a_real)

# Initial to final, project level (assuming average overrun):
mean((co_all$Final_cost - co_all$First_cost_when_Possible_or_under_consideration_a_a)/co_all$First_cost_when_Possible_or_under_consideration_a_a)
#.. which, again, is a trivial difference. 
# The assumption regarding average or zero overrun leads to a ~10% difference. 

# PROJECT level cost overrun indices, assuming NO OVERRUN if not observed ----
# Note: standard error of an arithmetic mean = sd(x) /sqrt (n)

#All: Road and rail
co_all_indices_AM<-
  co_all%>% 
  mutate(total_projects = n()) %>%
  mutate(co12 = sum((First_cost_when_Committed_a_z - First_cost_when_Possible_or_under_consideration_a_z)/First_cost_when_Possible_or_under_consideration_a_z*(1/total_projects)),
         co23 = sum((First_cost_when_under_construction_a_z - First_cost_when_Committed_a_z)/First_cost_when_Possible_or_under_consideration_a_z*(1/total_projects)),
         co34 = sum((Final_cost - First_cost_when_under_construction_a_z)/First_cost_when_Possible_or_under_consideration_a_z*(1/total_projects)),
         co13 = sum((First_cost_when_under_construction_a_z - First_cost_when_Possible_or_under_consideration_a_z)/First_cost_when_Possible_or_under_consideration_a_z*(1/total_projects)),
         co14 = sum((Final_cost - First_cost_when_Possible_or_under_consideration_a_z)/First_cost_when_Possible_or_under_consideration_a_z*(1/total_projects)),
         co24 = sum((Final_cost - First_cost_when_Committed_a_z)/First_cost_when_Possible_or_under_consideration_a_z*(1/total_projects)),
         se_co12 = sd((First_cost_when_Committed_a_z - First_cost_when_Possible_or_under_consideration_a_z)/First_cost_when_Possible_or_under_consideration_a_z)/sqrt(total_projects),
         se_co23 = sd((First_cost_when_under_construction_a_z - First_cost_when_Committed_a_z)/First_cost_when_Possible_or_under_consideration_a_z)/sqrt(total_projects),         
         se_co34 = sd((Final_cost - First_cost_when_under_construction_a_z)/First_cost_when_Possible_or_under_consideration_a_z)/sqrt(total_projects),         
         se_co13 = sd((First_cost_when_under_construction_a_z - First_cost_when_Possible_or_under_consideration_a_z)/First_cost_when_Possible_or_under_consideration_a_z)/sqrt(total_projects),
         se_co14 = sd((Final_cost - First_cost_when_Possible_or_under_consideration_a_z)/First_cost_when_Possible_or_under_consideration_a_z)/sqrt(total_projects),         
         se_co24 = sd((Final_cost - First_cost_when_Committed_a_z)/First_cost_when_Possible_or_under_consideration_a_z)/sqrt(total_projects))%>%
  dplyr::select(co12, se_co12, co13, se_co13, co14, se_co14, co23, se_co23, co24, se_co24, co34, se_co34) %>%
  unique

# Checking for internal consistency:
ifelse(co_all_indices_AM$co12+co_all_indices_AM$co23+co_all_indices_AM$co34 - co_all_indices_AM$co14 == 0, "PASS: the indices add up correctly", "FAIL: investigate this...")
ifelse(mean((co_all$Final_cost - co_all$First_cost_when_Possible_or_under_consideration_a_z)/co_all$First_cost_when_Possible_or_under_consideration_a_z) - co_all_indices_AM$co14 == 0, "PASS: the indices correspond with the top down calc", "FAIL: investigate this...")

#Road

co_all_road_indices_AM<-
  co_all_road%>% 
  mutate(total_projects = n()) %>%
  mutate(co12 = sum((First_cost_when_Committed_a_z - First_cost_when_Possible_or_under_consideration_a_z)/First_cost_when_Possible_or_under_consideration_a_z*(1/total_projects)),
         co23 = sum((First_cost_when_under_construction_a_z - First_cost_when_Committed_a_z)/First_cost_when_Possible_or_under_consideration_a_z*(1/total_projects)),
         co34 = sum((Final_cost - First_cost_when_under_construction_a_z)/First_cost_when_Possible_or_under_consideration_a_z*(1/total_projects)),
         co13 = sum((First_cost_when_under_construction_a_z - First_cost_when_Possible_or_under_consideration_a_z)/First_cost_when_Possible_or_under_consideration_a_z*(1/total_projects)),
         co14 = sum((Final_cost - First_cost_when_Possible_or_under_consideration_a_z)/First_cost_when_Possible_or_under_consideration_a_z*(1/total_projects)),
         co24 = sum((Final_cost - First_cost_when_Committed_a_z)/First_cost_when_Possible_or_under_consideration_a_z*(1/total_projects))) %>%
  dplyr::select(co12, co13, co14, co23, co24, co34) %>%
  unique

# Checking for internal consistency:
ifelse(co_all_road_indices_AM$co12+co_all_road_indices_AM$co23+co_all_road_indices_AM$co34 - co_all_road_indices_AM$co14 == 0, "PASS: the indices add up correctly", "FAIL: investigate this...")
ifelse(round(mean((co_all_road$Final_cost - co_all_road$First_cost_when_Possible_or_under_consideration_a_z)/co_all_road$First_cost_when_Possible_or_under_consideration_a_z) - co_all_road_indices_AM$co14,7) == 0, "PASS: the indices correspond with the top down calc", "FAIL: investigate this...")

#Rail

co_all_rail_indices_AM<-
  co_all_rail%>% 
  mutate(total_projects = n()) %>%
  mutate(co12 = sum((First_cost_when_Committed_a_z - First_cost_when_Possible_or_under_consideration_a_z)/First_cost_when_Possible_or_under_consideration_a_z*(1/total_projects)),
         co23 = sum((First_cost_when_under_construction_a_z - First_cost_when_Committed_a_z)/First_cost_when_Possible_or_under_consideration_a_z*(1/total_projects)),
         co34 = sum((Final_cost - First_cost_when_under_construction_a_z)/First_cost_when_Possible_or_under_consideration_a_z*(1/total_projects)),
         co13 = sum((First_cost_when_under_construction_a_z - First_cost_when_Possible_or_under_consideration_a_z)/First_cost_when_Possible_or_under_consideration_a_z*(1/total_projects)),
         co14 = sum((Final_cost - First_cost_when_Possible_or_under_consideration_a_z)/First_cost_when_Possible_or_under_consideration_a_z*(1/total_projects)),
         co24 = sum((Final_cost - First_cost_when_Committed_a_z)/First_cost_when_Possible_or_under_consideration_a_z*(1/total_projects))) %>%
  dplyr::select(co12, co13, co14, co23, co24, co34) %>%
  unique

# Checking for internal consistency:
ifelse(co_all_rail_indices_AM$co12+co_all_rail_indices_AM$co23+co_all_rail_indices_AM$co34 - co_all_rail_indices_AM$co14 == 0, "PASS: the indices add up correctly", "FAIL: investigate this...")
ifelse(mean((co_all_rail$Final_cost - co_all_rail$First_cost_when_Possible_or_under_consideration_a_z)/co_all_rail$First_cost_when_Possible_or_under_consideration_a_z) - co_all_rail_indices_AM$co14 == 0, "PASS: the indices correspond with the top down calc", "FAIL: investigate this...")

#                                               ~~~~ SUMMARY TABLE ~~~~
co_all_table_1_project_az <- 
  bind_rows("Road" = co_all_road_indices_AM, "Rail" = co_all_rail_indices_AM, "All" = co_all_indices_AM, .id = "Type")

# PROJECT level cost overrun indices, assuming THE AVERAGE overrun if not observed ----
# Note: standard error of an arithmetic mean = sd(x) /sqrt (n)

#All: Road and rail
co_all_indices_AM_aa<-
  co_all%>% 
  mutate(total_projects = n()) %>%
  mutate(
         co12 = sum((First_cost_when_Committed_a_a - First_cost_when_Possible_or_under_consideration_a_a)/First_cost_when_Possible_or_under_consideration_a_a*(1/total_projects)),
         co23 = sum((First_cost_when_under_construction_a_a - First_cost_when_Committed_a_a)/First_cost_when_Possible_or_under_consideration_a_a*(1/total_projects)),
         co34 = sum((Final_cost - First_cost_when_under_construction_a_a)/First_cost_when_Possible_or_under_consideration_a_a*(1/total_projects)),
         co13 = sum((First_cost_when_under_construction_a_a - First_cost_when_Possible_or_under_consideration_a_a)/First_cost_when_Possible_or_under_consideration_a_a*(1/total_projects)),
         co14 = sum((Final_cost - First_cost_when_Possible_or_under_consideration_a_a)/First_cost_when_Possible_or_under_consideration_a_a*(1/total_projects)),
         co24 = sum((Final_cost - First_cost_when_Committed_a_a)/First_cost_when_Possible_or_under_consideration_a_a*(1/total_projects)),
         se_co12 = sd((First_cost_when_Committed_a_a - First_cost_when_Possible_or_under_consideration_a_a)/First_cost_when_Possible_or_under_consideration_a_a)/sqrt(total_projects),
         se_co23 = sd((First_cost_when_under_construction_a_a - First_cost_when_Committed_a_a)/First_cost_when_Possible_or_under_consideration_a_a)/sqrt(total_projects),         
         se_co34 = sd((Final_cost - First_cost_when_under_construction_a_a)/First_cost_when_Possible_or_under_consideration_a_a)/sqrt(total_projects),         
         se_co13 = sd((First_cost_when_under_construction_a_a - First_cost_when_Possible_or_under_consideration_a_a)/First_cost_when_Possible_or_under_consideration_a_a)/sqrt(total_projects),
         se_co14 = sd((Final_cost - First_cost_when_Possible_or_under_consideration_a_a)/First_cost_when_Possible_or_under_consideration_a_a)/sqrt(total_projects),         
         se_co24 = sd((Final_cost - First_cost_when_Committed_a_a)/First_cost_when_Possible_or_under_consideration_a_a)/sqrt(total_projects))%>%
  dplyr::select( co12, se_co12, co13, se_co13, co14, se_co14, co23, se_co23, co24, se_co24, co34, se_co34) %>%
  unique

# Testing for internal consistency:
ifelse(round(co_all_indices_AM_aa$co12+co_all_indices_AM_aa$co23+co_all_indices_AM_aa$co34 - co_all_indices_AM_aa$co14,7) ==0, "PASS: the indices add up correctly", "FAIL: investigate this...")
ifelse(round(mean((co_all$Final_cost - co_all$First_cost_when_Possible_or_under_consideration_a_a)/co_all$First_cost_when_Possible_or_under_consideration_a_a) - co_all_indices_AM_aa$co14,7) == 0, "PASS: the indices correspond with the top down calc", "FAIL: investigate this...")

#Road:
co_all_road_indices_AM_aa<-
  co_all_road%>% 
  mutate(total_projects = n()) %>%
  mutate(
    co12 = sum((First_cost_when_Committed_a_a - First_cost_when_Possible_or_under_consideration_a_a)/First_cost_when_Possible_or_under_consideration_a_a*(1/total_projects)),
    co23 = sum((First_cost_when_under_construction_a_a - First_cost_when_Committed_a_a)/First_cost_when_Possible_or_under_consideration_a_a*(1/total_projects)),
    co34 = sum((Final_cost - First_cost_when_under_construction_a_a)/First_cost_when_Possible_or_under_consideration_a_a*(1/total_projects)),
    co13 = sum((First_cost_when_under_construction_a_a - First_cost_when_Possible_or_under_consideration_a_a)/First_cost_when_Possible_or_under_consideration_a_a*(1/total_projects)),
    co14 = sum((Final_cost - First_cost_when_Possible_or_under_consideration_a_a)/First_cost_when_Possible_or_under_consideration_a_a*(1/total_projects)),
    co24 = sum((Final_cost - First_cost_when_Committed_a_a)/First_cost_when_Possible_or_under_consideration_a_a*(1/total_projects))) %>%
    dplyr::select(co12, co13, co14, co23, co24, co34) %>%
  unique

# Testing for internal consistency:
ifelse(round(co_all_road_indices_AM_aa$co12+co_all_road_indices_AM_aa$co23+co_all_road_indices_AM_aa$co34 - co_all_road_indices_AM_aa$co14,7) ==0, "PASS: the indices add up correctly", "FAIL: investigate this...")
ifelse(round(mean((co_all_road$Final_cost - co_all_road$First_cost_when_Possible_or_under_consideration_a_a)/co_all_road$First_cost_when_Possible_or_under_consideration_a_a) - co_all_road_indices_AM_aa$co14,7) == 0, "PASS: the indices correspond with the top down calc", "FAIL: investigate this...")

#Rail:
co_all_rail_indices_AM_aa<-
  co_all_rail%>% 
  mutate(total_projects = n()) %>%
  mutate(
    co12 = sum((First_cost_when_Committed_a_a - First_cost_when_Possible_or_under_consideration_a_a)/First_cost_when_Possible_or_under_consideration_a_a*(1/total_projects)),
    co23 = sum((First_cost_when_under_construction_a_a - First_cost_when_Committed_a_a)/First_cost_when_Possible_or_under_consideration_a_a*(1/total_projects)),
    co34 = sum((Final_cost - First_cost_when_under_construction_a_a)/First_cost_when_Possible_or_under_consideration_a_a*(1/total_projects)),
    co13 = sum((First_cost_when_under_construction_a_a - First_cost_when_Possible_or_under_consideration_a_a)/First_cost_when_Possible_or_under_consideration_a_a*(1/total_projects)),
    co14 = sum((Final_cost - First_cost_when_Possible_or_under_consideration_a_a)/First_cost_when_Possible_or_under_consideration_a_a*(1/total_projects)),
    co24 = sum((Final_cost - First_cost_when_Committed_a_a)/First_cost_when_Possible_or_under_consideration_a_a*(1/total_projects))) %>%
  dplyr::select(co12, co13, co14, co23, co24, co34) %>%
  unique

# Testing for internal consistency:
ifelse(round(co_all_rail_indices_AM_aa$co12+co_all_rail_indices_AM_aa$co23+co_all_rail_indices_AM_aa$co34 - co_all_rail_indices_AM_aa$co14,7) ==0, "PASS: the indices add up correctly", "FAIL: investigate this...")
ifelse(mean((co_all_rail$Final_cost - co_all_rail$First_cost_when_Possible_or_under_consideration_a_a)/co_all_rail$First_cost_when_Possible_or_under_consideration_a_a) - co_all_rail_indices_AM_aa$co14 == 0, "PASS: the indices correspond with the top down calc", "FAIL: investigate this...")

#                                               ~~~~ SUMMARY TABLE ~~~~
co_all_table_1_project_aa <- 
  bind_rows("Road" = co_all_road_indices_AM_aa, "Rail" = co_all_rail_indices_AM_aa, "All" = co_all_indices_AM_aa, .id = "Type")

# PORTFOLIO level cost overrun indices, assuming NO OVERRUN if not observed ----
# NOTE: Standard errors won't be right here...

#Road and rail
co_all_indices_AM_portfolio<- 
  co_all%>% 
  mutate(total_projects = n(), total_value_of_projects = sum(First_cost_when_Possible_or_under_consideration_a_z_real)) %>%
  mutate(
         co12 = sum((First_cost_when_Committed_a_z - First_cost_when_Possible_or_under_consideration_a_z)/First_cost_when_Possible_or_under_consideration_a_z*(First_cost_when_Possible_or_under_consideration_a_z_real/total_value_of_projects)),
         co23 = sum((First_cost_when_under_construction_a_z - First_cost_when_Committed_a_z)/First_cost_when_Possible_or_under_consideration_a_z*(First_cost_when_Possible_or_under_consideration_a_z_real/total_value_of_projects)),
         co34 = sum((Final_cost - First_cost_when_under_construction_a_z)/First_cost_when_Possible_or_under_consideration_a_z*(First_cost_when_Possible_or_under_consideration_a_z_real/total_value_of_projects)),
         co13 = sum((First_cost_when_under_construction_a_z - First_cost_when_Possible_or_under_consideration_a_z)/First_cost_when_Possible_or_under_consideration_a_z*(First_cost_when_Possible_or_under_consideration_a_z_real/total_value_of_projects)),
         co14 = sum((Final_cost - First_cost_when_Possible_or_under_consideration_a_z)/First_cost_when_Possible_or_under_consideration_a_z*(First_cost_when_Possible_or_under_consideration_a_z_real/total_value_of_projects)),
         co24 = sum((Final_cost - First_cost_when_Committed_a_z)/First_cost_when_Possible_or_under_consideration_a_z*(First_cost_when_Possible_or_under_consideration_a_z_real/total_value_of_projects)),
         se_co12 = sd((First_cost_when_Committed_a_z - First_cost_when_Possible_or_under_consideration_a_z)/First_cost_when_Possible_or_under_consideration_a_z)/sqrt(total_projects),
         se_co23 = sd((First_cost_when_under_construction_a_z - First_cost_when_Committed_a_z)/First_cost_when_Possible_or_under_consideration_a_z)/sqrt(total_projects),         
         se_co34 = sd((Final_cost - First_cost_when_under_construction_a_z)/First_cost_when_Possible_or_under_consideration_a_z)/sqrt(total_projects),         
         se_co13 = sd((First_cost_when_under_construction_a_z - First_cost_when_Possible_or_under_consideration_a_z)/First_cost_when_Possible_or_under_consideration_a_z)/sqrt(total_projects),
         se_co14 = sd((Final_cost - First_cost_when_Possible_or_under_consideration_a_z)/First_cost_when_Possible_or_under_consideration_a_z)/sqrt(total_projects),         
         se_co24 = sd((Final_cost - First_cost_when_Committed_a_z)/First_cost_when_Possible_or_under_consideration_a_z)/sqrt(total_projects))%>%
  dplyr::select(co12, se_co12, co13, se_co13, co14, se_co14, co23, se_co23, co24, se_co24, co34, se_co34) %>%
  unique

# Testing for internal consistency:
ifelse(co_all_indices_AM_portfolio$co12+co_all_indices_AM_portfolio$co23+co_all_indices_AM_portfolio$co34 - co_all_indices_AM_portfolio$co14 ==0, "PASS: the indices add up correctly", "FAIL: investigate this...")
ifelse(round(mean((sum(co_all$Final_cost_real)-sum(co_all$First_cost_when_Possible_or_under_consideration_a_z_real))/sum(co_all$First_cost_when_Possible_or_under_consideration_a_z_real)) - co_all_indices_AM_portfolio$co14,7) == 0, "PASS: the indices correspond with the top down calc", "FAIL: investigate this...")

#Road:
co_all_road_indices_AM_portfolio<- 
  co_all_road%>% 
  mutate(total_projects = n(), total_value_of_projects = sum(First_cost_when_Possible_or_under_consideration_a_z_real)) %>%
  mutate(
    co12 = sum((First_cost_when_Committed_a_z - First_cost_when_Possible_or_under_consideration_a_z)/First_cost_when_Possible_or_under_consideration_a_z*(First_cost_when_Possible_or_under_consideration_a_z_real/total_value_of_projects)),
    co23 = sum((First_cost_when_under_construction_a_z - First_cost_when_Committed_a_z)/First_cost_when_Possible_or_under_consideration_a_z*(First_cost_when_Possible_or_under_consideration_a_z_real/total_value_of_projects)),
    co34 = sum((Final_cost - First_cost_when_under_construction_a_z)/First_cost_when_Possible_or_under_consideration_a_z*(First_cost_when_Possible_or_under_consideration_a_z_real/total_value_of_projects)),
    co13 = sum((First_cost_when_under_construction_a_z - First_cost_when_Possible_or_under_consideration_a_z)/First_cost_when_Possible_or_under_consideration_a_z*(First_cost_when_Possible_or_under_consideration_a_z_real/total_value_of_projects)),
    co14 = sum((Final_cost - First_cost_when_Possible_or_under_consideration_a_z)/First_cost_when_Possible_or_under_consideration_a_z*(First_cost_when_Possible_or_under_consideration_a_z_real/total_value_of_projects)),
    co24 = sum((Final_cost - First_cost_when_Committed_a_z)/First_cost_when_Possible_or_under_consideration_a_z*(First_cost_when_Possible_or_under_consideration_a_z_real/total_value_of_projects))) %>%
    dplyr::select(co12, co13, co14, co23, co24, co34) %>%
  unique

# Testing for internal consistency:
ifelse(round(co_all_road_indices_AM_portfolio$co12+co_all_road_indices_AM_portfolio$co23+co_all_road_indices_AM_portfolio$co34 - co_all_road_indices_AM_portfolio$co14,7) ==0, "PASS: the indices add up correctly", "FAIL: investigate this...")
ifelse(round(mean((sum(co_all_road$Final_cost_real)-sum(co_all_road$First_cost_when_Possible_or_under_consideration_a_z_real))/sum(co_all_road$First_cost_when_Possible_or_under_consideration_a_z_real)) - co_all_road_indices_AM_portfolio$co14,7) == 0, "PASS: the indices correspond with the top down calc", "FAIL: investigate this...")

#Rail:
co_all_rail_indices_AM_portfolio<- 
  co_all_rail%>% 
  mutate(total_projects = n(), total_value_of_projects = sum(First_cost_when_Possible_or_under_consideration_a_z_real)) %>%
  mutate(
    co12 = sum((First_cost_when_Committed_a_z - First_cost_when_Possible_or_under_consideration_a_z)/First_cost_when_Possible_or_under_consideration_a_z*(First_cost_when_Possible_or_under_consideration_a_z_real/total_value_of_projects)),
    co23 = sum((First_cost_when_under_construction_a_z - First_cost_when_Committed_a_z)/First_cost_when_Possible_or_under_consideration_a_z*(First_cost_when_Possible_or_under_consideration_a_z_real/total_value_of_projects)),
    co34 = sum((Final_cost - First_cost_when_under_construction_a_z)/First_cost_when_Possible_or_under_consideration_a_z*(First_cost_when_Possible_or_under_consideration_a_z_real/total_value_of_projects)),
    co13 = sum((First_cost_when_under_construction_a_z - First_cost_when_Possible_or_under_consideration_a_z)/First_cost_when_Possible_or_under_consideration_a_z*(First_cost_when_Possible_or_under_consideration_a_z_real/total_value_of_projects)),
    co14 = sum((Final_cost - First_cost_when_Possible_or_under_consideration_a_z)/First_cost_when_Possible_or_under_consideration_a_z*(First_cost_when_Possible_or_under_consideration_a_z_real/total_value_of_projects)),
    co24 = sum((Final_cost - First_cost_when_Committed_a_z)/First_cost_when_Possible_or_under_consideration_a_z*(First_cost_when_Possible_or_under_consideration_a_z_real/total_value_of_projects))) %>%
  dplyr::select(co12, co13, co14, co23, co24, co34) %>%
  unique

# Testing for internal consistency:
ifelse(co_all_rail_indices_AM_portfolio$co12+co_all_rail_indices_AM_portfolio$co23+co_all_rail_indices_AM_portfolio$co34 - co_all_rail_indices_AM_portfolio$co14 ==0, "PASS: the indices add up correctly", "FAIL: investigate this...")
ifelse(round(mean((sum(co_all_rail$Final_cost_real)-sum(co_all_rail$First_cost_when_Possible_or_under_consideration_a_z_real))/sum(co_all_rail$First_cost_when_Possible_or_under_consideration_a_z_real)) - co_all_rail_indices_AM_portfolio$co14,7) == 0, "PASS: the indices correspond with the top down calc", "FAIL: investigate this...")

#                                               ~~~~ SUMMARY TABLE ~~~~
co_all_table_1_portfolio_az <- 
  bind_rows("Road" = co_all_road_indices_AM_portfolio, "Rail" = co_all_rail_indices_AM_portfolio, "All" = co_all_indices_AM_portfolio, .id = "Type")

# PORTFOLIO level cost overrun indices, assuming THE AVERAGE overrun if not observed ----
# NOTE: Standard errors won't be right here...

co_all_indices_AM_aa_portfolio<-
  co_all%>% 
  mutate(total_projects = n(),total_value_of_projects = sum(First_cost_when_Possible_or_under_consideration_a_a_real)) %>%
  mutate(
    co12 = sum((First_cost_when_Committed_a_a - First_cost_when_Possible_or_under_consideration_a_a)/First_cost_when_Possible_or_under_consideration_a_a*(First_cost_when_Possible_or_under_consideration_a_a_real/total_value_of_projects)),
    co23 = sum((First_cost_when_under_construction_a_a - First_cost_when_Committed_a_a)/First_cost_when_Possible_or_under_consideration_a_a*(First_cost_when_Possible_or_under_consideration_a_a_real/total_value_of_projects)),
    co34 = sum((Final_cost - First_cost_when_under_construction_a_a)/First_cost_when_Possible_or_under_consideration_a_a*(First_cost_when_Possible_or_under_consideration_a_a_real/total_value_of_projects)),
    co13 = sum((First_cost_when_under_construction_a_a - First_cost_when_Possible_or_under_consideration_a_a)/First_cost_when_Possible_or_under_consideration_a_a*(First_cost_when_Possible_or_under_consideration_a_a_real/total_value_of_projects)),
    co14 = sum((Final_cost - First_cost_when_Possible_or_under_consideration_a_a)/First_cost_when_Possible_or_under_consideration_a_a*(First_cost_when_Possible_or_under_consideration_a_a_real/total_value_of_projects)),
    co24 = sum((Final_cost - First_cost_when_Committed_a_a)/First_cost_when_Possible_or_under_consideration_a_a*(First_cost_when_Possible_or_under_consideration_a_a_real/total_value_of_projects)),
    se_co12 = sd((First_cost_when_Committed_a_a - First_cost_when_Possible_or_under_consideration_a_a)/First_cost_when_Possible_or_under_consideration_a_a)/sqrt(total_projects),
    se_co23 = sd((First_cost_when_under_construction_a_a - First_cost_when_Committed_a_a)/First_cost_when_Possible_or_under_consideration_a_a)/sqrt(total_projects),         
    se_co34 = sd((Final_cost - First_cost_when_under_construction_a_a)/First_cost_when_Possible_or_under_consideration_a_a)/sqrt(total_projects),         
    se_co13 = sd((First_cost_when_under_construction_a_a - First_cost_when_Possible_or_under_consideration_a_a)/First_cost_when_Possible_or_under_consideration_a_a)/sqrt(total_projects),
    se_co14 = sd((Final_cost - First_cost_when_Possible_or_under_consideration_a_a)/First_cost_when_Possible_or_under_consideration_a_a)/sqrt(total_projects),         
    se_co24 = sd((Final_cost - First_cost_when_Committed_a_a)/First_cost_when_Possible_or_under_consideration_a_a)/sqrt(total_projects))%>%
  dplyr::select(co12, se_co12, co13, se_co13, co14, se_co14, co23, se_co23, co24, se_co24, co34, se_co34) %>%
  unique

# Testing for internal consistency:
ifelse(round(co_all_indices_AM_aa_portfolio$co12+co_all_indices_AM_aa_portfolio$co23+co_all_indices_AM_aa_portfolio$co34 - co_all_indices_AM_aa_portfolio$co14,7) ==0, "PASS: the indices add up correctly", "FAIL: investigate this...")
ifelse(mean((sum(co_all$Final_cost_real)-sum(co_all$First_cost_when_Possible_or_under_consideration_a_a_real))/sum(co_all$First_cost_when_Possible_or_under_consideration_a_a_real)) - co_all_indices_AM_aa_portfolio$co14 == 0, "PASS: the indices correspond with the top down calc", "FAIL: investigate this...")

#Road:
co_all_road_indices_AM_aa_portfolio<-
  co_all_road%>% 
  mutate(total_projects = n(),total_value_of_projects = sum(First_cost_when_Possible_or_under_consideration_a_a_real)) %>%
  mutate(
    co12 = sum((First_cost_when_Committed_a_a - First_cost_when_Possible_or_under_consideration_a_a)/First_cost_when_Possible_or_under_consideration_a_a*(First_cost_when_Possible_or_under_consideration_a_a_real/total_value_of_projects)),
    co23 = sum((First_cost_when_under_construction_a_a - First_cost_when_Committed_a_a)/First_cost_when_Possible_or_under_consideration_a_a*(First_cost_when_Possible_or_under_consideration_a_a_real/total_value_of_projects)),
    co34 = sum((Final_cost - First_cost_when_under_construction_a_a)/First_cost_when_Possible_or_under_consideration_a_a*(First_cost_when_Possible_or_under_consideration_a_a_real/total_value_of_projects)),
    co13 = sum((First_cost_when_under_construction_a_a - First_cost_when_Possible_or_under_consideration_a_a)/First_cost_when_Possible_or_under_consideration_a_a*(First_cost_when_Possible_or_under_consideration_a_a_real/total_value_of_projects)),
    co14 = sum((Final_cost - First_cost_when_Possible_or_under_consideration_a_a)/First_cost_when_Possible_or_under_consideration_a_a*(First_cost_when_Possible_or_under_consideration_a_a_real/total_value_of_projects)),
    co24 = sum((Final_cost - First_cost_when_Committed_a_a)/First_cost_when_Possible_or_under_consideration_a_a*(First_cost_when_Possible_or_under_consideration_a_a_real/total_value_of_projects))) %>%
    dplyr::select(co12, co13, co14, co23, co24, co34) %>%
  unique

# Testing for internal consistency:
ifelse(round(co_all_road_indices_AM_aa_portfolio$co12+co_all_road_indices_AM_aa_portfolio$co23+co_all_road_indices_AM_aa_portfolio$co34 - co_all_road_indices_AM_aa_portfolio$co14,4) ==0, "PASS: the indices add up correctly", "FAIL: investigate this...")
ifelse(round(mean((sum(co_all_road$Final_cost_real)-sum(co_all_road$First_cost_when_Possible_or_under_consideration_a_a_real))/sum(co_all_road$First_cost_when_Possible_or_under_consideration_a_a_real)) - co_all_road_indices_AM_aa_portfolio$co14,4) == 0, "PASS: the indices correspond with the top down calc", "FAIL: investigate this...")

#Rail:
co_all_rail_indices_AM_aa_portfolio<-
  co_all_rail%>% 
  mutate(total_projects = n(),total_value_of_projects = sum(First_cost_when_Possible_or_under_consideration_a_a_real)) %>%
  mutate(
    co12 = sum((First_cost_when_Committed_a_a - First_cost_when_Possible_or_under_consideration_a_a)/First_cost_when_Possible_or_under_consideration_a_a*(First_cost_when_Possible_or_under_consideration_a_a_real/total_value_of_projects)),
    co23 = sum((First_cost_when_under_construction_a_a - First_cost_when_Committed_a_a)/First_cost_when_Possible_or_under_consideration_a_a*(First_cost_when_Possible_or_under_consideration_a_a_real/total_value_of_projects)),
    co34 = sum((Final_cost - First_cost_when_under_construction_a_a)/First_cost_when_Possible_or_under_consideration_a_a*(First_cost_when_Possible_or_under_consideration_a_a_real/total_value_of_projects)),
    co13 = sum((First_cost_when_under_construction_a_a - First_cost_when_Possible_or_under_consideration_a_a)/First_cost_when_Possible_or_under_consideration_a_a*(First_cost_when_Possible_or_under_consideration_a_a_real/total_value_of_projects)),
    co14 = sum((Final_cost - First_cost_when_Possible_or_under_consideration_a_a)/First_cost_when_Possible_or_under_consideration_a_a*(First_cost_when_Possible_or_under_consideration_a_a_real/total_value_of_projects)),
    co24 = sum((Final_cost - First_cost_when_Committed_a_a)/First_cost_when_Possible_or_under_consideration_a_a*(First_cost_when_Possible_or_under_consideration_a_a_real/total_value_of_projects))) %>%
  dplyr::select(co12, co13, co14, co23, co24, co34) %>%
  unique

# Testing for internal consistency:
ifelse(round(co_all_rail_indices_AM_aa_portfolio$co12+co_all_rail_indices_AM_aa_portfolio$co23+co_all_rail_indices_AM_aa_portfolio$co34 - co_all_rail_indices_AM_aa_portfolio$co14,4) ==0, "PASS: the indices add up correctly", "FAIL: investigate this...")
ifelse(round(mean((sum(co_all_rail$Final_cost_real)-sum(co_all_rail$First_cost_when_Possible_or_under_consideration_a_a_real))/sum(co_all_rail$First_cost_when_Possible_or_under_consideration_a_a_real)) - co_all_rail_indices_AM_aa_portfolio$co14,4) == 0, "PASS: the indices correspond with the top down calc", "FAIL: investigate this...")

#                                               ~~~~ SUMMARY TABLE ~~~~
co_all_table_1_portfolio_aa <- 
  bind_rows("Road" = co_all_road_indices_AM_aa_portfolio, "Rail" = co_all_rail_indices_AM_aa_portfolio, "All" = co_all_indices_AM_aa_portfolio, .id = "Type")

# Cost overrun threshold analysis -----

# The threshold analysis is based on the PROJECT level cost overrun indices, assuming no overrun if not observed:
# I write the co14 to the co_all dataset so that I can construct the threshold analysis off it.
co_all %<>%
  mutate(total_projects = n(), total_value_of_projects = sum(First_cost_when_Possible_or_under_consideration_a_z_real)) %>%
  mutate(co14 = (Final_cost - First_cost_when_Possible_or_under_consideration_a_z)/First_cost_when_Possible_or_under_consideration_a_z)


# Cost overruns vs cost underruns:

threshold_cost_overrun <- 0    # 0 = 0% overrun

# Above / below an arbitrary threshold

co_all %<>%
  mutate(Final_cost_over_initial_roundedup = RoundTo(co14, 0.25, ceiling)) %>%
  group_by(Final_cost_over_initial_roundedup) %>%
  mutate(freq_co_roundedup = n(), 
         value_co_roundedup = sum(value_co), 
         Prop_freq_co_roundedup = freq_co_roundedup/total_no_projects, 
         Prop_value_co_roundedup = value_co_roundedup/total_value_co)

co_all %<>%
  mutate(co_initial_final_category_prep = as.factor(ifelse(co14 > threshold_cost_overrun, "Cost overrun", 
                                                 ifelse(co14 < threshold_cost_overrun, "Cost underrun", "On budget")))) %>%
  mutate(co_initial_final_category = ordered(co_initial_final_category_prep, c("Cost underrun", "On budget", "Cost overrun"))) %>%
  group_by(co_initial_final_category, Matching_status) %>%
  mutate(no_projects_by_co_category_and_matching_status = n()) %>%
  mutate(prop_projects_by_co_category_and_matching_status = (no_projects_by_co_category_and_matching_status / no_projects_by_matching_status)*100) %>%
  ungroup() %>%
  group_by(co_initial_final_category) %>%
  mutate(total_value_co_by_co_initial_final_category = sum(value_co), 
         total_prop_co_by_co_intial_final_category = total_value_co_by_co_initial_final_category / total_value_co, 
         total_prop_of_projects_by_co_intial_final_category = n()/total_projects)

table(co_all$Matching_status)

co_all_table_3 <-  
  co_all %>%
  arrange(Matching_status_refined, co_initial_final_category) %>%
  group_by(Matching_status_refined, co_initial_final_category) %>%
  summarise(prop_projects_by_co_category_and_matching_status) %>% 
  unique

co_all_table_4 <-
  co_all %>%
  arrange(co_initial_final_category) %>%
  group_by(co_initial_final_category) %>%
  summarise(total_prop_of_projects_by_co_intial_final_category,  total_value_co_by_co_initial_final_category,total_prop_co_by_co_intial_final_category) %>%
  unique

# The total value of cost overruns should add to this number: 
sum(co_all$Final_cost_real)-sum(co_all$Initial_cost_real)
co_all_indices_AM_portfolio$co14*sum(co_all$Initial_cost_real)

co_all_table_5 <-
  co_all %>%
  arrange(Final_cost_over_initial_roundedup) %>%
  group_by(Final_cost_over_initial_roundedup) %>%
  dplyr::select(Final_cost_over_initial_roundedup, freq_co_roundedup, value_co_roundedup, Prop_freq_co_roundedup, Prop_value_co_roundedup) %>%
  unique

# Cost overruns by project stage: -----

co_g1_overruns_only <-
  co_g1 %>%
  filter(Final_cost_over_initial >1)
co_g2_overruns_only <-
  co_g2 %>%
  filter(Final_cost_over_initial >1)
co_g3_overruns_only <-
  co_g3 %>%
  filter(Final_cost_over_initial >1)

co_g1_underruns_only <-
  co_g1 %>%
  filter(Final_cost_over_initial <1)
co_g2_underruns_only <-
  co_g2 %>%
  filter(Final_cost_over_initial <1)
co_g3_underruns_only <-
  co_g3 %>%
  filter(Final_cost_over_initial <1)

overall_overruns_by_cohort <- data.frame(variable = c("Possible or under consid cohort", "Committed cohort", "Under construction cohort"),
                                         
                                         Average_overrun = c(sum(co_g1_overruns_only$Final_cost_real)/sum(co_g1_overruns_only$Initial_cost_real), 
                                                             sum(co_g2_overruns_only$Final_cost_real)/sum(co_g2_overruns_only$Initial_cost_real), 
                                                             sum(co_g3_overruns_only$Final_cost_real)/sum(co_g3_overruns_only$Initial_cost_real)),
                                         
                                         Average_underrun = c(sum(co_g1_underruns_only$Final_cost_real)/sum(co_g1_underruns_only$Initial_cost_real), 
                                                             sum(co_g2_underruns_only$Final_cost_real)/sum(co_g2_underruns_only$Initial_cost_real), 
                                                             sum(co_g3_underruns_only$Final_cost_real)/sum(co_g3_underruns_only$Initial_cost_real)), 
                                         
                                         Average_net_overrun= c(sum(co_g1$Final_cost_real)/sum(co_g1$Initial_cost_real), 
                                                                sum(co_g2$Final_cost_real)/sum(co_g2$Initial_cost_real), 
                                                                sum(co_g3$Final_cost_real)/sum(co_g3$Initial_cost_real)))  


# Frequency value graph:
      
      # Relevant frequencies:
      freq_1<-as.numeric(nrow(co_all[co_all$co14<0,])/nrow(co_all))
      freq_2<-as.numeric(nrow(co_all[co_all$co14==0,])/nrow(co_all))
      freq_3<-as.numeric((nrow(co_all[co_all$co14>0,])- nrow(co_all[co_all$co14>=0.25,]))/nrow(co_all))
      freq_4<-as.numeric((nrow(co_all[co_all$co14>=0.25,])- nrow(co_all[co_all$co14>=0.5,]))/nrow(co_all))
      freq_5<-as.numeric(nrow(co_all[co_all$co14>=0.5,])/nrow(co_all))
      
      # Relevant % of value
      pc_val_1<-as.numeric((co_all%>% filter(co14<0) %>% summarise(sum(Final_cost_real - Initial_cost_real)))/(co_all%>% filter(co14>0) %>% summarise(sum(Final_cost_real - Initial_cost_real))))
      pc_val_2<-as.numeric((co_all%>% filter(co14==0) %>% summarise(sum(Final_cost_real - Initial_cost_real)))/(co_all%>% filter(co14>0) %>% summarise(sum(Final_cost_real - Initial_cost_real))))
      pc_val_3<-as.numeric((co_all%>% filter(co14>0 & co14<0.25) %>% summarise(sum(Final_cost_real - Initial_cost_real)))/(co_all%>% filter(co14>0) %>% summarise(sum(Final_cost_real - Initial_cost_real))))
      pc_val_4<-as.numeric((co_all%>% filter(co14>=0.25 & co14<0.5) %>% summarise(sum(Final_cost_real - Initial_cost_real)))/(co_all%>% filter(co14>0) %>% summarise(sum(Final_cost_real - Initial_cost_real))))
      pc_val_5<-as.numeric((co_all%>% filter(co14>=0.5) %>% summarise(sum(Final_cost_real - Initial_cost_real)))/(co_all%>% filter(co14>0) %>% summarise(sum(Final_cost_real - Initial_cost_real))))
      
      freq_value_graph<-data.frame( "Magnitude of cost overruns" = c("<= 25% underrun", "On budget exactly", "<= 25% overrun ", "25%-50% overrun", ">50% overrun"),
                  "Proportion of projects" = c(freq_1, freq_2, freq_3, freq_4, freq_5),
                   "Proportion of the value of cost overruns" = c(pc_val_1, pc_val_2, pc_val_3, pc_val_4, pc_val_5))
      
      

#* Export cost overrun figures analysis data to excel: --------
#Cost_overrun_figures <- createWorkbook()
#addWorksheet(Cost_overrun_figures, "CO_project_level_az")
#addWorksheet(Cost_overrun_figures, "CO_project_level_aa")
#addWorksheet(Cost_overrun_figures, "CO_portfolio_level_az")
#addWorksheet(Cost_overrun_figures, "CO_portfolio_level_aa")
#addWorksheet(Cost_overrun_figures, "All_co_by_categories")
#addWorksheet(Cost_overrun_figures, "All_co_by_overrun_underrun")
#addWorksheet(Cost_overrun_figures, "All_co_by_thresholds")
#addWorksheet(Cost_overrun_figures, "Overall COs X cohort")
#writeData(Cost_overrun_figures, 1, co_all_table_1_project_az)
#writeData(Cost_overrun_figures, 2, co_all_table_1_project_aa)
#writeData(Cost_overrun_figures, 3, co_all_table_1_portfolio_az)
#writeData(Cost_overrun_figures, 4, co_all_table_1_portfolio_aa) 
#writeData(Cost_overrun_figures, 5, co_all_table_3)
#writeData(Cost_overrun_figures, 6, co_all_table_4)
#writeData(Cost_overrun_figures, 7, co_all_table_5)
#writeData(Cost_overrun_figures, 8, overall_overruns_by_cohort)
#saveWorkbook(Cost_overrun_figures, file = "../Spreadsheets/Deloitte pipeline analysis outputs/Cost_overrun_figures.xlsx", overwrite = TRUE)

#* Analysis >>>>>>>>>>>>  Correlation between cost overruns across periods -------

# Between consecutive periods:
#G1:
g1_costoverruns = cbind(co_12 = co_g1$Committed_cost_over_Possible_or_under_consideration, 
                        co_23 = co_g1$Under_construction_cost_over_committed,
                        co_34 = co_g1$Final_cost_over_under_construction)
rcorr_g1_costoverrun<-rcorr(g1_costoverruns, type="pearson")

corr_g1_costoverrun=data.frame(rcorr_g1_costoverrun$r)
pval_corr_g1_costoverrun=data.frame(rcorr_g1_costoverrun$P)


#G1 and G2:

g1g2_costoverruns = cbind(co_13 = (co_g1g2$First_cost_when_under_construction - co_g1g2$Initial_cost)/co_g1g2$Initial_cost,
                          co_34 = (co_g1g2$Final_cost - co_g1g2$First_cost_when_under_construction)/co_g1g2$First_cost_when_under_construction)
rcorr_g1g2_costoverrun<-rcorr(g1g2_costoverruns, type="pearson")
corr_g1g2_costoverrun=data.frame(rcorr_g1g2_costoverrun$r)
pval_corr_g1g2_costoverrun=data.frame(rcorr_g1g2_costoverrun$P)  
  
#G2:
g2_costoverruns =  cbind(co_23 = co_g2$Under_construction_cost_over_committed,
                         co_34 = co_g2$Final_cost_over_under_construction)                          
rcorr_g2_costoverrun<-rcorr(g2_costoverruns, type="pearson")

corr_g2_costoverrun=data.frame(rcorr_g2_costoverrun$r)
pval_corr_g2_costoverrun=data.frame(rcorr_g2_costoverrun$P)

#All: 
all_costoverruns = cbind(co_12 = co_all$Committed_cost_over_Possible_or_under_consideration, 
                         co_23 = co_all$Under_construction_cost_over_committed,
                         co_34 = co_all$Final_cost_over_under_construction)
rcorr_all_costoverrun<-rcorr(all_costoverruns, type="pearson")

corr_all_costoverrun=data.frame(rcorr_all_costoverrun$r)
pval_corr_all_costoverrun=data.frame(rcorr_all_costoverrun$P)

# Do underruns during the tender process lead to later overruns? No. There are examples of this happening, but it's not the rule. 
co_g1_and_2__underrun_in_2 <-
  co_all %>%
  filter(Matching_status_numeric <=2) %>%
  filter(Committed_cost_over_under_consideration<=1)

tender_and_construction_overruns = cbind(co_23 = co_g1_and_2__underrun_in_2$Committed_cost_over_under_consideration,
                                         co_34 = co_g1_and_2__underrun_in_2$Under_construction_cost_over_committed) 

rcorr_tender_and_construction_overruns <-rcorr(tender_and_construction_overruns, type ="pearson")
corr_tender_and_construction_overruns<-data.frame(rcorr_tender_and_construction_overruns$r)  
pval_tender_and_construction_overruns<-data.frame(rcorr_tender_and_construction_overruns$P)



# Export correlations:
#Correlations <- createWorkbook()
#addWorksheet(Correlations, "G1 co correlations")
#addWorksheet(Correlations, "G1 co corr pvals")
#addWorksheet(Correlations, "G2 co correlations")
#addWorksheet(Correlations, "G2 co corr pvals")
#addWorksheet(Correlations, "Tender and constr co corrs")
#addWorksheet(Correlations, "Tender and constr co pvals")
#writeData(Correlations, 1, corr_g1_costoverrun)
#writeData(Correlations, 2, pval_corr_g1_costoverrun)
#writeData(Correlations, 3, corr_g2_costoverrun)
#writeData(Correlations, 4, pval_corr_g2_costoverrun)
#writeData(Correlations, 5, corr_tender_and_construction_overruns)
#writeData(Correlations, 6, pval_tender_and_construction_overruns)
#saveWorkbook(Correlations, file = "../Spreadsheets/Deloitte pipeline analysis outputs/Correlations.xlsx", overwrite = TRUE)

#* Descriptive statistics, co_all dataset ------

# Table 1 - Completed projects - split by initial status and mode
SS_coall_table_1 <-
  co_all %>%
  arrange(Matching_status) %>%
  group_by(`Sub-industry`, Matching_status) %>%
  summarise(no_projects = n()) %>%
  spread(Matching_status, no_projects)  %>%
  setkey(`Sub-industry`)

# Table 2 - Completed projects - split by mode and state

SS_coall_table_2 <-  
  co_all %>%
  group_by(`Sub-industry`, State_new) %>%
  summarise(no_projects = n()) %>%
  spread(State_new, no_projects) %>%
  setkey(`Sub-industry`)

# Table 3: Table of means and variances for each variable
# Total cost when contracted:
log_Total_cost_when_contracted_<-
  co_all %>%
  filter(!is.na(First_cost_when_under_construction_real)) %>%
  summarise(Mean = mean(log(First_cost_when_under_construction_real)), 
            Var = var(log(First_cost_when_under_construction_real)))

# Mode
Mode_<-
  co_all %>%
  group_by(`Sub-industry`) %>%
  mutate(no_projects = n()) %>%
  mutate(Mean = no_projects / total_no_projects, 
         Var = Mean*(1-Mean)) %>%
  filter(`Sub-industry` == "Road") %>%
  summarise(Mean, Var) %>%
  unique

# Pre/post GFC
prepost_GFC_<-
  co_all %>%
  group_by(`Constructed_post_GFC`) %>%
  mutate(no_projects = n()) %>%
  mutate(Mean = no_projects / total_no_projects, 
         Var = Mean*(1-Mean))  %>%
  filter(`Constructed_post_GFC` == 1) %>%
  summarise(Mean, Var) %>%
  unique

# Total_days_pre_consideration
Total_days_pre_consideration_g1<-
  co_g1 %>%
  filter(!is.na(Total_days_pre_consideration) & Total_days_pre_consideration != 0) %>%
  summarise(Mean = mean(Total_days_pre_consideration), Var = var(Total_days_pre_consideration))


# Total_days_pre_commitment
Total_days_pre_commitment_<-
  co_all %>%
  filter(!is.na(Total_days_pre_commitment) & Total_days_pre_commitment != 0) %>%
  summarise(Mean = mean(Total_days_pre_commitment), Var = var(Total_days_pre_commitment))

Total_days_pre_commitment_g1<-
  co_g1 %>%
  filter(!is.na(Total_days_pre_commitment) & Total_days_pre_commitment != 0) %>%
  summarise(Mean = mean(Total_days_pre_commitment), Var = var(Total_days_pre_commitment))


# Total_days_pre_construction
Total_days_pre_construction_<-
  co_all %>%
  filter(!is.na(Total_days_pre_construction) & Total_days_pre_construction != 0) %>%
  summarise(Mean = mean(Total_days_pre_construction), Var = var(Total_days_pre_construction))

Total_days_pre_construction_g1<-
  co_g1 %>%
  filter(!is.na(Total_days_pre_construction) & Total_days_pre_construction != 0) %>%
  summarise(Mean = mean(Total_days_pre_construction), Var = var(Total_days_pre_construction))

Total_days_pre_construction_g2<-
  co_g2 %>%
  filter(!is.na(Total_days_pre_construction) & Total_days_pre_construction != 0) %>%
  summarise(Mean = mean(Total_days_pre_construction), Var = var(Total_days_pre_construction))

log_Total_days_pre_construction_co_all<-
  co_all %>%
  summarise(Mean = mean(log_Total_days_pre_construction), Var = Var(log_Total_days_pre_construction))
  
SS_coall_table_3_variable_names<-data_frame(Variable = c("Mode (0 if rail, 1 if road)", "Contracted after the GFC", "log(Total cost when contracted)", "Log(Total days pre-construction)"))
SS_coall_table_3_content <- rbind(Mode_[1], prepost_GFC_[1], log_Total_cost_when_contracted_[1], log_Total_days_pre_construction_co_all[1])
SS_coall_table_3 <- cbind(SS_coall_table_3_variable_names, SS_coall_table_3_content)



# Table 4: Descriptive statistics, commonwealth election variables: 

CW_election_90_<-
  co_all %>%
  filter(CW_election_within_90_days) %>%
  mutate(no_projects = n()) %>%
  mutate(Mean = no_projects / total_no_projects, Var = Mean*(1-Mean)) %>%
  dplyr::select(no_projects, Mean, Var) %>%
  unique

CW_election_180_<-
  co_all %>%
  filter(CW_election_within_180_days == TRUE) %>%
  mutate(no_projects = n()) %>%
  mutate(Mean = no_projects / total_no_projects, Var = Mean*(1-Mean)) %>%
  dplyr::select(no_projects, Mean, Var) %>%
  unique

CW_election_365_<-
  co_all %>%
  filter(CW_election_within_365_days == TRUE) %>%
  mutate(no_projects = n()) %>%
  mutate(Mean = no_projects / total_no_projects, Var = Mean*(1-Mean)) %>%
  dplyr::select(no_projects, Mean, Var) %>%
  unique

incumbent_won_CW_election_90_<-
  co_all %>%
  filter(incumbent_won_CW_election_within_90_days == TRUE) %>%
  mutate(no_projects = n()) %>%
  mutate(Mean = no_projects / total_no_projects, Var = Mean*(1-Mean)) %>%
  dplyr::select(no_projects, Mean, Var) %>%
  unique

incumbent_won_CW_election_180_<-
  co_all %>%
  filter(incumbent_won_CW_election_within_180_days == TRUE) %>%
  mutate(no_projects = n()) %>%
  mutate(Mean = no_projects / total_no_projects, Var = Mean*(1-Mean)) %>%
  dplyr::select(no_projects, Mean, Var) %>%
  unique

incumbent_won_CW_election_365_<-
  co_all %>%
  filter(incumbent_won_CW_election_within_365_days == TRUE) %>%
  mutate(no_projects = n()) %>%
  mutate(Mean = no_projects / total_no_projects, Var = Mean*(1-Mean)) %>%
  summarise(no_projects, Mean, Var) %>%
  unique

nonincumbent_won_CW_election_90_<-
  co_all %>%
  filter(nonincumbent_won_CW_election_within_90_days == TRUE) %>%
  mutate(no_projects = n()) %>%
  mutate(Mean = no_projects / total_no_projects, Var = Mean*(1-Mean)) %>%
  dplyr::select(no_projects, Mean, Var) %>%
  unique

# This doesn't produce anything because there are no projects that pass through the filter (see table(co_all$nonincumbent_won_CW_election_within_90_days))
# Replace this line of the table with c(0, "NA", )

nonincumbent_won_CW_election_180_<-
  co_all %>%
  filter(nonincumbent_won_CW_election_within_180_days == TRUE) %>%
  mutate(no_projects = n()) %>%
  mutate(Mean = no_projects / total_no_projects, Var = Mean*(1-Mean)) %>%
  dplyr::select(no_projects, Mean, Var) %>%
  unique

nonincumbent_won_CW_election_365_<-
  co_all %>%
  filter(nonincumbent_won_CW_election_within_365_days == TRUE) %>%
  mutate(no_projects = n()) %>%
  mutate(Mean = no_projects / total_no_projects, Var = Mean*(1-Mean)) %>%
  dplyr::select(no_projects, Mean, Var) %>%
  unique


SS_coall_table_4_variable_names<-data_frame(Variable = c("CW_election_90", "CW_election_180", "CW_election_365", 
                                                         "incumbent_won_CW_election_90", "incumbent_won_CW_election_180", "incumbent_won_CW_election_365","nonincumbent_won_CW_election_90", "nonincumbent_won_CW_election_180", "nonincumbent_won_CW_election_365"))
SS_coall_table_4_content <- rbind(CW_election_90_[1], CW_election_180_[1], CW_election_365_[1], 
                                  incumbent_won_CW_election_90_[1], incumbent_won_CW_election_180_[1], incumbent_won_CW_election_365_[1],
                                  nonincumbent_won_CW_election_90_[1], nonincumbent_won_CW_election_180_[1], nonincumbent_won_CW_election_365_[1])
SS_coall_table_4<- cbind(SS_coall_table_4_variable_names, SS_coall_table_4_content)

# Table 5: Descriptive statistics, state election variables: 

State_election_90_<-
  co_all %>%
  filter(State_election_within_90_days == TRUE) %>%
  mutate(no_projects = n()) %>%
  mutate(no_projects = n()) %>%
  mutate(Mean = no_projects / total_no_projects, Var = Mean*(1-Mean)) %>%
  summarise(no_projects, Mean, Var)


State_election_180_<-
  co_all %>%
  filter(State_election_within_180_days == TRUE) %>%
  mutate(no_projects = n()) %>%
  mutate(no_projects = n()) %>%
  mutate(Mean = no_projects / total_no_projects, Var = Mean*(1-Mean)) %>%
  summarise(no_projects, Mean, Var)

State_election_365_<-
  co_all %>%
  filter(State_election_within_365_days == TRUE) %>%
  mutate(no_projects = n()) %>%
  mutate(no_projects = n()) %>%
  mutate(Mean = no_projects / total_no_projects, Var = Mean*(1-Mean)) %>%
  summarise(no_projects, Mean, Var)

incumbent_won_State_election_90_<-
  co_all %>%
  filter(incumbent_won_State_election_within_90_days == TRUE) %>%
  mutate(no_projects = n()) %>%
  mutate(no_projects = n()) %>%
  mutate(Mean = no_projects / total_no_projects, Var = Mean*(1-Mean)) %>%
  summarise(no_projects, Mean, Var)

incumbent_won_State_election_180_<-
  co_all %>%
  filter(incumbent_won_State_election_within_180_days == TRUE) %>%
  mutate(no_projects = n()) %>%
  mutate(no_projects = n()) %>%
  mutate(Mean = no_projects / total_no_projects, Var = Mean*(1-Mean)) %>%
  summarise(no_projects, Mean, Var)

incumbent_won_State_election_365_<-
  co_all %>%
  filter(incumbent_won_State_election_within_365_days == TRUE) %>%
  mutate(no_projects = n()) %>%
  mutate(no_projects = n()) %>%
  mutate(Mean = no_projects / total_no_projects, Var = Mean*(1-Mean)) %>%
  summarise(no_projects, Mean, Var)

nonincumbent_won_State_election_90_<-
  co_all %>%
  filter(nonincumbent_won_State_election_within_90_days == TRUE) %>%
  mutate(no_projects = n()) %>%
  mutate(no_projects = n()) %>%
  mutate(Mean = no_projects / total_no_projects, Var = Mean*(1-Mean)) %>%
  summarise(no_projects, Mean, Var)

nonincumbent_won_State_election_180_<-
  co_all %>%
  filter(nonincumbent_won_State_election_within_180_days == TRUE) %>%
  mutate(no_projects = n()) %>%
  mutate(no_projects = n()) %>%
  mutate(Mean = no_projects / total_no_projects, Var = Mean*(1-Mean)) %>%
  summarise(no_projects, Mean, Var)

nonincumbent_won_State_election_365_<-
  co_all %>%
  filter(nonincumbent_won_State_election_within_365_days == TRUE) %>%
  mutate(no_projects = n()) %>%
  mutate(no_projects = n()) %>%
  mutate(Mean = no_projects / total_no_projects, Var = Mean*(1-Mean)) %>%
  summarise(no_projects, Mean, Var)

SS_coall_table_5_variable_names<-data_frame(Variable = c("State_election_90", "State_election_180", "State_election_365", 
                                                         "incumbent_won_State_election_90", "incumbent_won_State_election_180", "incumbent_won_State_election_365","nonincumbent_won_State_election_90", "nonincumbent_won_State_election_180", "nonincumbent_won_State_election_365"))
SS_coall_table_5_content <- rbind(State_election_90_[1], State_election_180_[1], State_election_365_[1], 
                                  incumbent_won_State_election_90_[1], incumbent_won_State_election_180_[1], incumbent_won_State_election_365_[1],
                                  nonincumbent_won_State_election_90_[1], nonincumbent_won_State_election_180_[1], nonincumbent_won_State_election_365_[1])
SS_coall_table_5<- cbind(SS_coall_table_5_variable_names, SS_coall_table_5_content)

# Table 6: Sample sizes by cost overrun category
SS_coall_table_6 <-
  co_all %>%
  arrange(co_initial_final_category) %>%
  filter(Final_status_historical == "Completed") %>%
  group_by(`Sub-industry`, co_initial_final_category) %>%
  summarise(no_projects = n()) %>%
  spread(co_initial_final_category, no_projects)  %>%
  setkey(`Sub-industry`)

SS_coall_table_7 <-
  co_all %>%
  arrange(co_initial_final_category) %>%
  filter(Final_status_historical == "Completed") %>%
  group_by(State_new, co_initial_final_category) %>%
  summarise(no_projects = n()) %>%
  spread(co_initial_final_category, no_projects)  %>%
  setkey(State_new)

SS_coall_table_8 <-
  co_all %>%
  group_by(State_new) %>%
  summarise(mean_project_size = mean(First_cost_when_under_construction)) %>%
  spread(State_new, mean_project_size)

SS_coall_table_9 <-
  co_all %>%
  arrange(co_initial_final_category) %>%
  group_by(Matching_status, co_initial_final_category) %>%
  summarise(no_projects = n()) %>%
  spread(co_initial_final_category, no_projects)  %>%
  setkey(Matching_status)


# Project size and % overrun by state - graph for report: 
sample_size_states <-
  co_all %>%
  group_by(State_new) %>%
  summarise(no_projects = n()) %>%
  setkey(State_new)

project_size_states<-
  co_all %>%
  filter(Final_cost_over_initial>1) %>%
  group_by(State_new) %>%
  summarise(average_size = mean(First_cost_when_under_construction)) %>%
  setkey(State_new) 

n_overruns_states <-
  co_all %>%
  filter(Final_cost_over_initial>1) %>%
  group_by(State_new) %>%
  summarise(no_projects = n()) %>%
  setkey(State_new)

pc_overruns_and_project_size_states<-data.frame(State_new = c("Australian Capital Territory","New South Wales","Northern Territory","Queensland",
                                             "South Australia","Tasmania","Unallocated","Victoria","Western Australia"),
                               pc_w_overruns = n_overruns_states$no_projects/sample_size_states$no_projects, 
                               average_project_size = c(as.numeric(project_size_states$average_size[1]), as.numeric(project_size_states$average_size[2]), 
                                                        as.numeric(project_size_states$average_size[3]), as.numeric(project_size_states$average_size[4]), 
                                                        as.numeric(project_size_states$average_size[5]), as.numeric(project_size_states$average_size[6]), 
                                                        as.numeric(project_size_states$average_size[7]), as.numeric(project_size_states$average_size[8]), 
                                                        as.numeric(project_size_states$average_size[9])))

# Mode and cost overruns - graph for report:
Cost_overruns_by_mode<- data.frame(Mode = c("road", "rail", "all"),
                                  First_announced_to_contracted = c(co_all_table_1_portfolio_az$co13[1], co_all_table_1_portfolio_az$co13[2], co_all_table_1_portfolio_az$co13[3]),
                                  Contracted_to_completed = c(co_all_table_1_portfolio_az$co13[1], co_all_table_1_portfolio_az$co13[2], co_all_table_1_portfolio_az$co13[3]))


# Key numbers for the report

#Prep:
big_overruns <- co_all %>% filter(Final_cost_over_initial>=1.1)
huge_overruns <- co_all %>% filter(Final_cost_over_initial >=3)
overrun_gt_50_pc<- co_all %>% filter(Final_cost_over_initial>1.5)
full_data<-co_all %>% filter(Matching_status_numeric<=4)
overruns <-co_all %>% filter(Final_cost_over_initial>1)
project_dataset_t_g1 <- project_dataset_t %>% filter(Initial_status=="Possible" | Initial_status=="Under consideration" )


#Key figures:
n_projects <- project_dataset_t %>% summarise(n())
n_completed_projects <- co_all %>% summarise(n())
pc_g1_projects_completed <- (project_dataset_t_g1 %>% filter(Final_status_historical == "Completed") %>% nrow)/(project_dataset_t_g1 %>% nrow)
@

<<savings_if_every_proj_with_CO_had_CO_le_10pc>>=
savings_if_every_proj_with_CO_had_CO_le_10pc <- 
  co_all %>%
  filter(Final_cost_real > Initial_cost_real) %$%
  # If every cost-overrun was only 10%, subtract from
  # 110% of initial_cost_real, otherwise just the normal difference
  sum(if_else(Final_cost_real > 1.1 * Initial_cost_real, 
              Final_cost_real - 1.1 * Initial_cost_real, 
              Final_cost_real - 1.0 * Initial_cost_real)) %>%
  # Costs are in millions
  multiply_by(10^6)
@

<<prop_projects_on_budget>>=
prop_projects_on_budget <- 
  co_all %$% 
  mean(co_initial_final_category == "On budget")
@

<<source-continued>>=
pc_of_projects_w_overrun<- (co_all %>% filter(co_initial_final_category =="Cost overrun") %>% summarise(n()))/(co_all %>% summarise(n()))
pc_of_projects_w_overrun_gt_0.5<- ((co_all %>% filter(Final_cost_over_initial > 1.5) %>% nrow) / (co_all %>% nrow))*100
pc_of_co_value_from_projects_w_overrun_gt_0.5 <- (sum(overrun_gt_50_pc$Final_cost_real)-sum(overrun_gt_50_pc$Initial_cost_real))/(sum(overruns$Final_cost_real)-sum(overruns$Initial_cost_real))*100
pc_of_projects_w_overrun_gt_2<- (co_all %>% filter(Final_cost_over_initial > 3) %>% nrow) / (co_all %>% nrow)*100
pc_of_co_value_from_projects_w_overrun_gt_2 <- (sum(huge_overruns$Final_cost_real)-sum(huge_overruns$Initial_cost_real))/(sum(overruns$Final_cost_real)-sum(overruns$Initial_cost_real))*100
value_B_of_co_gt_2<- (sum(huge_overruns$Final_cost_real)-sum(huge_overruns$Initial_cost_real))/1000
spending_per_dollar_budgeted<-sum(co_all$Final_cost_real)/sum(co_all$Initial_cost_real)
pc_lower_ROI<-1-(1*sum(co_all$Initial_cost_real)/sum(co_all$Final_cost_real)) # My working: (Initial_BCR - BCR_after_COs)/Initial_BCR, where BCR_after_COs = Benefits/(Initial costs*(sum(Final_costs)/sum(Initial_costs))) and Initial_BCR = Benefits/Initial_costs. 
cost_of_overruns_gt_50_pc<- sum(overrun_gt_50_pc$Final_cost_real) - sum(overrun_gt_50_pc$Initial_cost_real)

SS_coall_table_10_variable_names<-data_frame(Variable = c("n_completed_projects", "savings_from_no_co_gt_10_pc", "pc_of_projects_on_budget", 
                                                         "pc_of_projects_w_overrun", "spending_per_dollar_budgeted", "pc_lower_ROI","cost_of_overruns_gt_50_pc"))
SS_coall_table_10_content <- as.data.frame(c(n_completed_projects, data.frame(savings_from_no_co_gt_10_pc), pc_of_projects_on_budget, 
                               pc_of_projects_w_overrun, data.frame(spending_per_dollar_budgeted), data.frame(pc_lower_ROI),
                               data.frame(cost_of_overruns_gt_50_pc)))
SS_coall_table_10<- data.table(cbind(SS_coall_table_10_variable_names), "Key figures" = t(SS_coall_table_10_content))


# Export these summary statistics to excel

#Summary_statistics_coall <- createWorkbook()
#addWorksheet(Summary_statistics_coall, "Mode X initial status")
#addWorksheet(Summary_statistics_coall, "Mode X State")
#addWorksheet(Summary_statistics_coall, "General summary stats")
#addWorksheet(Summary_statistics_coall, "CW election variables")
#addWorksheet(Summary_statistics_coall, "State election variables")
#addWorksheet(Summary_statistics_coall, "CO cat X Mode")
#addWorksheet(Summary_statistics_coall, "CO cat X State")
#addWorksheet(Summary_statistics_coall, "Project size X State")
#addWorksheet(Summary_statistics_coall, "CO cat X Matching status")
#addWorksheet(Summary_statistics_coall, "Misc key CO nos")
#writeData(Summary_statistics_coall, 1, SS_coall_table_1)
#writeData(Summary_statistics_coall, 2, SS_coall_table_2)
#writeData(Summary_statistics_coall, 3, SS_coall_table_3)
#writeData(Summary_statistics_coall, 4, SS_coall_table_4)
#writeData(Summary_statistics_coall, 5, SS_coall_table_5)
#writeData(Summary_statistics_coall, 6, SS_coall_table_6)
#writeData(Summary_statistics_coall, 7, SS_coall_table_7)
#writeData(Summary_statistics_coall, 8, SS_coall_table_8)
#writeData(Summary_statistics_coall, 9, SS_coall_table_9)
#writeData(Summary_statistics_coall, 10, SS_coall_table_10)
#saveWorkbook(Summary_statistics_coall, file = "../Spreadsheets/Deloitte pipeline analysis outputs/Summary statistics co_all dataset.xlsx", overwrite = TRUE)

#* Exporting misc subsets of the data (This is exploratory, not needed for the report): ----

the_worst_offenders<-
  co_all %>%
  filter(Final_cost_over_initial>2) %>%
  summarise(Grattan_record, Project, Final_cost_over_initial, Initial_cost, First_cost_when_Possible_or_under_consideration, First_cost_when_Committed, First_cost_when_under_construction, Final_cost) %>%
  arrange(Final_cost_over_initial)

project_list_for_Eric<-
  co_all %>%
  filter(Final_cost>1000) %>%
  summarise(Project, Final_cost, Final_cost_real) %>%
  arrange(Final_cost)

really_small_overruns <-
  co_all %>%
  filter(Final_cost_over_initial_roundedup <=0.8)  %>%
  dplyr::summarise(Grattan_record, Project, Final_cost_over_initial, Initial_cost, First_cost_when_Possible_or_under_consideration, First_cost_when_Committed, First_cost_when_under_construction, Final_cost) %>%
  arrange(Final_cost_over_initial)

Grattan_projects <- 
  co_all %>%
  filter(Grattan_record == 2423| Grattan_record == 4177| Grattan_record == 4186| Grattan_record == 4621| Grattan_record == 4798| Grattan_record == 4835| Grattan_record == 5232| Grattan_record == 5244| Grattan_record == 5476| Grattan_record == 5478| Grattan_record == 6101| Grattan_record == 6781| Grattan_record == 6784| Grattan_record == 6786| Grattan_record == 6829| Grattan_record == 6990| Grattan_record == 6997| Grattan_record == 7187| Grattan_record == 7421| Grattan_record == 7525| Grattan_record == 7574| Grattan_record == 7861| Grattan_record == 8566| Grattan_record == 8628| Grattan_record == 8629| Grattan_record == 8636| Grattan_record == 9181| Grattan_record == 9182| Grattan_record == 9202| Grattan_record == 9329| Grattan_record == 9346| Grattan_record == 9347| Grattan_record == 9888| Grattan_record == 9889| Grattan_record == 9926| Grattan_record == 10087| Grattan_record == 10193| Grattan_record == 10216| Grattan_record == 10646| Grattan_record == 10691| Grattan_record == 10742| Grattan_record == 10760| Grattan_record == 10761| Grattan_record == 10762| Grattan_record == 10906| Grattan_record == 10994| Grattan_record == 11040| Grattan_record == 11048| Grattan_record == 11069| Grattan_record == 11073| Grattan_record == 11074| Grattan_record == 11322) %>%
  #filter(Grattan_record == 2423 | Grattan_record == 9926 | Grattan_record == 4186 | Grattan_record == 9889 | Grattan_record == 4621 | Grattan_record == 6786 | Grattan_record == 11073 | Grattan_record == 11069 | Grattan_record == 10646 | Grattan_record == 7574 | Grattan_record == 10760 | Grattan_record == 10761 | Grattan_record == 11074 | Grattan_record == 6781 | Grattan_record == 10762 | Grattan_record == 6990 | Grattan_record == 11040 | Grattan_record == 5232 | Grattan_record == 9346 | Grattan_record == 9347 | Grattan_record == 8629 | Grattan_record == 7861 | Grattan_record == 8566 | Grattan_record == 7187 | Grattan_record == 10742 | Grattan_record == 6784 | Grattan_record == 5244 | Grattan_record == 10994 | Grattan_record == 7525 | Grattan_record == 8636 | Grattan_record == 9329 | Grattan_record == 4835 | Grattan_record == 9181 | Grattan_record == 9182 | Grattan_record == 10216 | Grattan_record == 9202 | Grattan_record == 8628 | Grattan_record == 9888 | Grattan_record == 9926 | Grattan_record == 10193 | Grattan_record == 10691 | Grattan_record == 11322 | Grattan_record == 4177  | Grattan_record == 5476  | Grattan_record == 5478  | Grattan_record == 5508  | Grattan_record == 6107  | Grattan_record == 6829  | Grattan_record == 6997  | Grattan_record == 7421) %>%
  dplyr::select(., Grattan_record, Project, Initial_cost, First_cost_when_Possible_or_under_consideration_a_a, First_cost_when_Committed_a_a, First_cost_when_under_construction_a_a, Final_cost)


# And writing them to the spreadsheets folder

#the_worst_offenders %>% 
#  as.data.frame %>%
#  write.xlsx2(., file = "../Spreadsheets/The worst offenders.xlsx", col.names = TRUE, row.names = FALSE)

#project_list_for_Eric %>% 
#  as.data.frame %>%
#  write.xlsx2(., file = "../Spreadsheets/Project list for Eric.xlsx", col.names = TRUE, row.names = FALSE)

#Grattan_projects %>% 
#  as.data.frame %>%
#  write.xlsx2(., file = "../Spreadsheets/Initial and final IM cost data for Grattan projects_a_a.xlsx", col.names = TRUE, row.names = FALSE)


######################### Detailed analysis of cost overruns -----

# Spliting the data into subsamples that might be better suited to analysis: -----
# co_only_all ==> exclude the stack of 0's
co_all%<>%
  filter(!is.na(log_Total_days_pre_construction)) %>% # This filters out the 27 projects that never go through the construction stage (but end up completed..). Obviously they did get constructed, but it means assumptions about WHEN would have to be made to include them in these averages.
  mutate(total_value_of_projects = sum(First_cost_when_under_construction_real))

co_all %<>%
  mutate(election_180_days = if_else(State_election_within_180_days ==1, 1, if_else(CW_election_within_180_days==1, 1, 0 )), 
         election_365_days = if_else(State_election_within_365_days ==1, 1, if_else(CW_election_within_365_days==1, 1, 0 )), 
         premature_announcement = if_else(Matching_status_numeric<=2, 1, 0))

co_only_all<-
  co_all%>%
  filter(!is.na(log_Total_days_pre_construction)) %>% # This filters out the 27 projects that never go through the construction stage (but end up completed..). Obviously they did get constructed, but it means assumptions about WHEN would have to be made to include them in these averages.
  filter(Final_cost_over_initial_roundedup != 1)
# co_positive_only_all ==> exclude cost underruns as well
co_positive_only_all<-
  co_all %>%
  filter(Final_cost_over_initial > 1) %>%
  filter(!is.na(log_Total_days_pre_construction)) %>%# This filters out the 27 projects that never go through the construction stage (but end up completed..). Obviously they did get constructed, but it means assumptions about WHEN would have to be made to include them in these averages.
  mutate(Road = ifelse(`Sub-industry`=="Road", 1, 0))

######################### Exploratory analysis which is not used in the final report: ------

# P50, P90 analysis: ----

#Overall:

#Full sample:            
co_all %$%
  quantile(Final_cost_over_initial, seq(0, 1, 0.1))
#G1:             
co_all %>%
  filter(Matching_status_numeric == 1) %$% 
  quantile(Final_cost_over_initial, seq(0, 1, 0.1))
#G2:
co_all %>%
  filter(Matching_status_numeric == 2) %$% 
  quantile(Final_cost_over_initial, seq(0, 1, 0.1))   
#G3:
co_all %>%
  filter(Matching_status_numeric == 3) %$% 
  quantile(Final_cost_over_initial, seq(0, 1, 0.1))   
#G4:
co_all %>%
  filter(Matching_status_numeric == 4) %$% 
  quantile(Final_cost_over_initial, seq(0, 1, 0.1))   

#Under consideration to final:
co_all %>%
  filter(Matching_status_numeric == 1 | Matching_status_numeric == 2 ) %$% 
  quantile(Final_cost_over_Possible_or_under_consideration, seq(0, 1, 0.1))

#Committed to final:
co_all %>%
  filter(Matching_status_numeric == 1 | Matching_status_numeric == 2 | Matching_status_numeric == 3) %$% 
  quantile(Final_cost_over_committed, seq(0, 1, 0.1))


#Under construction to final:
#co_all %>%
#  quantile(Final_cost_over_under_construction, seq(0, 1, 0.1))

# PDF of cost overruns:
ecdf_final_cost_over_initial<-  ecdf(co_all$Final_cost_over_initial)
ecdf_matrix_prep<-cbind(seq(0,4,0.05),ecdf_final_cost_over_initial(seq(0,4,0.05)))
str(ecdf_matrix_prep[,1])
average_overrun<-cbind(seq(1.34, 1.34,length.out=81)-ecdf_matrix_prep[,1])
ecdf_matrix<-cbind(ecdf_matrix_prep, average_overrun)
plot(ecdf_matrix[,1],ecdf_matrix[,2], type="n", main = "ECDF: Probability that a random CO is < X", xlab = "Magnitude of cost overrun (Final cost / Initial)", ylab = "Probability")
lines(ecdf_matrix[,1], ecdf_matrix[,2], lty = 1, lwd = 4, col = "orange")

plot(ecdf_matrix[,2],ecdf_matrix[,3], type="n", main = "Relationship between probability pricing and reference class forecasting", xlab = "Probability that the final cost is less than or equal to the initial cost", ylab = "Magnitude of average cost overrun = % uplift that should be used in RCF")
lines(ecdf_matrix[,2], ecdf_matrix[,3], lty = 1, lwd = 4, col = "orange")


# I should add a normal distribution to this graph:
ecdf_normal_dist_mean_1<-  ecdf(rnorm(100000, mean = 1, sd = 0.65))

normal_ecdf_matrix_prep<-cbind(seq(0,4,0.05),  ecdf_normal_dist_mean_1(seq(0,4,0.05)))
average_overrun_normal<-cbind(seq(1, 1,length.out=81)-normal_ecdf_matrix_prep[,1])
normal_ecdf_matrix<-cbind(normal_ecdf_matrix_prep, average_overrun_normal)

#pdf_matrix_prep <-cbind(seq(0,4,0.05), pdf_final_cost_over_initial)

#PDF's
Final_over_initial_density<-density(co_all$Final_cost_over_initial, bw = 0.3)
plot(Final_over_initial_density, xlim = c(-1,8), ylim = c(0,1), lwd=3, col = "orange", main = "PDF: Probability that a random CO is = X", xlab = "Magnitude of cost overrun (Final cost / Initial)", ylab = "Probability")
norm_sample<-rnorm(1000, mean=1, sd=0.65)
norm_sample_density<-density(norm_sample, bw = 0.3)
lines(norm_sample_density, lty = 1, lwd = 3, col = "maroon")

#CDF's
plot(ecdf_matrix[,1],ecdf_matrix[,2], type="n", main = "ECDF: Probability that a random CO is < X", xlab = "Magnitude of cost overrun (Final cost / Initial)", ylab = "Probability")
lines(ecdf_matrix[,1], ecdf_matrix[,2], lty = 1, lwd = 4, col = "orange")
lines(normal_ecdf_matrix[,1], normal_ecdf_matrix[,2], lty = 1, lwd = 4, col = "maroon")

#Comparison of RCF to P_costings
#plot(ecdf_matrix[,2],ecdf_matrix[,3], type="n", main = "Relationship between probability pricing and reference class forecasting", xlab = "Probability that the final cost is less than or equal to the initial cost", ylab = "Magnitude of average cost overrun = % uplift that should be used in RCF")
#lines(ecdf_matrix[,2], ecdf_matrix[,3], lty = 1, lwd = 4, col = "orange")
#lines(normal_ecdf_matrix[,2], normal_ecdf_matrix[,3], lty = 1, lwd = 4, col = "maroon")
#lines(seq(0,4,0.05), seq(0, 0,length.out=81),lty = 2, lwd = 2)

plot(normal_ecdf_matrix[,2],normal_ecdf_matrix[,3], type="n", main = "Relationship between probability pricing and reference class forecasting", xlab = "Probability that the final cost is less than or equal to the initial cost", ylab = "Magnitude of average cost overrun = % uplift that should be used in RCF")
lines(ecdf_matrix[,2], ecdf_matrix[,3], lty = 1, lwd = 4, col = "orange")
lines(normal_ecdf_matrix[,2], normal_ecdf_matrix[,3], lty = 1, lwd = 4, col = "maroon")
lines(seq(0,4,0.05), seq(0, 0,length.out=81),lty = 2, lwd = 2)
#text(locator(), labels = c("Observed distribution", "Normal distribution"))

ecdf_final_cost_over_initial(unique(co_all$Final_cost_over_initial))
cbind(unique(co_all$Final_cost_over_initial),    ecdf_final_cost_over_initial(unique(co_all$Final_cost_over_initial)))

#* Exploring the project-level / portfolio level disjoint: ########

# Normal distribution: http://stats.stackexchange.com/questions/17800/what-is-the-distribution-of-the-sum-of-independent-normal-variables
n1<-rnorm(1000,0,1)
n1_density<-density(n1, bw = 0.2)
n2<-rnorm(1000,0,1)
n2_density<-density(n2, bw = 0.2)
n3<-n1+n2
n3_density<-density(n3, bw = 0.2)
n4<-rnorm(1000,0,sqrt(2))
n4_density<-density(n4, bw = 0.2)
plot(n1_density)
lines(n2_density)
lines(n3_density)
lines(n4_density)

# Sum of two observations from our empirical distribution
Final_over_initial_density<-density((co_all$Final_cost_over_initial), bw = 0.3) 
fcoi_1<-sample(co_all$Final_cost_over_initial, 1000, replace = TRUE)
fcoi_1_density<-density(fcoi_1, bw = 0.3) 
fcoi_2<-sample(co_all$Final_cost_over_initial, 1000, replace = TRUE)
fcoi_2_density<-density(fcoi_2, bw = 0.3) 
fcoi_3 <-fcoi_1+fcoi_2
fcoi_3_density<-density(fcoi_3, bw = 0.3) 

plot(Final_over_initial_density)
lines(fcoi_1_density)
lines(fcoi_2_density)
lines(fcoi_3_density)

# Distribution of project outcomes, relative to the distribution of average outcomes:
library(boot)

samplemean <- function(x, d) {
  return(mean(x[d]))
}

# Densities:
sample_of_means<-boot(co_all$Final_cost_over_initial, samplemean, 1000)
sample_of_means_density<-density(sample_of_means$t, bw = 0.4)

plot(Final_over_initial_density, ylim=c(0, 1), xlim=c(0, 5), lty = 1, lwd = 2, col = "orange")
lines(sample_of_means_density, lty = 1, lwd = 2, col = "aquamarine4")

# ECDF's: 

mean(co_all$Final_cost_over_initial)

ecdf_final_cost_over_initial<-  ecdf(co_all$Final_cost_over_initial)
ecdf_matrix_prep<-cbind(seq(0,4,0.05),ecdf_final_cost_over_initial(seq(0,4,0.05)))
str(ecdf_matrix_prep[,1])
average_overrun<-cbind(seq(1.34, 1.34,length.out=81)-ecdf_matrix_prep[,1])
ecdf_matrix<-cbind(ecdf_matrix_prep, average_overrun)
plot(ecdf_matrix[,1],ecdf_matrix[,2], type="n", main = "ECDF: Probability that a random CO is < X", xlab = "Magnitude of cost overrun (Final cost / Initial)", ylab = "Probability")
lines(ecdf_matrix[,1], ecdf_matrix[,2], lty = 1, lwd = 4, col = "orange")

ecdf_sample_of_means<-  ecdf(sample_of_means$t)
ecdf_matrix<-cbind(ecdf_matrix_prep,ecdf_sample_of_means(seq(0,4,0.05)))
lines(ecdf_matrix[,1], ecdf_matrix[,3], lty = 1, lwd = 4, col = "aquamarine4")

# "Certainty curves" 
plot(ecdf_matrix[,1],1-ecdf_matrix[,2], type="n", main = "ECDF: Probability that cost overruns are greater than X", xlab = "Magnitude of cost overrun (Final cost / Initial)", ylab = "Probability", xlim=c(1,3))
lines(ecdf_matrix[,1], 1-ecdf_matrix[,2], lty = 1, lwd = 4, col = "orange")
lines(ecdf_matrix[,1], 1-ecdf_matrix[,3], lty = 1, lwd = 4, col = "aquamarine4")

#* Pre-regression analysis >>>>>>>  Outliers: ------------
table(co_all$Final_cost_over_initial_roundedup)  ## Double check the 79 has been excluded

#* Pre-regression analysis >>>>>>>  How heavy are the tails of our distribution? -----

# Zipf plot:
ecdf_log_Final_cost_over_initial<- ecdf(log(co_all$Final_cost_over_initial))
plot(log(co_all$Final_cost_over_initial), (1-ecdf_log_Final_cost_over_initial(log(co_all$Final_cost_over_initial))))

ecdf_log_Final_cost_over_initial_co_only<- ecdf(log(co_only_all$Final_cost_over_initial))
plot(log(co_only_all$Final_cost_over_initial), (1-ecdf_log_Final_cost_over_initial_co_only(log(co_only_all$Final_cost_over_initial)))) 
# This looks like it could be exponentially distributed, but that's mostly because of the cost underruns.
# The cost overruns most closely follow a pareto/power law distribution because the convexity of the plot is closer to a linear relationship than a concave shape...  

# Mean excess plot:
meplot(co_all$Final_cost_over_initial)
meplot(co_only_all$Final_cost_over_initial)
meplot(co_positive_only_all$Final_cost_over_initial) 
# This looks like a clean power distribution between 1 and 4 (exclusive), then it is extremely irregular (just a sample size issue? Only 19 in this range). 

# Note: Necessary but not sufficient evidence of Pareto dist:
# The MEfunction and Zipf plots could have rejected the hyp of Pareto distribution, but didn't. 
# However, these traditional graphs have poor rejection power, so are not sufficient to conclude the var is Pareto distributed.

# Moments plot:
moment_plot=function(data){
  # "data" is a vector containing the sample data
  ##############################################
  ##############################################
  # CV and Skewness functions
  coefvar=function(data){
    CV=sd(data)/mean(data)
    CV}
  skewness=function(data) {
    m_3 <- mean((data-mean(data))^3)
    skew <- m_3/(sd(data)^3)
    skew}
  ##############################################
  ##############################################
  # Computation of CV and Skewness
  # CV
  CV=coefvar(data);
  # Skewness
  skew=skewness(data)
  # Rule of Thumb
  if (CV<0 | skew <0.15){print("Possibly neither Pareto nor lognormal. Thin tails."); stop}
  ##############################################
  # Preparation of the plot
  ##############################################
  # Paretian Area
  25
  # The upper limit - Pareto I
  p=seq(3.001,400,length.out=250)
  g2brup=1/(sqrt(p*(p-2)))
  g3brup=(1+p)/(p-3)*2/(sqrt(1-2/p))
  # The lower limit, corresponding to the Inverted Gamma
  g2ibup=seq(0.001,0.999,length.out=250)
  g3ibup=4*g2ibup/(1-g2ibup^2)
  ##############################################
  # Lognormal area
  # Upper limit: Lognormal
  w=seq(1.01,20,length.out=250)
  g2log=sqrt(w-1)
  g3log=(w+2)*sqrt(w-1)
  # Lower limit - Gamma
  g2iblow=seq(0,20,length.out=250)
  g3iblow=2*g2iblow
  ##############################################
  # Exponential Area
  # The upper limit corresponds to the lower limit of the
  # lognormal area
  # The lower limit - Bernoulli
  g2below=seq(0,20,length.out=250)
  g3below=g2below-1/g2below
  ##############################################
  # The Gray area is obtained for free from
  # the previous lines of code.
  ##############################################
  # Normal / Symmetric distribution
  g2nor=seq(0,20,length.out=250)
  g3nor=rep(0,250)
  ##############################################
  # PLOT
  # Limits
  plot(g2iblow,g3iblow,"l",xlab="CV",ylab="Skewness",main="Discriminant Moment-ratio Plot", xlim=c(0,20),ylim=c(-1,40))
  lines(g2ibup,g3ibup,"l")
  lines(g2brup,g3brup,"l")
  lines(g2below,g3below,"l")
  lines(g2log,g3log,lty=2) # Lognormal
  lines(g2nor,g3nor,lty=2) # Normal
  # Strictly Paretian Area
  polygon(c(g2ibup,g2brup),c(g3ibup,g3brup),col="green")
  points(0,2,pch=1,cex=0.8) # Pareto limit point
  # Hints for interpretation
  text(-0.2,20,cex=0.8,srt=90,"Pareto I")
  text(1.2,20,cex=0.8,srt=90,"Inverted Gamma")
  26
  text(2.5,12,cex=0.8,srt=70,"Lognormal")
  text(12,21,cex=0.8,srt=23,"Gamma")
  text(14,11,cex=0.8,srt=10,"Bernoulli")
  text(15,1.5,cex=0.8,"Normal or Symmetric")
  points(CV,skew,pch=16,col="red")
  return(c(CV,skew))
}
moment_plot(co_all$Final_cost_over_initial) #Borderline inverted Gamma / Pareto I
moment_plot(co_only_all$Final_cost_over_initial) #Borderline inverted Gamma / Lognormal
moment_plot(co_positive_only_all$Final_cost_over_initial) #inverted Gamma, though not far off Lognormal.

# Note: sample size is particularly important here. 100+ is sufficient, so we are okay..

# Zenga curve (varient of the lorenz curve)
zengaplot=function(data){
  # Since the code relies on the Lorenz curve
  # as computed by the "ineq" library,
  # we upload it
  library(ineq)
  # Empirical Lorenz
  est=Lc(data)
  # Zenga curve
  Zu=(est$p-est$L)/(est$p*(1-est$L))
  # We rescale the first and the last point for
  # graphical reasons
  Zu[1]=Zu[2]; Zu[length(Zu)]=Zu[(length(Zu)-1)]
  # Here's the plot
  plot(est$p,Zu,xlab="u",ylab="Z(u)",ylim=c(0,1), main="Zenga plot","l",lty=1)
}
zengaplot(co_all$Final_cost_over_initial)
zengaplot(co_only_all$Final_cost_over_initial)
zengaplot(co_positive_only_all$Final_cost_over_initial)

# Estimating the shape parametre of a pareto distribution, to confirm existance of variance:
# Co_all dataset:
power.law.fit(co_all$Final_cost_over_initial) # a = 2.684343, lL=-193, KS.p = 0.35 --> DNR the hyp that the data could have been drawn from this dist.
# Co_only_all dataset:
power.law.fit(co_only_all$Final_cost_over_initial) # a = 2.863116, Ks.p = 0.94
# Co_positive_only_all dataset:
power.law.fit(co_positive_only_all$Final_cost_over_initial) # a = 2.684343, Ks.p = 0.94


# Check this for G1 cost overrun variables: (p-vals are high for all)
power.law.fit(co_g1$Final_cost_over_Possible_or_under_consideration) # a = 3.02
power.law.fit(co_g1$Final_cost_over_committed) # a = 3.07
power.law.fit(co_g1$Final_cost_over_under_construction) # a = 3.64
power.law.fit(co_g1$Committed_cost_over_Possible_or_under_consideration) # a = 3.38
power.law.fit(co_g1$Under_construction_cost_over_Possible_or_under_consideration) # a = 3.04
power.law.fit(co_g1$Under_construction_cost_over_committed) # a = 3.27
# Check this for G2 cost overrun variables: (p-vals are high for all)
power.law.fit(co_g2$Final_cost_over_committed) # a = 3.43
power.law.fit(co_g2$Final_cost_over_under_construction) # a = 3.36
power.law.fit(co_g2$Under_construction_cost_over_committed) # a = 3.35
# Check this for G3 cost overrun variables: (p-vals are high for all)
power.law.fit(co_g3$Final_cost_over_under_construction) # a = 3.88
# We're good all round.

# Conclusions of the heavy tails analysis (07/07/2016):
# None of the theoretical distributions seem to be a perfect fit - the tail and the body of the distribution are just so different.
# Of the distributions examined, inverted gamma, lognormal, weibull, exponential and Pareto were the only ones that ever looked encouraging (in that order)
# Good news! Under any variant of the pareto distribution, alpha is always estimated above 2 --> Variance always exists.




######################### Analysis which is used in the final report: ------

# How many projects run over budget, relative to the % predicted by the PP? -----
  
# Density plot: 
# Note that CO's are defined as FC/CC (which is comparable to FC/CC - 1 = (FC-CC)/CC), not (FC-CC)/IC
# This means that it doesn't QUITE mesh with all the other results. However, no one will notice, and I think it's a fairer measure of the P90 process.
  Final_over_committed_density<-density(co_all$Final_cost_over_committed , bw = 0.3)
  plot(Final_over_committed_density, lty = 1, lwd = 3, ylim=c(0,1), xlim = c(-1,15))
  
# We expect P90, or at the very least, P75, to be used at this stage. 
# However, the percentage of projects that runs over budget is far greater than 25% or 10%:
  100*(co_all %>% summarise(n()) - co_all %>% filter(Final_cost_over_committed <=1) %>% summarise(n()))/co_all %>% summarise(n())
  
# If we assume that projects are like those we observe when unobserved, then this figure is higher again:
  100*(co_all %>% summarise(n()) - co_all %>% filter(Final_cost/First_cost_when_Committed_a_a <=1) %>% summarise(n()))/co_all %>% summarise(n())
      
  

#* Regression analysis >>>>>>>>  PROJECT level, probability of experiencing an overrun: -----
# All
# Regression
fit_logit_co_all_v7<-glm(experienced_overrun ~ premature_announcement+ log_Total_days_pre_construction + big_states + `Sub-industry` + `Constructed_post_GFC`+ log(First_cost_when_under_construction_real) +election_180_days, data = co_all, family = binomial(link = "logit"))
marginal_effects_logit_co_all_v7<-logitmfx(fit_logit_co_all_v7, data = co_all, robust = TRUE)
marginal_effects_logit_co_all_v7

mean(co_all$log_Total_days_pre_construction)

# Diagnostics
pr_onbudget_logit_all_v7<- exp(predict(fit_logit_co_all_v7))/(1+exp(predict(fit_logit_co_all_v7))) # Prediction
hist(pr_onbudget_logit_all_v7)
resids_logit_co_all_v7<- rstandard(fit_logit_co_all_v7) # Standardized deviance residuals
hist(resids_logit_co_all_v7)
qqnorm(resids_logit_co_all_v7)
#avPlots(fit_logit_co_all_v7)

# GoF
summary(fit_logit_co_all_v7)
logLik(fit_logit_co_all_v7) 
AIC(fit_logit_co_all_v7) 
BIC(fit_logit_co_all_v7)  

# Possible or under consideration to committed ("t1"):

fit_logit_co_all_v7_t1<- 
  co_all %>%
  filter(Matching_status =="Possible - Completed" |Matching_status =="Under consideration - Completed") %$%
  glm(experienced_overrun_t1 ~  premature_announcement+ log_Total_days_pre_construction + log_Total_days_pre_construction + big_states + `Sub-industry` + `Constructed_post_GFC`+ log(First_cost_when_under_construction_real) +  election_180_days  , family = binomial(link = "logit"))

marginal_effects_logit_co_all_v7_t1<-
  co_all %>%
  filter(Matching_status =="Possible - Completed" |Matching_status =="Under consideration - Completed") %>%
  logitmfx(fit_logit_co_all_v7_t1, data = ., robust = TRUE)
marginal_effects_logit_co_all_v7_t1


# Diagnostics
pr_onbudget_logit_all_v7_t1<- exp(predict(fit_logit_co_all_v7_t1))/(1+exp(predict(fit_logit_co_all_v7_t1))) # Prediction
hist(pr_onbudget_logit_all_v7_t1)
resids_logit_co_all_v7_t1<- rstandard(fit_logit_co_all_v7_t1) # Standardized deviance residuals
hist(resids_logit_co_all_v7_t1)
qqnorm(resids_logit_co_all_v7_t1)
#avPlots(fit_logit_co_all_v7_t1)

# GoF
summary(fit_logit_co_all_v7_t1)
logLik(fit_logit_co_all_v7_t1) 
AIC(fit_logit_co_all_v7_t1) 
BIC(fit_logit_co_all_v7_t1)  


# Committed to under construction ("t2"): 
fit_logit_co_all_v7_t2<- 
  co_all %>%
  filter(Matching_status =="Possible - Completed" |Matching_status =="Under consideration - Completed" | Matching_status== "Committed - Completed") %$%
  glm(experienced_overrun_t2 ~   premature_announcement+ log_Total_days_pre_construction + log_Total_days_pre_construction + big_states + `Sub-industry` + `Constructed_post_GFC`+ log(First_cost_when_under_construction_real)  +election_180_days  , family = binomial(link = "logit"))

marginal_effects_logit_co_all_v7_t2<-
  co_all %>%
  filter(Matching_status =="Possible - Completed" |Matching_status =="Under consideration - Completed" | Matching_status== "Committed - Completed") %>%
  logitmfx(fit_logit_co_all_v7_t2, data = ., robust = TRUE) # CHECK THAT THIS IS RUNNING ON THE CORRECT SUBSAMPLE. 
marginal_effects_logit_co_all_v7_t2

# Diagnostics
pr_onbudget_logit_all_v7_t2<- exp(predict(fit_logit_co_all_v7_t2))/(1+exp(predict(fit_logit_co_all_v7_t2))) # Prediction
hist(pr_onbudget_logit_all_v7_t2)
resids_logit_co_all_v7_t2<- rstandard(fit_logit_co_all_v7_t2) # Standardized deviance residuals
hist(resids_logit_co_all_v7_t2)
qqnorm(resids_logit_co_all_v7_t2)
#avPlots(fit_logit_co_all_v7_t2)

# GoF
summary(fit_logit_co_all_v7_t2)
logLik(fit_logit_co_all_v7_t2) 
AIC(fit_logit_co_all_v7_t2) 
BIC(fit_logit_co_all_v7_t2)  

# Under construction to completed ("t3")
fit_logit_co_all_v7_t3<- 
  co_all %>%
  filter(Matching_status =="Possible - Completed" | Matching_status =="Under consideration - Completed" | Matching_status== "Committed - Completed" |  Matching_status== "Under construction - Completed") %$%
  glm(experienced_overrun_t3 ~     premature_announcement+ log_Total_days_pre_construction + log_Total_days_pre_construction + big_states + `Sub-industry` + `Constructed_post_GFC`+ log(First_cost_when_under_construction_real)  + election_180_days , family = binomial(link = "logit"))

marginal_effects_logit_co_all_v7_t3<-
  co_all %>%
  filter(Matching_status =="Possible - Completed" |Matching_status =="Under consideration - Completed" | Matching_status== "Committed - Completed") %>%
  logitmfx(fit_logit_co_all_v7_t3, data = ., robust = TRUE) # CHECK THAT THIS IS RUNNING ON THE CORRECT SUBSAMPLE. 
marginal_effects_logit_co_all_v7_t3

# Diagnostics
pr_onbudget_logit_all_v7_t3<- exp(predict(fit_logit_co_all_v7_t3))/(1+exp(predict(fit_logit_co_all_v7_t3))) # Prediction
hist(pr_onbudget_logit_all_v7_t3)
resids_logit_co_all_v7_t3<- rstandard(fit_logit_co_all_v7_t3) # Standardized deviance residuals
hist(resids_logit_co_all_v7_t3)
qqnorm(resids_logit_co_all_v7_t3)
#avPlots(fit_logit_co_all_v7_t3)

# GoF
summary(fit_logit_co_all_v7_t3)
logLik(fit_logit_co_all_v7_t3) 
AIC(fit_logit_co_all_v7_t3) 
BIC(fit_logit_co_all_v7_t3)  

#* Regression analysis >>>>>>>>  PROJECT level, average magnitude of cost overruns: ----
# Note: cost overruns are defined as (C2 - C1)/C1 here, not (C2 - C1)/First cost, as was done with the indices. 
# This is because the denominator only scales the results, and extending it back earlier than necessary (ie, <C1) only increases the assumptions about missing data that are invoked.

# All
# Regression
fit_logistic_co_all_v4<- lm(log(Final_cost_over_initial)~ premature_announcement + log_Total_days_pre_construction   + big_states + `Sub-industry` + `Constructed_post_GFC`+ log(First_cost_when_under_construction_real)  +election_180_days         , data = co_positive_only_all)
summary(fit_logistic_co_all_v4)   



# Diagnostics
e_fit_logistic_co_all_v4<-residuals(fit_logistic_co_all_v4)
scatter.smooth(e_fit_logistic_co_all_v4)
hist(e_fit_logistic_co_all_v4)
qqnorm(e_fit_logistic_co_all_v4)
plot(e_fit_logistic_co_all_v4, predict(fit_logistic_co_all_v4)) # Fine, though it fits the 0's terribly.
bptest(fit_logistic_co_all_v4) # PASS: No hetero
#fit_logistic_co_all_v4$newse<-vcovHC(fit_logistic_co_all_v4)
#as.data.frame.matrix(coeftest(fit_logistic_co_all_v4,fit_logistic_co_all_v4$newse))
#avPlots(fit_logistic_co_all_v4)

# GoF
logLik(fit_logistic_co_all_v4) 
AIC(fit_logistic_co_all_v4)
BIC(fit_logistic_co_all_v4)    
summary(fit_logistic_co_all_v4)$r.squared 
summary(fit_logistic_co_all_v4)$adj.r.squared 

#Possible or under consideration to committed:

# Regression 
fit_logistic_co_all_v4_t1<-
  co_positive_only_all %>%
  filter(Matching_status =="Possible - Completed" |Matching_status =="Under consideration - Completed") %>%
  lm(log(First_cost_when_Committed_a_z/First_cost_when_Possible_or_under_consideration_a_z) ~ premature_announcement + log_Total_days_pre_construction   + big_states + `Sub-industry` + `Constructed_post_GFC`+ log(First_cost_when_under_construction_real)   +election_180_days, data =. ) 
summary(fit_logistic_co_all_v4_t1)  


# Diagnostics
e_fit_logistic_co_all_v4_t1<-residuals(fit_logistic_co_all_v4_t1)
scatter.smooth(e_fit_logistic_co_all_v4_t1)
hist(e_fit_logistic_co_all_v4_t1)
qqnorm(e_fit_logistic_co_all_v4_t1)
#plot(e_fit_logistic_co_all_v4_t1, predict(fit_logistic_co_all_v4_t1)) 
bptest(fit_logistic_co_all_v4_t1) # all good, which means the next two lines are unnecessary.
#fit_logistic_co_all_v4$newse<-vcovHC(fit_logistic_co_all_v4_t1)
#as.data.frame.matrix(coeftest(fit_logistic_co_all_v4_t1,fit_logistic_co_all_v4_t1$newse))
#avPlots(fit_logistic_co_all_v4_t1)

# GoF
logLik(fit_logistic_co_all_v4_t1) 
AIC(fit_logistic_co_all_v4_t1)
BIC(fit_logistic_co_all_v4_t1)    
summary(fit_logistic_co_all_v4_t1)$r.squared 
summary(fit_logistic_co_all_v4_t1)$adj.r.squared 


#Committed to under construction:

# Regression 
fit_logistic_co_all_v4_t2<-
  co_positive_only_all %>%
  filter(Matching_status =="Possible - Completed" |Matching_status =="Under consideration - Completed" | Matching_status== "Committed - Completed") %>%
  lm(log(First_cost_when_under_construction_a_z/First_cost_when_Committed_a_z) ~ premature_announcement + log_Total_days_pre_construction   + big_states + `Sub-industry` + `Constructed_post_GFC`+ log(First_cost_when_under_construction_real)  +election_180_days        , data =. ) 
summary(fit_logistic_co_all_v4_t2)  

# Diagnostics
e_fit_logistic_co_all_v4_t2<-residuals(fit_logistic_co_all_v4_t2)
scatter.smooth(e_fit_logistic_co_all_v4_t2)
hist(e_fit_logistic_co_all_v4_t2)
qqnorm(e_fit_logistic_co_all_v4_t2)
plot(e_fit_logistic_co_all_v4_t2, predict(fit_logistic_co_all_v4_t2)) 
bptest(fit_logistic_co_all_v4_t2) # all good, which means the next two lines are unnecessary.
#fit_logistic_co_all_v4$newse<-vcovHC(fit_logistic_co_all_v4_t2)
#as.data.frame.matrix(coeftest(fit_logistic_co_all_v4_t2,fit_logistic_co_all_v4_t2$newse))
#avPlots(fit_logistic_co_all_v4_t2)

# GoF
logLik(fit_logistic_co_all_v4_t2) 
AIC(fit_logistic_co_all_v4_t2)
BIC(fit_logistic_co_all_v4_t2)    
summary(fit_logistic_co_all_v4_t2)$r.squared 
summary(fit_logistic_co_all_v4_t2)$adj.r.squared 

#Under construction to complete:

# Regression 
fit_logistic_co_all_v4_t3<-
  co_positive_only_all %>%
  filter(Matching_status =="Possible - Completed" |Matching_status =="Under consideration - Completed" | Matching_status== "Committed - Completed"| Matching_status== "Under construction - Completed") %>%
  lm(log(Final_cost/First_cost_when_under_construction_a_z) ~ premature_announcement + log_Total_days_pre_construction   + big_states + `Sub-industry` + `Constructed_post_GFC`+ log(First_cost_when_under_construction_real)   +election_180_days, data =. ) 
summary(fit_logistic_co_all_v4_t3)  

# Diagnostics
e_fit_logistic_co_all_v4_t3<-residuals(fit_logistic_co_all_v4_t3)
scatter.smooth(e_fit_logistic_co_all_v4_t3)
hist(e_fit_logistic_co_all_v4_t3)
qqnorm(e_fit_logistic_co_all_v4_t3)
plot(e_fit_logistic_co_all_v4_t3, predict(fit_logistic_co_all_v4_t3)) 
bptest(fit_logistic_co_all_v4_t3) # hetero is present, so adjust the standard errors
fit_logistic_co_all_v4$newse<-vcovHC(fit_logistic_co_all_v4_t3)
as.data.frame.matrix(coeftest(fit_logistic_co_all_v4_t3,fit_logistic_co_all_v4_t3$newse))
#avPlots(fit_logistic_co_all_v4_t3)

# GoF
logLik(fit_logistic_co_all_v4_t3) 
AIC(fit_logistic_co_all_v4_t3)
BIC(fit_logistic_co_all_v4_t3)    
summary(fit_logistic_co_all_v4_t3)$r.squared 
summary(fit_logistic_co_all_v4_t3)$adj.r.squared 

#* Regression analysis >>>>>>>>  Exporting regression results: ----

# Summarising GoF measures:

# Writing the excel file: 

# Logit models:
fit_logit_co_all_v7_OUTPUT<-cbind(row.names(marginal_effects_logit_co_all_v7$mfxest), marginal_effects_logit_co_all_v7$mfxest)
fit_logit_co_all_v7_t1_OUTPUT<-cbind(row.names(marginal_effects_logit_co_all_v7_t1$mfxest),marginal_effects_logit_co_all_v7_t1$mfxest)                 
fit_logit_co_all_v7_t2_OUTPUT<-cbind(row.names(marginal_effects_logit_co_all_v7_t2$mfxest), marginal_effects_logit_co_all_v7_t2$mfxest)               
fit_logit_co_all_v7_t3_OUTPUT<-cbind(row.names(marginal_effects_logit_co_all_v7_t3$mfxest), marginal_effects_logit_co_all_v7_t3$mfxest)  

# Loglogistic PROJECT level models:
fit_logistic_co_all_v4_OUTPUT<- tidy(fit_logistic_co_all_v4)
fit_logistic_co_all_v4_t1_OUTPUT <-tidy(fit_logistic_co_all_v4_t1)
fit_logistic_co_all_v4_t2_OUTPUT <-tidy(fit_logistic_co_all_v4_t2)
fit_logistic_co_all_v4_t3_OUTPUT<- cbind(row.names(as.data.frame.matrix(coeftest(fit_logistic_co_all_v4_t3,fit_logistic_co_all_v4_t3$newse))), as.data.frame.matrix(coeftest(fit_logistic_co_all_v4_t3,fit_logistic_co_all_v4_t3$newse))) 

# Goodness of fit: full dataset:  
Goodness_of_fit <- data.frame(Model = c("Logit_all", "Loglogistic_project_level_all", "Logit_t1", "Loglogistic_project_level_t1", "Logit_t2", "Loglogistic_project_level_t2", "Logit_t3", "Loglogistic_project_level_t3"),
                              logLikelihood = c(logLik(fit_logit_co_all_v7) , logLik(fit_logistic_co_all_v4), logLik(fit_logit_co_all_v7_t1) , logLik(fit_logistic_co_all_v4_t1),  logLik(fit_logit_co_all_v7_t2) , logLik(fit_logistic_co_all_v4_t2), logLik(fit_logit_co_all_v7_t3) , logLik(fit_logistic_co_all_v4_t3)),
                              AIC = c(AIC(fit_logit_co_all_v7), AIC(fit_logistic_co_all_v4),  AIC(fit_logit_co_all_v7_t1), AIC(fit_logistic_co_all_v4_t1), AIC(fit_logit_co_all_v7_t2), AIC(fit_logistic_co_all_v4_t2),   AIC(fit_logit_co_all_v7_t3), AIC(fit_logistic_co_all_v4_t3)),   
                              BIC = c(BIC(fit_logit_co_all_v7), BIC(fit_logistic_co_all_v4), BIC(fit_logit_co_all_v7_t1), BIC(fit_logistic_co_all_v4_t1),  BIC(fit_logit_co_all_v7_t2), BIC(fit_logistic_co_all_v4_t2), BIC(fit_logit_co_all_v7_t3), BIC(fit_logistic_co_all_v4_t3)),
                              R_sq = c("NA", summary(fit_logistic_co_all_v4)$r.squared , "NA", summary(fit_logistic_co_all_v4_t1)$r.squared ,  "NA", summary(fit_logistic_co_all_v4_t2)$r.squared, "NA", summary(fit_logistic_co_all_v4_t3)$r.squared), 
                              Adj_R_sq = c("NA", summary(fit_logistic_co_all_v4)$adj.r.squared,  "NA", summary(fit_logistic_co_all_v4_t1)$adj.r.squared, "NA", summary(fit_logistic_co_all_v4_t2)$adj.r.squared, "NA", summary(fit_logistic_co_all_v4_t3)$adj.r.squared))

#Regressions_second_round <- createWorkbook()
#addWorksheet(Regressions_second_round, "Logit all")
#addWorksheet(Regressions_second_round, "Logit t1")
#addWorksheet(Regressions_second_round, "Logit t2")
#addWorksheet(Regressions_second_round, "Logit t3")
#addWorksheet(Regressions_second_round, "lL project all")
#addWorksheet(Regressions_second_round, "lL project t1")
#addWorksheet(Regressions_second_round, "lL project t2")
#addWorksheet(Regressions_second_round, "lL project t3")
#addWorksheet(Regressions_second_round, "Goodness of fit")
#writeData(Regressions_second_round, 1, fit_logit_co_all_v7_OUTPUT)
#writeData(Regressions_second_round, 2, fit_logit_co_all_v7_t1_OUTPUT)
#writeData(Regressions_second_round, 3, fit_logit_co_all_v7_t2_OUTPUT)
#writeData(Regressions_second_round, 4, fit_logit_co_all_v7_t3_OUTPUT)
#writeData(Regressions_second_round, 5, fit_logistic_co_all_v4_OUTPUT)
#writeData(Regressions_second_round, 6, fit_logistic_co_all_v4_t1_OUTPUT)
#writeData(Regressions_second_round, 7, fit_logistic_co_all_v4_t2_OUTPUT)
#writeData(Regressions_second_round, 8, fit_logistic_co_all_v4_t3_OUTPUT)
#writeData(Regressions_second_round, 9, Goodness_of_fit)
#saveWorkbook(Regressions_second_round, file = "../Spreadsheets/Deloitte pipeline analysis outputs/Regressions_second_round.xlsx", overwrite = TRUE)    

#* Regression analysis >>>>>>>>  Exhibiting the benefit of a loglogistic glm for the magnitude regression: ----

# Linear regression: 
fit<-lm(Final_cost_over_initial~Matching_status_numeric + log_Total_days_pre_construction   + big_states + `Sub-industry` + `Constructed_post_GFC`+ log(First_cost_when_under_construction_real)  +State_election_within_180_days        , data = co_positive_only_all)
e_fit<-residuals(fit)
scatter.smooth(e_fit)

plot(density(e_fit, bw=0.5), lty=1, lwd=3, col = "skyblue")
lines(density(e_fit_logistic_co_all_v4, bw=0.5),lty=1, lwd=3, col = "orange")
lines(density(rnorm(1000, 0, sd(e_fit_logistic_co_all_v4)), bw=0.5), lty=1, lwd=3)

# Time series analysis : Sample sizes over time, classified by initial date -----


sample_size_2000 <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2000-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2001-01-01")) %>%
  summarise(n())

sample_size_2001 <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2001-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2002-01-01")) %>%
  summarise(n())
sample_size_2002 <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2002-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2003-01-01")) %>%
  summarise(n())
sample_size_2003 <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2003-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2004-01-01")) %>%
  summarise(n())
sample_size_2004 <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2004-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2005-01-01")) %>%
  summarise(n())
sample_size_2005 <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2005-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2006-01-01")) %>%
  summarise(n())
sample_size_2006 <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2006-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2007-01-01")) %>%
  summarise(n())
sample_size_2007 <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2007-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2008-01-01")) %>%
  summarise(n())
sample_size_2008 <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2008-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2009-01-01")) %>%
  summarise(n())
sample_size_2009 <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2009-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2010-01-01")) %>%
  summarise(n())
sample_size_2010 <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2010-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2011-01-01")) %>%
  summarise(n())
sample_size_2011 <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2011-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2012-01-01")) %>%
  summarise(n())
sample_size_2012 <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2012-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2013-01-01")) %>%
  summarise(n())
sample_size_2013 <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2013-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2014-01-01")) %>%
  summarise(n())
sample_size_2014 <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2014-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2015-01-01")) %>%
  summarise(n())
sample_size_2015 <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2015-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2016-01-01")) %>%
  summarise(n())
sample_size_by_year <- data.frame(variable = c("2000", "2001", "2002", "2003", "2004", "2005", "2006", "2007", "2008", "2009", "2010", "2011", "2012", "2013", "2014", "2015"), 
                                                       sample_size = c(sample_size_2000$`n()`, sample_size_2001$`n()`, sample_size_2002$`n()`, sample_size_2003$`n()`, sample_size_2004$`n()`, sample_size_2005$`n()`, sample_size_2006$`n()`,
                                                                             sample_size_2007$`n()`, sample_size_2008$`n()`, sample_size_2009$`n()`, sample_size_2010$`n()`, sample_size_2011$`n()`, sample_size_2012$`n()`, sample_size_2013$`n()`,
                                                                             sample_size_2014$`n()`, sample_size_2015$`n()`))

plot(sample_size_by_year)

# Time series analysis : MIN cost overrun over time, classified by initial date -----


min_2000_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2000-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2001-01-01")) %>%
  summarise(min_2000_overall_overrun = min(Final_cost_over_initial))

min_2001_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2001-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2002-01-01")) %>%
  summarise(min_2001_overall_overrun = min(Final_cost_over_initial))

min_2002_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2002-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2003-01-01")) %>%
  summarise(min_2002_overall_overrun = min(Final_cost_over_initial))

min_2003_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2003-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2004-01-01")) %>%
  summarise(min_2003_overall_overrun = min(Final_cost_over_initial))

min_2004_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2004-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2005-01-01")) %>%
  summarise(min_2004_overall_overrun = min(Final_cost_over_initial))

min_2005_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2005-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2006-01-01")) %>%
  summarise(min_2005_overall_overrun = min(Final_cost_over_initial))

min_2006_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2006-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2007-01-01")) %>%
  summarise(min_2006_overall_overrun = min(Final_cost_over_initial))

min_2007_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2007-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2008-01-01")) %>%
  summarise(min_2007_overall_overrun = min(Final_cost_over_initial))

min_2008_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2008-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2009-01-01")) %>%
  summarise(min_2008_overall_overrun = min(Final_cost_over_initial))

min_2009_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2009-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2010-01-01")) %>%
  summarise(min_2009_overall_overrun = min(Final_cost_over_initial))

min_2010_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2010-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2011-01-01")) %>%
  summarise(min_2010_overall_overrun = min(Final_cost_over_initial))

min_2011_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2011-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2012-01-01")) %>%
  summarise(min_2011_overall_overrun = min(Final_cost_over_initial))

min_2012_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2012-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2013-01-01")) %>%
  summarise(min_2012_overall_overrun = min(Final_cost_over_initial))

min_2013_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2013-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2014-01-01")) %>%
  summarise(min_2013_overall_overrun = min(Final_cost_over_initial))

min_2014_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2014-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2015-01-01")) %>%
  summarise(min_2014_overall_overrun = min(Final_cost_over_initial))

min_2015_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2015-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2016-01-01")) %>%
  summarise(min_2015_overall_overrun = min(Final_cost_over_initial))

min_overall_overrun_over_time___initial <- data.frame(variable = c("2000", "2001", "2002", "2003", "2004", "2005", "2006", "2007", "2008", "2009", "2010", "2011", "2012", "2013", "2014", "2015"), 
                                                      min_cost_overrun = c(0,as.numeric(min_2001_overall_overrun), as.numeric(min_2002_overall_overrun), as.numeric(min_2003_overall_overrun), as.numeric(min_2004_overall_overrun),
                                                                           as.numeric(min_2005_overall_overrun), as.numeric(min_2006_overall_overrun), as.numeric(min_2007_overall_overrun), as.numeric(min_2008_overall_overrun),
                                                                           as.numeric(min_2009_overall_overrun), as.numeric(min_2010_overall_overrun), as.numeric(min_2011_overall_overrun), as.numeric(min_2012_overall_overrun),
                                                                           as.numeric(min_2013_overall_overrun), as.numeric(min_2014_overall_overrun), as.numeric(min_2015_overall_overrun)))

plot(min_overall_overrun_over_time___initial)

# Time series analysis : MAX cost overrun over time, classified by initial date -----


max_2000_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2000-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2001-01-01")) %>%
  summarise(max_2000_overall_overrun = max(Final_cost_over_initial))

max_2001_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2001-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2002-01-01")) %>%
  summarise(max_2001_overall_overrun = max(Final_cost_over_initial))

max_2002_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2002-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2003-01-01")) %>%
  summarise(max_2002_overall_overrun = max(Final_cost_over_initial))

max_2003_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2003-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2004-01-01")) %>%
  summarise(max_2003_overall_overrun = max(Final_cost_over_initial))

max_2004_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2004-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2005-01-01")) %>%
  summarise(max_2004_overall_overrun = max(Final_cost_over_initial))

max_2005_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2005-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2006-01-01")) %>%
  summarise(max_2005_overall_overrun = max(Final_cost_over_initial))

max_2006_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2006-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2007-01-01")) %>%
  summarise(max_2006_overall_overrun = max(Final_cost_over_initial))

max_2007_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2007-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2008-01-01")) %>%
  summarise(max_2007_overall_overrun = max(Final_cost_over_initial))

max_2008_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2008-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2009-01-01")) %>%
  summarise(max_2008_overall_overrun = max(Final_cost_over_initial))

max_2009_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2009-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2010-01-01")) %>%
  summarise(max_2009_overall_overrun = max(Final_cost_over_initial))

max_2010_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2010-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2011-01-01")) %>%
  summarise(max_2010_overall_overrun = max(Final_cost_over_initial))

max_2011_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2011-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2012-01-01")) %>%
  summarise(max_2011_overall_overrun = max(Final_cost_over_initial))

max_2012_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2012-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2013-01-01")) %>%
  summarise(max_2012_overall_overrun = max(Final_cost_over_initial))

max_2013_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2013-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2014-01-01")) %>%
  summarise(max_2013_overall_overrun = max(Final_cost_over_initial))

max_2014_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2014-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2015-01-01")) %>%
  summarise(max_2014_overall_overrun = max(Final_cost_over_initial))

max_2015_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2015-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2016-01-01")) %>%
  summarise(max_2015_overall_overrun = max(Final_cost_over_initial))

max_overall_overrun_over_time___initial <- data.frame(variable = c("2000", "2001", "2002", "2003", "2004", "2005", "2006", "2007", "2008", "2009", "2010", "2011", "2012", "2013", "2014", "2015"), 
                                                       max_cost_overrun = c(0,as.numeric(max_2001_overall_overrun), as.numeric(max_2002_overall_overrun), as.numeric(max_2003_overall_overrun), as.numeric(max_2004_overall_overrun),
                                                                             as.numeric(max_2005_overall_overrun), as.numeric(max_2006_overall_overrun), as.numeric(max_2007_overall_overrun), as.numeric(max_2008_overall_overrun),
                                                                             as.numeric(max_2009_overall_overrun), as.numeric(max_2010_overall_overrun), as.numeric(max_2011_overall_overrun), as.numeric(max_2012_overall_overrun),
                                                                             as.numeric(max_2013_overall_overrun), as.numeric(max_2014_overall_overrun), as.numeric(max_2015_overall_overrun)))

plot(max_overall_overrun_over_time___initial)

# Time series analysis : MEAN cost overrun over time, classified by initial date -----


mean_2000_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2000-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2001-01-01")) %>%
  summarise(mean_2000_overall_overrun = mean(Final_cost_over_initial))

mean_2001_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2001-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2002-01-01")) %>%
  summarise(mean_2001_overall_overrun = mean(Final_cost_over_initial))

mean_2002_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2002-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2003-01-01")) %>%
  summarise(mean_2002_overall_overrun = mean(Final_cost_over_initial))

mean_2003_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2003-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2004-01-01")) %>%
  summarise(mean_2003_overall_overrun = mean(Final_cost_over_initial))

mean_2004_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2004-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2005-01-01")) %>%
  summarise(mean_2004_overall_overrun = mean(Final_cost_over_initial))

mean_2005_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2005-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2006-01-01")) %>%
  summarise(mean_2005_overall_overrun = mean(Final_cost_over_initial))

mean_2006_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2006-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2007-01-01")) %>%
  summarise(mean_2006_overall_overrun = mean(Final_cost_over_initial))

mean_2007_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2007-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2008-01-01")) %>%
  summarise(mean_2007_overall_overrun = mean(Final_cost_over_initial))

mean_2008_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2008-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2009-01-01")) %>%
  summarise(mean_2008_overall_overrun = mean(Final_cost_over_initial))

mean_2009_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2009-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2010-01-01")) %>%
  summarise(mean_2009_overall_overrun = mean(Final_cost_over_initial))

mean_2010_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2010-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2011-01-01")) %>%
  summarise(mean_2010_overall_overrun = mean(Final_cost_over_initial))

mean_2011_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2011-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2012-01-01")) %>%
  summarise(mean_2011_overall_overrun = mean(Final_cost_over_initial))

mean_2012_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2012-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2013-01-01")) %>%
  summarise(mean_2012_overall_overrun = mean(Final_cost_over_initial))

mean_2013_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2013-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2014-01-01")) %>%
  summarise(mean_2013_overall_overrun = mean(Final_cost_over_initial))

mean_2014_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2014-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2015-01-01")) %>%
  summarise(mean_2014_overall_overrun = mean(Final_cost_over_initial))

mean_2015_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2015-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2016-01-01")) %>%
  summarise(mean_2015_overall_overrun = mean(Final_cost_over_initial))

mean_overall_overrun_over_time___initial <- data.frame(variable = c("2000", "2001", "2002", "2003", "2004", "2005", "2006", "2007", "2008", "2009", "2010", "2011", "2012", "2013", "2014", "2015"), 
                                                         mean_cost_overrun = c(as.numeric(mean_2000_overall_overrun),as.numeric(mean_2001_overall_overrun), as.numeric(mean_2002_overall_overrun), as.numeric(mean_2003_overall_overrun), as.numeric(mean_2004_overall_overrun),
                                                                               as.numeric(mean_2005_overall_overrun), as.numeric(mean_2006_overall_overrun), as.numeric(mean_2007_overall_overrun), as.numeric(mean_2008_overall_overrun),
                                                                               as.numeric(mean_2009_overall_overrun), as.numeric(mean_2010_overall_overrun), as.numeric(mean_2011_overall_overrun), as.numeric(mean_2012_overall_overrun),
                                                                               as.numeric(mean_2013_overall_overrun), as.numeric(mean_2014_overall_overrun), as.numeric(mean_2015_overall_overrun)))

plot(mean_overall_overrun_over_time___initial)

# Time series analysis : SD cost overrun over time, classified by initial date -----


sd_2000_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2000-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2001-01-01")) %>%
  summarise(sd_2000_overall_overrun = sd(Final_cost_over_initial))

sd_2001_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2001-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2002-01-01")) %>%
  summarise(sd_2001_overall_overrun = sd(Final_cost_over_initial))

sd_2002_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2002-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2003-01-01")) %>%
  summarise(sd_2002_overall_overrun = sd(Final_cost_over_initial))

sd_2003_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2003-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2004-01-01")) %>%
  summarise(sd_2003_overall_overrun = sd(Final_cost_over_initial))

sd_2004_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2004-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2005-01-01")) %>%
  summarise(sd_2004_overall_overrun = sd(Final_cost_over_initial))

sd_2005_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2005-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2006-01-01")) %>%
  summarise(sd_2005_overall_overrun = sd(Final_cost_over_initial))

sd_2006_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2006-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2007-01-01")) %>%
  summarise(sd_2006_overall_overrun = sd(Final_cost_over_initial))

sd_2007_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2007-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2008-01-01")) %>%
  summarise(sd_2007_overall_overrun = sd(Final_cost_over_initial))

sd_2008_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2008-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2009-01-01")) %>%
  summarise(sd_2008_overall_overrun = sd(Final_cost_over_initial))

sd_2009_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2009-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2010-01-01")) %>%
  summarise(sd_2009_overall_overrun = sd(Final_cost_over_initial))

sd_2010_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2010-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2011-01-01")) %>%
  summarise(sd_2010_overall_overrun = sd(Final_cost_over_initial))

sd_2011_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2011-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2012-01-01")) %>%
  summarise(sd_2011_overall_overrun = sd(Final_cost_over_initial))

sd_2012_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2012-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2013-01-01")) %>%
  summarise(sd_2012_overall_overrun = sd(Final_cost_over_initial))

sd_2013_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2013-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2014-01-01")) %>%
  summarise(mean_2013_overall_overrun = sd(Final_cost_over_initial))

sd_2014_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2014-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2015-01-01")) %>%
  summarise(sd_2014_overall_overrun = sd(Final_cost_over_initial))

sd_2015_overall_overrun <-
  co_all %>%
  filter(!is.na(Initial_date)) %>%
  filter(as.Date("2015-01-01") <=as.Date(Initial_date),
         as.Date(Initial_date)<= as.Date("2016-01-01")) %>%
  summarise(sd_2015_overall_overrun = sd(Final_cost_over_initial))

sd_overall_overrun_over_time___initial <- data.frame(variable = c("2000", "2001", "2002", "2003", "2004", "2005", "2006", "2007", "2008", "2009", "2010", "2011", "2012", "2013", "2014", "2015"), 
                                                       sd_cost_overrun = c(as.numeric(sd_2000_overall_overrun),as.numeric(sd_2001_overall_overrun), as.numeric(sd_2002_overall_overrun), as.numeric(sd_2003_overall_overrun), as.numeric(sd_2004_overall_overrun),
                                                                             as.numeric(sd_2005_overall_overrun), as.numeric(sd_2006_overall_overrun), as.numeric(sd_2007_overall_overrun), as.numeric(sd_2008_overall_overrun),
                                                                             as.numeric(sd_2009_overall_overrun), as.numeric(sd_2010_overall_overrun), as.numeric(sd_2011_overall_overrun), as.numeric(sd_2012_overall_overrun),
                                                                             as.numeric(sd_2013_overall_overrun), as.numeric(sd_2014_overall_overrun), as.numeric(sd_2015_overall_overrun)))

plot(sd_overall_overrun_over_time___initial)

#  Exporting time analysis: ----
#Overruns_by_time <- createWorkbook()
#addWorksheet(Overruns_by_time, "N by year")
#addWorksheet(Overruns_by_time, "Min by year")
#addWorksheet(Overruns_by_time, "Max by year")
#addWorksheet(Overruns_by_time, "Mean by year")
#addWorksheet(Overruns_by_time, "Sd by year")
#writeData(Overruns_by_time, 1, sample_size_by_year)
#writeData(Overruns_by_time, 2, min_overall_overrun_over_time___initial)
#writeData(Overruns_by_time, 3, max_overall_overrun_over_time___initial)
#writeData(Overruns_by_time, 4, mean_overall_overrun_over_time___initial)
#writeData(Overruns_by_time, 5, sd_overall_overrun_over_time___initial)
#saveWorkbook(Overruns_by_time, file = "../Spreadsheets/Deloitte pipeline analysis outputs/Overruns by time.xlsx", overwrite = TRUE)










@

<<grattan_percent>>=
grattan_percent <- function(number, digits = 1){
  paste0(comma(100*number, digits = digits), "~per~cent")
}
@


\begin{overview}[-40pt]
Most of the time, Australia isnt bad at managing transport infrastructure projects. But when one goes wrong, it can be spectacular. Australia could have saved \Sexpr{texNum(savings_if_every_proj_with_CO_had_CO_le_10pc, dollar = TRUE)} over the past 15 years if every transport infrastructure project with a cost overrun had gone no more than ten per cent over budget. 

Policymakers appear to be complacent about this outcome. At first glance, this is understandable: \Sexpr{grattan_percent(prop_projects_on_budget)} of projects finish on budget, and we are assured that every extreme cost blowout comes with its own story. 

However, data on the cost overruns incurred over the \Sexpr{n_completed_projects} $20m+ transport infrastructure projects built in Australia since 2000 reveals that these stories are misleading: Australias cost overruns are larger and far more common than could be considered normal, and more predictable than their surprised proponents realise. 
Over the last 15 years, Australia has spent at least \Sexpr{texNum(spending_per_dollar_budgeted, dollar = TRUE)} for every dollar initially budgeted for transport infrastructure projects. Cost overruns on infrastructure projects are not a uniquely Australian phenomenon, but Australias cost overruns  especially those that occur prior to construction  are larger than is commonly observed on similarly sized projects overseas. 

This outcome is not surprising when considered against the backdrop of Australias current cost management efforts. As it stands, the guidelines for risk management on transport infrastructure projects are fragmented, insufficient information has been provided for modern strategies like reference class forecasting to be employed and outcomes are not reported transparently.

These efforts are not proportionate to the importance of cost management on transport infrastructure projects. Australia has spent more on transport infrastructure over the last 15 years than weve saved in our Future Fund, and the realisation of a \Sexpr{pc_lower_ROI} per cent lower return on investment than promised in final business cases on average represents a substantial distortion to infrastructure investment decision making. A comparison of the governance of transport infrastructure with that of the Future Fund suggests that transport infrastructure is destined to fail.

Australias toothless appraisal process is not assisted by the perverse incentives facing project proponents. When cheaper projects are more likely to go ahead, top-up federal funding relieves proponents from facing the full marginal cost of overruns and projects scopes can be readily expanded during construction, it is not surprising that cost overruns occur far more commonly than underruns. 

Moreover, the efforts Australia has made to manage cost overruns are not proportional to the opportunity to anticipate and manage cost overruns better. Our analysis identifies that the average size of cost overruns at each project stage varies systematically with project size, maturity, mode, the projects political circumstances and the size of earlier overruns. Insofar as cost overruns can be predicted by observable characteristics like these, opportunities exist for data driven policy that anticipates and actively manages uncertainty.

In this context, Australias complacency regarding cost overruns comes at a high (opportunity) cost. Shifting from an anecdotal to data driven approach to understanding cost overruns reveals that there is substantial scope for improvement at all stages of a projects life, for individual projects and for the portfolio as a whole, and by politicians, bureaucrats and companies alike. 

Instead of each project being a fresh start, the information exists to support project proponents and managers to make good decisions, prevent duplicated effort and learn from experience. We neednt continue to be surprised by whats predictable, and this report puts that ambition within reach.


\end{overview}

\chapter{Introduction}
Cost overruns on transport infrastructure projects are nothing new. Some of the biggest examples are widely known, such as Western Australias Forrest Highway between Perth and Bunbury, which cost nearly six times its initial budget, or New South Wales Hunter Expressway, which cost nearly four times its initial budget. The amount of money at stake is very large: transport infrastructure over the past 15 years has cost \Sexpr{texNum(savings_if_every_proj_with_CO_had_CO_le_10pc, dollar = TRUE)} more than taxpayers were told it would. 

...some more text...

This report brings two unique advantages to these public finance questions. One is that we analyse the entire suite of \Sexpr{n_projects}  transport infrastructure projects valued at $20 million or more each, planned or built by Australian governments since 2000. Another specific advantage is that we analyse projects over their entire lifecycle, right from when they are first announced by a minister or opposition politician, to when they receive a formal funding commitment, through to completion (Figure xx). 

...and the rest of this section is text. 

Figure 1.1: Cost overruns are at least as large as 22 per cent of initial project costs, but could be as large as 45 per cent
<<>>=

@


\chapter{People underestimate the extent of cost overruns}
Even though cost overruns on transport infrastructure represent a very large cost, they receive little focus and governments appear complacent...

\section {Cost overruns are very expensive}
...But the frequency of overruns is only a small part of the story: what is much more important is the size. While only \Sexpr{round(pc_of_projects_w_overrun_gt_0.5,0)} per cent of projects overran their budget by 50 per cent or more, such overruns accounted for \Sexpr{round(pc_of_co_value_from_projects_w_overrun_gt_0.5,0)} per cent of the total value of overruns (Figure xx). The cost to government budgets of overruns of 50 per cent or more was $xx billion over the past fifteen years.

Even bigger blowouts, of 200 per cent or more, occurred on \Sexpr{round(pc_of_projects_w_overrun_gt_2,0)} per cent of projects, but accounted for fully a quarter (\Sexpr{round(pc_of_co_value_from_projects_w_overrun_gt_2,0)}\%)of the total value of all overruns. The cost of overruns where the project was completed at double its budgeted cost or more was $\Sexpr{round(value_B_of_co_gt_2,2)} billion.

Figure 2.1: Extremely large cost overruns pose almost all the cost
<<>>=
freq_value_graph
            
@

\section{Australia does not compare especially well internationally}
 ... lit review goes here...
  <<>>=
# The lit review graph uses lots of datasets. The key figures from this dataset (not in the current graph, which is super old) are:
co_all_table_1_portfolio_az$co12[3]
co_all_table_1_portfolio_az$co23[3]
co_all_table_1_portfolio_az$co34[3]

@

\section{Cost overruns have no single culprit}
Transport infrastructure projects are very varied, sometimes very complex, and subject to a range of pressures. None of the common reasons given for cost overruns, taken alone is especially compelling.

\subsection{Scope changes explain a small share of overruns}

...some text...
Scope changes only account for around 12 per cent of cost overruns on transport infrastructure projects, even including the full project lifecycle from the time of first announcement 
Hugh: This figure comes from the Grattan dataset. The analysis is in excel. 

Figure 2.3.1: Scope changes pie chart (again, the data is not in R)
...some text...

\subsection{Escalation in costs is not a significant cause of cost overruns}

...some text...
However, escalation in costs does not have a significant impact on cost overruns across the whole portfolio of projects of the past 15 years in above and beyond the other factors outlined in this report. 
Hugh: This finding comes the eight regression models listed below.

<<>>=
# Escalation (which is consequence of spending longer than expected in the investment pipeline) is proxied by log_Total_days_pre_construction:
# Note: t1: initial announcment - commitment stage, t2: commitment - under construction stage, t3: under construction - completion, no t suffix: initial announcement - completion stage

# These four models report the marginal effects of X's on the probability of a cost overrun
fit_logit_co_all_v7_OUTPUT
fit_logit_co_all_v7_t1_OUTPUT
fit_logit_co_all_v7_t2_OUTPUT
fit_logit_co_all_v7_t3_OUTPUT

# These four models report the marginal effects of X's on the magnitude of cost overruns, if they occurred. 
fit_logistic_co_all_v4_OUTPUT
fit_logistic_co_all_v4_t1_OUTPUT
fit_logistic_co_all_v4_t2_OUTPUT
fit_logistic_co_all_v4_t3_OUTPUT

@


\subsection{Early overruns do not prevent later overruns}
Cost overruns occur throughout the project lifecycle, accounting overall for \Sexpr{round((spending_per_dollar_budgeted-1)*100,0)}  cents additional cost for every dollar of estimated project cost (Figure 2.3.3). 

Figure 2.3.3:

<<>>= 
waterfall_graph <-data.frame( Time_period = c("First cost announcement - budget commitment", "Budget commitment - under construction", "Under construction - completed", "First cost announcement - completed" ), 
                              Cost_overrun = c(co_all_table_1_portfolio_az$co12[3], co_all_table_1_portfolio_az$co23[3], co_all_table_1_portfolio_az$co34[3], co_all_table_1_portfolio_az$co14[3]))

@


Overruns in the initial phase, between announcement and before a formal funding commitment, occur at a rate of \Sexpr{round(co_all_indices_AM$co12*100,0)} cents on every dollar of project value. These overruns are concerning because any later overruns that occur do so on the enlarged cost base resulting from the earlier overrun. 
Overruns in the middle phase, after the funding commitment up until construction begins, occur at a rate of \Sexpr{round(co_all_indices_AM$co23*100,0)} cents on every dollar of project value. Overruns during construction occur at a rate of \Sexpr{round(co_all_indices_AM$co34*100,0)} cents for every dollar of project value. These middle and later phase overruns are concerning because they reveal that the initial decision to invest was made on an inaccurate basis. 

The inaccurate basis for the decision to invest is also apparent from analysis of the cost estimates. Cost estimates produced to a standard that anticipates the project will equal or better its budget three quarters of the time (known as a P75 costing) actually only achieved this result \Sexpr{round((1-pc_of_projects_w_overrun)*100,0)} per cent of the time. The difference reveals significant understatement of costs across the portfolio of projects planned or built since 2000.

\chapter{Cost overruns are more preventable than people think}
..some text..

\section {Poor incentives for decision-makers}
Ministers, governments and would-be governments have always sought political advantage by promising infrastructure. But politicised announcements that ignore proper process have poor outcomes. Cost overruns are \Sexpr{round(fit_logistic_co_all_v4$coefficients[11]*100,0)} per cent larger on average for projects announced close to a state election than otherwise similar projects announced at other times. This confirms the contention of previous Grattan report, Roads to Riches, that politicians commit to poor quality projects for political benefit.  

\section {Poor process causes cost overruns}

\subsection{Premature announcements}

Figure 3.3.11
<<>>=
 co_all_table_3

@

Figure 3.3.12
<<>>=
overall_overruns_by_cohort
@

Figure 3.3.21
<<>>=
#Hmm triple check this. 

cancellation_rate_by_stage

@

Figure 3.3.22
<<>>=

cancellation_rate_by_cohort
  
@

Premature announcement affects not only the likelihood of an overrun, but also its size. Projects with costs announced ahead of a government funding commitment have far larger cost overruns, averaging \Sexpr{round((overall_overruns_by_cohort[1,4]-1)*100,0)} per cent of the initially announced cost (Figure xx).  Figure xx illustrates net overruns of \Sexpr{round((overall_overruns_by_cohort[2,4]-1)*100,0)} to \Sexpr{round((overall_overruns_by_cohort[3,4]-1)*100,0)} per cent occur for projects announced with more mature cost estimates than those announced early.

(This paragraph is currently being rewritten, but these should be the correct figures)

\subsection{Failure to cancel dubious projects}
..some text...

Not all projects that are announced end up being built. Around \Sexpr{round(n_completed_projects/n_projects*100,0)} per cent of all announced projects go through to completion. Of those announced early, before a formal government funding commitment, \Sexpr{round(pc_g1_projects_completed*100, 0)} per cent continue through to completion. Projects that are announced when more mature are much more likely to be completed (Figure xx).

\chapter{Cost overruns are much more predictable than people think}

\section {Why predict unavoidable risks?}
\subsection {More complex projects are riskier}

The likelihood of a cost overrun increases markedly as project size increases, after consideration of other factors. For every extra 10 per cent in a projects size (measured by cost estimate when first under construction), there is a \Sexpr{round(marginal_effects_logit_co_all_v7$mfxest[9]*100*10,0)}  per cent higher chance of a cost overrun, and for the projects with an overrun, greater project size leads is linked to much greater overrun size during the pre-construction period .

<<>>=
# For the last claim, see the coefficients of log_first_cost_when_under_construction in:
summary(fit_logistic_co_all_v4_t1)
summary(fit_logistic_co_all_v4_t2)
@

 Figure 4.2.1
<<>>=
                           
pc_overruns_and_project_size_states
@


\subsection{Singular projects are riskier}

Figure 4.2.2
<<>>=

Cost_overruns_by_mode

@



\section {How can avoidable risks be managed?}

Note: this figure does not exist (and can't be estimated) and will be removed from the draft:
The following three sections identify three major places where improvements could be made so as to save a substantial share of the $18 billion of overruns occurring after the formal funding commitment. 

\subsection {Learn from past experience}

Perhaps the most valuable resource we have in estimating project risks is the reservoir of experience from planning and delivering over \Sexpr{round(n_completed_projects/100,0)*100} transport infrastructure projects valued at $20 million or more in Australia over the past 15 years. 

...some more text...

Note: there's some text that says:
"The assumptions that are being made at present in project budgets are significantly different to the costs that eventuate when the project is built (Figure XX). Almost 50 per cent of projects end up costing more than the worst case or P90 cost estimate. . "

This needs to be changed to:
"Over \Sexpr{round(pc_of_projects_w_overrun*100,0)} per cent of projects end up costing more than the worst case or (P75-P90) cost estimate." It also needs to be clarified and moved to chapter 1..

\chapter{Charts that will probably be added in}

 <<>>=

# Sample size charts:
sample_size_by_cohort<- data.frame(Period_of_initial_cost_announcement = c("Possible or under consideration", "Committed", "Under construction"), 
                                   Sample_size = c(nrow(co_g1), nrow(co_g2), nrow(co_g3)))

@


\end{document}